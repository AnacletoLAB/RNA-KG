{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aab6c15",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">RNA-KG node properties and entity linking</p>\n",
    "    \n",
    "***\n",
    "***\n",
    "\n",
    "**Author:** [ECavalleri](https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=emanuele.cavalleri@unimi.it)\n",
    "\n",
    "**GitHub Repositories:** [RNA-KG](https://github.com/AnacletoLAB/RNA-KG/)\n",
    "  \n",
    "<br>  \n",
    "  \n",
    "**Purpose:** This notebook serves as a script to add properties to entities within the RNA-centered Knowledge Graph. Entities without a direct corresponce to an ontology class are linked to a proper ontology class via the RDF `subClassOf` predicate.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Dependencies:**   \n",
    "- **Scripts**: This notebook utilizes several helper functions, which are stored in the [`data_utils.py`](https://github.com/callahantiff/PheKnowLator/blob/master/pkt_kg/utils/data_utils.py) and [`kg_utils.py`](https://github.com/callahantiff/PheKnowLator/blob/master/pkt_kg/utils/kg_utils.py) scripts.  \n",
    "- **Data**: All downloaded and generated data sources are provided through [10.5281/zenodo.10078876](https://zenodo.org/doi/10.5281/zenodo.10078876) dedicated repository. <u>This notebook will download everything that is needed for you</u>.  \n",
    "_____\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f86aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0254d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import datetime\n",
    "import glob\n",
    "import itertools\n",
    "import networkx\n",
    "import numpy\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import tarfile\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import gffpandas.gffpandas as gffpd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import json\n",
    "import ast\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "from reactome2py import content\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "from pkt_kg.utils import * \n",
    "from builds.ontology_cleaning import *\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6aa0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to store resources\n",
    "resource_data_location = '../resources/'\n",
    "\n",
    "# directory to use for unprocessed data\n",
    "unprocessed_data_location = '../resources/processed_data/unprocessed_data/'\n",
    "\n",
    "# directory to use for unprocessed edge data\n",
    "unprocessed_edge_data_location = '../resources/processed_data/unprocessed_data/edges/'\n",
    "\n",
    "# directory to use for unprocessed property data\n",
    "unprocessed_property_data_location = '../resources/processed_data/unprocessed_data/properties/'\n",
    "\n",
    "# directory to use for processed data\n",
    "processed_data_location = '../resources/processed_data/'\n",
    "\n",
    "# directory to write ontology data to\n",
    "ontology_data_location = '../resources/ontologies/'\n",
    "\n",
    "# directory to write edges data to\n",
    "edge_data_location = '../resources/edge_data/'\n",
    "\n",
    "# directory to write node properties to\n",
    "properties_location = '../resources/property_data/'\n",
    "\n",
    "# processed data url \n",
    "processed_url = 'https://storage.googleapis.com/pheknowlator/current_build/data/processed_data/'\n",
    "\n",
    "# original data url \n",
    "original_url = 'https://storage.googleapis.com/pheknowlator/current_build/data/original_data/'\n",
    "\n",
    "# owltools location\n",
    "owltools_location = '../pkt_kg/libs/owltools'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b427d02",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0769b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = []\n",
    "for filename in os.listdir(unprocessed_edge_data_location):\n",
    "    if filename.endswith('.pkl'):\n",
    "        type.append(filename.split('_')[0])\n",
    "        type.append(filename.split('_')[-1].replace('.pkl', ''))\n",
    "type = set(type)\n",
    "type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec013b6",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# RNA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d524975",
   "metadata": {},
   "source": [
    "* [RNAcentral](https://rnacentral.org/) <br/> RNAcentral is a free, public resource that offers integrated access to a comprehensive and up-to-date set of non-coding RNA sequences provided by a collaborating group of Expert Databases representing a broad range of organisms and RNA types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de79a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ftp.ebi.ac.uk/pub/databases/RNAcentral/current_release/sequences/rnacentral_species_specific_ids.fasta.gz -O $unprocessed_property_data_location/rnacentral_species_specific_ids.fasta.gz \n",
    "!gunzip $unprocessed_property_data_location/rnacentral_species_specific_ids.fasta.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57478cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta_to_df(fasta_file):\n",
    "    records = SeqIO.parse(fasta_file, \"fasta\")   \n",
    "    data = [{'ID': record.id.split(\"_\")[0], 'Sequence': str(record.seq), 'Description': str(record.description.split(\" \",1)[1])}\n",
    "            for record in records if record.id.split(\"_\")[1] == \"9606\"] # aggiungere virus\n",
    "    print(records)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = read_fasta_to_df(unprocessed_property_data_location + \"rnacentral_species_specific_ids.fasta\")\n",
    "\n",
    "df.to_csv(unprocessed_property_data_location + 'rnacentral_species_specific_ids_human.csv', index=False)\n",
    "#df = pd.read_csv(unprocessed_property_data_location + 'rnacentral_species_specific_ids_human.csv')\n",
    "df['Description'] = df['Description'].str.lower()\n",
    "df['Sequence'] = df['Sequence'].str.upper()\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec209b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ftp.ebi.ac.uk/pub/databases/RNAcentral/current_release/genome_coordinates/gff3/homo_sapiens.GRCh38.gff3.gz -O $unprocessed_property_data_location/homo_sapiens.GRCh38.gff3.gz\n",
    "!gunzip $unprocessed_property_data_location/homo_sapiens.GRCh38.gff3.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_attributes(attr_str):\n",
    "    return dict(item.split('=') for item in attr_str.split(';') if '=' in item)\n",
    "\n",
    "gff_df = gffpd.read_gff3(unprocessed_data_location + 'homo_sapiens.GRCh38.gff3').df\n",
    "gff_df = gff_df[gff_df['attributes'].str.contains(\"_9606;\")]\n",
    "gff_df['parsed_attributes'] = gff_df['attributes'].apply(parse_attributes)\n",
    "gff_df = pd.concat([gff_df.drop(columns=['attributes']), gff_df['parsed_attributes'].apply(pd.Series)], axis=1)\n",
    "gff_df.to_csv(unprocessed_property_data_location + \"gffrnacentral.csv\", index=False)\n",
    "#gff_df = pd.read_csv(unprocessed_property_data_location + \"gffrnacentral.csv\")\n",
    "gff_df['Name'] = gff_df['Name'].str.split(\"_\").str[0]\n",
    "gff_df['Genomic_location'] = \"chr\" + gff_df['seq_id'].astype(str) + \":\" + gff_df['start'].astype(str) +\\\n",
    "    \"-\" + gff_df['end'].astype(str) + gff_df['strand']\n",
    "gff_df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da064bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_properties = pd.merge(df, gff_df, left_on='ID', right_on='Name', how='outer')\n",
    "rnacentral_properties['Name'] = rnacentral_properties['Name'].fillna(rnacentral_properties['ID_x'])\n",
    "rnacentral_properties = rnacentral_properties[['Name', 'Sequence', 'Description', 'description',\n",
    "                                               'type.1', 'source', 'databases', 'Genomic_location']]\n",
    "rnacentral_properties.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_map = pd.read_csv(unprocessed_data_location + \"id_mapping.tsv\", delimiter='\\t',\n",
    "                             names=['ID', 'DB', 'DB ID', 'Organism', 'RNA category', 'Label'])\n",
    "rnacentral_map_human = rnacentral_map[rnacentral_map['Organism'] == 9606]\n",
    "rnacentral_map_human.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1845a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_properties = pd.merge(rnacentral_properties, rnacentral_map_human, left_on='Name', right_on='ID', how='right')\n",
    "rnacentral_properties['Name'] = rnacentral_properties['Name'].fillna(rnacentral_properties['ID'])\n",
    "rnacentral_properties['description'] = rnacentral_properties['description'].fillna(rnacentral_properties['Label'])\n",
    "rnacentral_properties.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_properties['Category'] = rnacentral_properties['type.1'] + \",\" + rnacentral_properties['RNA category']\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].str.split(\",\")\n",
    "rnacentral_properties = rnacentral_properties.explode('Category')\n",
    "rnacentral_properties = rnacentral_properties.drop(\n",
    "    columns=['type.1', 'source','databases','ID','DB','DB ID','Organism','RNA category','Label']).drop_duplicates()\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace(np.nan, 'ncRNA')\n",
    "\n",
    "rnacentral_el = rnacentral_properties.copy()\n",
    "rnacentral_el[['Name','Category']].drop_duplicates().to_pickle(unprocessed_property_data_location + 'rnacentral_el.pkl')\n",
    "\n",
    "rnacentral_properties.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_properties = rnacentral_properties.groupby('Name').agg({\n",
    "    'Category': set,\n",
    "    'Description': lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan,\n",
    "    'description': lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan,\n",
    "    'Genomic_location': lambda x: set(x.dropna()) if x.dropna().any() else set(),\n",
    "    'Sequence': lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan\n",
    "}).reset_index()\n",
    "rnacentral_properties.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a145b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_properties.Category = rnacentral_properties.Category.astype(str)\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('{\\'', '', regex=True)\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('\\'}', '', regex=True)\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('\\'', '', regex=True)\n",
    "rnacentral_properties.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40123577",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('lncRNA', 'RNA, ncRNA, lncRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('antisense_RNA', 'RNA, ncRNA, antisense_RNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('precursor_RNA', 'RNA, precursor_RNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('guide_RNA', 'RNA, ncRNA, guide_RNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('autocatalytically_spliced_intron',\n",
    "                                                                              'RNA, ncRNA, intron, autocatalytically_spliced_intron')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('RNase_MRP_RNA',  'RNA, ncRNA, enzymatic_RNA, RNase_MRP_RNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('tmRNA', 'RNA, ncRNA, sncRNA, small_regulatory_ncRNA, tmRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('other', 'RNA, ncRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('circRNA', 'RNA, ncRNA, circRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('piRNA', 'RNA, ncRNA, sncRNA, small_regulatory_ncRNA, piRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('miRNA', 'RNA, ncRNA, sncRNA, small_regulatory_ncRNA, miRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('pre_miRNA',\n",
    "                                                                              'RNA, precursor_RNA, ncRNA, sncRNA, small_regulatory_ncRNA, miRNA, pre_miRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('snRNA', 'RNA, ncRNA, sncRNA, snRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('sRNA', 'RNA, ncRNA, sncRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('snoRNA', 'RNA, ncRNA, sncRNA, snoRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('Y_RNA', 'RNA, ncRNA, Y_RNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('scaRNA', 'RNA, ncRNA, sncRNA, snoRNA, scaRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('scRNA', 'RNA, ncRNA, sncRNA, scRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('tRNA', 'RNA, ncRNA, sncRNA, tRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('SRP_RNA', 'RNA, ncRNA, SRP_RNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('ncRNA', 'RNA, ncRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('rRNA', 'RNA, ncRNA, rRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('ribozyme', 'RNA, ncRNA, enzymatic_RNA, ribozyme')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('hammerhead_ribozyme',\n",
    "                                                                              'RNA, ncRNA, enzymatic_RNA, ribozyme, hammerhead_ribozyme')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('RNase_P_RNA', 'RNA, ncRNA, enzymatic_RNA, RNase_P_RNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('vault_RNA', 'RNA, ncRNA, vault_RNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('misc_RNA', 'RNA, ncRNA')\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].replace('telomerase_RNA', 'RNA, ncRNA, telomerase_RNA')\n",
    "rnacentral_properties['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_properties[':ID'] = \"https://rnacentral.org/rna/\" + rnacentral_properties['Name'].astype(str) + \"_9606\"\n",
    "rnacentral_properties['Category'] = rnacentral_properties['Category'].str.split(\", \").apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "rnacentral_properties['Genomic_location'] = rnacentral_properties['Genomic_location'].apply(lambda x: json.dumps(list(x)))\n",
    "rnacentral_properties['Sequence'] = rnacentral_properties['Sequence'].str.replace('T', 'U')\n",
    "rnacentral_properties = rnacentral_properties.rename(columns={'Name':'RNAcentral_ID', 'Category':':TYPE', 'description':'Label'})\n",
    "rnacentral_properties['Species'] = 'Homo sapiens'\n",
    "rnacentral_properties.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ecbf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_properties.Label = rnacentral_properties.Label.str.replace(\"\\(human\\) \", \"\")\n",
    "rnacentral_properties.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0469fad",
   "metadata": {},
   "source": [
    "We add secondary structures (cloverleaves) from tRNA sequences from GtRNAdb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df835f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_map_gtrnadb = pd.read_csv(processed_data_location + \"RNAcentral_MAP/gtrnadb.tsv\",sep='\\t',\n",
    "                                     names=['RNAcentral ID', 'DB', 'GtRNAdb transcript ID', 'Organism', 'RNA category', 'GtRNAdb Gene ID'])\n",
    "rnacentral_map_human_gtrnadb = rnacentral_map_gtrnadb[rnacentral_map_gtrnadb['Organism'] == 9606].drop(\n",
    "    columns=['Organism', 'DB', 'RNA category'])\n",
    "trna = rnacentral_map_human_gtrnadb[['GtRNAdb Gene ID']].drop_duplicates()\n",
    "trna.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to show retrieval logic\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "tRNA = pd.read_html('http://gtrnadb.ucsc.edu/genomes/eukaryota/Hsapi38/genes/tRNA-Thr-TGT-2-1.html')[0].T\n",
    "tRNA2 = pd.read_html('http://gtrnadb.ucsc.edu/genomes/eukaryota/Hsapi38/genes/tRNA-Thr-TGT-2-1.html')[1].T\n",
    "tRNA = pd.concat([tRNA,tRNA2],axis=1)\n",
    "tRNA.columns = tRNA.iloc[0]\n",
    "tRNA = tRNA[1:][['RNAcentral ID','Secondary Structure (nested bp)']]\n",
    "tRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for identifier in tqdm(trna['GtRNAdb Gene ID'], desc=\"Processing tRNA structures\"):\n",
    "    try:\n",
    "        temp = pd.read_html('http://gtrnadb.ucsc.edu/genomes/eukaryota/Hsapi38/genes/' + identifier + '.html')[0].T\n",
    "        temp2 = pd.read_html('http://gtrnadb.ucsc.edu/genomes/eukaryota/Hsapi38/genes/' + identifier + '.html')[1].T\n",
    "        temp = pd.concat([temp, temp2], axis=1)\n",
    "        temp.columns = temp.iloc[0]\n",
    "        temp = temp[1:]\n",
    "        tRNA = pd.concat([tRNA, temp])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "tRNA = tRNA[['RNAcentral ID','Secondary Structure (nested bp)']].drop_duplicates().rename(\n",
    "    columns={'Secondary Structure (nested bp)':'Structure','RNAcentral ID':'RNAcentral_ID'})\n",
    "tRNA['RNAcentral_ID'] = tRNA['RNAcentral_ID'].str.replace(\"_9606\",\"\")\n",
    "tRNA['Structure'] = tRNA['Structure'].replace(\"\",np.nan)\n",
    "tRNA.to_pickle(unprocessed_property_data_location + 'gtrnadb.pkl')\n",
    "#tRNA = pd.read_pickle(unprocessed_property_data_location + 'gtrnadb.pkl')\n",
    "tRNA.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14576295",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_properties = rnacentral_properties.merge(tRNA, on='RNAcentral_ID', how='left')\n",
    "rnacentral_properties.to_pickle(unprocessed_property_data_location + 'RNAcentral.pkl')\n",
    "rnacentral_properties.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2258b6",
   "metadata": {},
   "source": [
    "* Ensembl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget ftp://ftp.ensembl.org/pub/release-113/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz -O $unprocessed_property_data_location/Homo_sapiens.GRCh38.cdna.all.fa.gz\n",
    "!gunzip $unprocessed_property_data_location/Homo_sapiens.GRCh38.cdna.all.fa.gz\n",
    "!wget ftp://ftp.ensembl.org/pub/release-113/fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz -O  $unprocessed_property_data_location/Homo_sapiens.GRCh38.ncrna.fa.gz\n",
    "!gunzip $unprocessed_property_data_location/Homo_sapiens.GRCh38.ncrna.fa.gz\n",
    "!wget ftp://ftp.ensembl.org/pub/release-113/tsv/homo_sapiens/Homo_sapiens.GRCh38.113.canonical.tsv.gz -O  $unprocessed_property_data_location/Homo_sapiens.GRCh38.113.canonical.tsv.gz\n",
    "!gunzip $unprocessed_property_data_location/Homo_sapiens.GRCh38.113.canonical.tsv.gz\n",
    "!wget ftp://ftp.ensembl.org/pub/release-113/gtf/homo_sapiens/Homo_sapiens.GRCh38.113.gtf.gz -O  $unprocessed_property_data_location/Homo_sapiens.GRCh38.113.gtf.gz\n",
    "!gunzip $unprocessed_property_data_location/Homo_sapiens.GRCh38.113.gtf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a74729",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_records = []\n",
    "for record in SeqIO.parse(unprocessed_property_data_location + \"Homo_sapiens.GRCh38.ncrna.fa\", \"fasta\"):\n",
    "    desc = record.description\n",
    "    # Safely retrieve description\n",
    "    if \"description:\" in desc:\n",
    "        part_desc = desc.split(\"description:\", 1)[1]\n",
    "        if \" [Source\" in part_desc:\n",
    "            description = part_desc.split(\" [Source\", 1)[0]\n",
    "        else:\n",
    "            description = part_desc\n",
    "    else:\n",
    "        description = \"\"\n",
    "\n",
    "    # Safely retrieve transcript biotype\n",
    "    if \"transcript_biotype:\" in desc:\n",
    "        part_type = desc.split(\"transcript_biotype:\", 1)[1]\n",
    "        if \" gene_symbol:\" in part_type:\n",
    "            rna_type = part_type.split(\" gene_symbol:\", 1)[0]\n",
    "        elif \" description:\" in part_type:\n",
    "            rna_type = part_type.split(\" description:\", 1)[0]\n",
    "        else:\n",
    "            rna_type = part_type\n",
    "    else:\n",
    "        rna_type = \"\"\n",
    "\n",
    "    # Safely retrieve transcript biotype\n",
    "    if \"chromosome:GRCh38:\" in desc:\n",
    "        part_type = desc.split(\"chromosome:GRCh38:\", 1)[1]\n",
    "        if \":-1 \" in part_type:\n",
    "            genomic_loc = part_type.split(\":-1 \", 1)[0] + \"-\"\n",
    "        elif \":1 \" in part_type:\n",
    "            genomic_loc = part_type.split(\":1 \", 1)[0] + \"+\"\n",
    "    else:\n",
    "        genomic_loc = \"\"\n",
    "\n",
    "    rna_records.append({\n",
    "        \"ID\": record.id.split(\".\")[0],\n",
    "        \"Sequence\": str(record.seq),\n",
    "        \"Description\": description,\n",
    "        \":TYPE\": rna_type,\n",
    "        \"Genomic_location\": genomic_loc\n",
    "    })\n",
    "\n",
    "for record in SeqIO.parse(unprocessed_property_data_location + \"Homo_sapiens.GRCh38.cdna.all.fa\", \"fasta\"):\n",
    "    desc = record.description\n",
    "    if \"description:\" in desc:\n",
    "        part_desc = desc.split(\"description:\", 1)[1]\n",
    "        if \" [Source\" in part_desc:\n",
    "            description = part_desc.split(\" [Source\", 1)[0]\n",
    "        else:\n",
    "            description = part_desc\n",
    "    else:\n",
    "        description = \"\"\n",
    "\n",
    "    if \"transcript_biotype:\" in desc:\n",
    "        part_type = desc.split(\"transcript_biotype:\", 1)[1]\n",
    "        if \" gene_symbol:\" in part_type:\n",
    "            rna_type = part_type.split(\" gene_symbol:\", 1)[0]\n",
    "        elif \" description:\" in part_type:\n",
    "            rna_type = part_type.split(\" description:\", 1)[0]\n",
    "        else:\n",
    "            rna_type = part_type\n",
    "    else:\n",
    "        rna_type = \"\"\n",
    "\n",
    "    # Safely retrieve transcript biotype\n",
    "    if \"chromosome:GRCh38:\" in desc:\n",
    "        part_type = desc.split(\"chromosome:GRCh38:\", 1)[1]\n",
    "        if \":-1 \" in part_type:\n",
    "            genomic_loc = part_type.split(\":-1 \", 1)[0] + \"-\"\n",
    "        elif \":1 \" in part_type:\n",
    "            genomic_loc = part_type.split(\":1 \", 1)[0] + \"+\"\n",
    "    else:\n",
    "        genomic_loc = \"\"\n",
    "\n",
    "    rna_records.append({\n",
    "        \"ID\": record.id.split(\".\")[0],\n",
    "        \"Sequence\": str(record.seq),\n",
    "        \"Description\": description,\n",
    "        \":TYPE\": rna_type,\n",
    "        \"Genomic_location\": genomic_loc\n",
    "    })\n",
    "\n",
    "rnacentral_map_ensembl = pd.read_csv(processed_data_location + 'RNAcentral_MAP/ensembl.tsv',\n",
    "    sep='\\t', names=['RNAcentral ID', 'DB', 'Ensembl transcript ID', 'Organism', 'RNA category', 'Ensembl Gene ID'])\n",
    "rnacentral_map_human_ensembl = rnacentral_map_ensembl[rnacentral_map_ensembl['Organism'] == 9606].drop(\n",
    "    columns=['Organism', 'DB', 'RNA category'])\n",
    "rnacentral_map_human_ensembl['Ensembl Gene ID'] = rnacentral_map_human_ensembl['Ensembl Gene ID'].str.split('.').str[0]\n",
    "\n",
    "ensembl = pd.DataFrame(rna_records)\n",
    "ensembl['Genomic_location'] = \"chr\" + ensembl['Genomic_location'].astype(str)\n",
    "ensembl['Genomic_location'] = ensembl['Genomic_location'].str.replace(r'^([^:]*:[^:]*):', r'\\1-', regex=True)\n",
    "ensembl['Description'] = ensembl['Description'].str.lower()\n",
    "ensembl['Sequence'] = ensembl['Sequence'].str.upper()\n",
    "\n",
    "ensembl = ensembl[~ensembl['ID'].isin(rnacentral_map_human_ensembl['Ensembl transcript ID'])]\n",
    "canonical_transcripts = pd.read_csv(unprocessed_property_data_location + \"Homo_sapiens.GRCh38.113.canonical.tsv\", sep=\"\\t\", header=None)\n",
    "canonical_transcripts[1] = canonical_transcripts[1].str.split(\".\").str[0]\n",
    "ensembl = ensembl[~ensembl['ID'].isin(canonical_transcripts[1])]\n",
    "\n",
    "ensembl['Sequence'] = ensembl['Sequence'].replace(\"\", np.nan)\n",
    "ensembl['Description'] = ensembl['Description'].replace(\"\", np.nan)\n",
    "ensembl['Genomic_location'] = ensembl['Genomic_location'].replace(\"chr\", np.nan)\n",
    "ensembl['Genomic_location'] = ensembl['Genomic_location'].replace(\"\", np.nan)\n",
    "ensembl[':TYPE'] = ensembl[':TYPE'].replace(\"\", np.nan)\n",
    "ensembl[':TYPE'] = ensembl[':TYPE'].replace(np.nan, \"RNA\")\n",
    "\n",
    "ensembl.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c72bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = pd.read_csv(unprocessed_property_data_location + \"Homo_sapiens.GRCh38.113.gtf\", sep=\"\\t\", comment=\"#\", header=None)\n",
    "gtf = gtf[gtf[2] == \"transcript\"]\n",
    "gtf[\"ID\"] = gtf[8].str.extract(r'transcript_id \"([^\"]+)\"')\n",
    "gtf[\"Label\"] = gtf[8].str.extract(r'transcript_name \"([^\"]+)\"')\n",
    "gtf = gtf[[\"ID\", \"Label\"]]\n",
    "gtf.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1aa128",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl = ensembl.merge(gtf, how='left', on='ID')\n",
    "ensembl['Label'] = ensembl['Label'].replace(\"\", np.nan)\n",
    "ensembl.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_el = ensembl[['ID',':TYPE']].drop_duplicates().copy()\n",
    "ensembl_el.to_pickle(unprocessed_property_data_location + 'ensembl_el.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b542be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_properties = ensembl.groupby('ID').agg({\n",
    "    ':TYPE': set,\n",
    "    'Description': lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan,\n",
    "    'Label': lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan,\n",
    "    'Genomic_location': lambda x: set(x.dropna()) if x.dropna().any() else set(),\n",
    "    'Sequence': lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan\n",
    "}).reset_index()\n",
    "ensembl_properties.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_properties[':TYPE'] = ensembl_properties[':TYPE'].astype(str)\n",
    "ensembl_properties[':TYPE'] = ensembl_properties[':TYPE'].replace('{\\'', '', regex=True)\n",
    "ensembl_properties[':TYPE'] = ensembl_properties[':TYPE'].replace('\\'}', '', regex=True)\n",
    "ensembl_properties[':TYPE'] = ensembl_properties[':TYPE'].replace('\\'', '', regex=True)\n",
    "ensembl_properties[':TYPE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('lncRNA', 'RNA, ncRNA, lncRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('', 'RNA, ncRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('antisense_RNA', 'RNA, ncRNA, antisense_RNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('precursor_RNA', 'RNA, precursor_RNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('guide_RNA', 'RNA, ncRNA, guide_RNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('autocatalytically_spliced_intron',\n",
    "                                                                  'RNA, ncRNA, intron, autocatalytically_spliced_intron')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('RNase_MRP_RNA',  'RNA, ncRNA, enzymatic_RNA, RNase_MRP_RNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('tmRNA', 'RNA, ncRNA, sncRNA, small_regulatory_ncRNA, tmRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('other', 'RNA, ncRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('circRNA', 'RNA, ncRNA, circRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('piRNA', 'RNA, ncRNA, sncRNA, small_regulatory_ncRNA, piRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('miRNA', 'RNA, ncRNA, sncRNA, small_regulatory_ncRNA, miRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('pre_miRNA',\n",
    "                                                                  'RNA, precursor_RNA, ncRNA, sncRNA, small_regulatory_ncRNA, miRNA, pre_miRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('snRNA', 'RNA, ncRNA, sncRNA, snRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('sRNA', 'RNA, ncRNA, sncRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('snoRNA', 'RNA, ncRNA, sncRNA, snoRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('Y_RNA', 'RNA, ncRNA, Y_RNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('scaRNA', 'RNA, ncRNA, sncRNA, snoRNA, scaRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('tRNA', 'RNA, ncRNA, sncRNA, tRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('SRP_RNA', 'RNA, ncRNA, SRP_RNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('ncRNA', 'RNA, ncRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('rRNA', 'RNA, ncRNA, rRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('ribozyme', 'RNA, ncRNA, enzymatic_RNA, ribozyme')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('hammerhead_ribozyme',\n",
    "                                                                  'RNA, ncRNA, enzymatic_RNA, ribozyme, hammerhead_ribozyme')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('RNase_P_RNA', 'RNA, ncRNA, enzymatic_RNA, RNase_P_RNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('vault_RNA', 'RNA, ncRNA, vault_RNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('misc_RNA', 'RNA, ncRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('TEC', 'RNA, ncRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('retained_intron', 'RNA, ncRNA, intron, retained_intron')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('telomerase_RNA', 'RNA, ncRNA, telomerase_RNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('protein_coding', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('TR_J_gene', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('TR_D_gene', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('IG_V_gene', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('IG_C_gene', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('IG_D_gene', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('IG_J_gene', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('TR_C_gene', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('TR_V_gene', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('protein_coding_LoF', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('protein_coding_LoF', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('protein_coding_CDS_not_defined', 'RNA, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('non_stop_decay', 'RNA, mRNA, RNA_decay')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('nonsense_mediated_decay', 'RNA, mRNA, RNA_decay')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('rRNA_pseudogene', 'RNA, ncRNA, rRNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('IG_C_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('processed_transcript', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('processed_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('TR_J_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('IG_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('transcribed_unprocessed_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('unprocessed_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('unitary_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('transcribed_unitary_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('IG_V_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('TR_V_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('translated_processed_pseudogene', 'RNA, RNA_pseudogene, mRNA')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('IG_J_pseudogene', 'RNA, RNA_pseudogene')\n",
    "ensembl_properties[\":TYPE\"] = ensembl_properties[\":TYPE\"].replace('transcribed_processed_pseudogene', 'RNA, RNA_pseudogene')\n",
    "\n",
    "ensembl_properties[\":TYPE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_properties[':ID'] = \"https://www.ensembl.org/Homo_sapiens/Transcript/Summary?t=\" + ensembl_properties['ID'].astype(str)\n",
    "ensembl_properties[':TYPE'] = ensembl_properties[':TYPE'].str.split(\", \").apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "ensembl_properties['Sequence'] = ensembl_properties['Sequence'].str.replace(\"T\",\"U\")\n",
    "ensembl_properties['Genomic_location'] = ensembl_properties['Genomic_location'].apply(lambda x: json.dumps(list(x)))\n",
    "ensembl_properties = ensembl_properties.rename(columns={'ID':'Ensembl_ID'})\n",
    "ensembl_properties['Species'] = 'Homo sapiens'\n",
    "ensembl_properties.to_pickle(unprocessed_property_data_location + 'ensembl.pkl')\n",
    "ensembl_properties.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54919f",
   "metadata": {},
   "source": [
    "* Addgene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "gRNA_gene = pd.read_csv(unprocessed_data_location + 'grna_sequences_addgene.txt', sep='\\t', dtype = {\"Plasmid ID\":str})  \n",
    "gRNA_gene.columns=gRNA_gene.columns.str.rstrip()\n",
    "gRNA_gene = gRNA_gene[gRNA_gene['Target Species'].notna()]\n",
    "gRNA_gene = gRNA_gene[gRNA_gene['Target Species'].str.contains('apiens')]\n",
    "gRNA_gene = gRNA_gene[~gRNA_gene['Plasmid ID'].isna()]\n",
    "gRNA_gene['Plasmid ID'] = 'www.addgene.org/'+gRNA_gene['Plasmid ID'].astype(str).str.rstrip()\n",
    "gRNA_gene['Target Gene'] = gRNA_gene['Target Gene'].str.upper().astype(str).str.rstrip()\n",
    "gRNA_gene.drop(columns=['Target Species','Depositor'],inplace=True)\n",
    "gRNA_gene['Cas9 Species'] = gRNA_gene['Cas9 Species'].str.strip()\n",
    "\n",
    "gRNA_gene['Target Sequence'] = gRNA_gene['Target Sequence'].str.replace(' $', '', regex=True)\n",
    "gRNA_gene['Target Sequence'] = gRNA_gene['Target Sequence'].str.replace('gRNA1: ', '')\n",
    "gRNA_gene['Target Sequence'] = gRNA_gene['Target Sequence'].str.replace('gRNA1:', '')\n",
    "gRNA_gene['Target Sequence'] = gRNA_gene['Target Sequence'].str.replace(', gRNA2', '|')\n",
    "gRNA_gene['Target Sequence'] = gRNA_gene['Target Sequence'].str.replace(r'; gRNA2:\\s*', ', ', regex=True)\n",
    "gRNA_gene['Target Sequence'] = gRNA_gene['Target Sequence'].str.split(\", \")\n",
    "gRNA_gene = gRNA_gene.explode('Target Sequence')\n",
    "\n",
    "gRNA_gene = gRNA_gene.groupby(['Plasmid ID']).agg({'Cas9 Species': 'first', 'Target Sequence':'first'}).reset_index()\n",
    "gRNA_gene[':TYPE'] = 'RNA, ncRNA, gRNA'\n",
    "gRNA_gene[':ID'] = 'https://' + gRNA_gene['Plasmid ID']\n",
    "gRNA_gene['Plasmid ID'] = gRNA_gene['Plasmid ID'].str.replace(\"www.addgene.org/\", \"\")\n",
    "gRNA_gene['Target Sequence'] = gRNA_gene['Target Sequence'].str.replace(\"T\", \"U\")\n",
    "gRNA_gene.rename(columns={'Plasmid ID':'Addgene_ID','Cas9 Species':'Species','Target Sequence':'Sequence'},inplace=True)\n",
    "gRNA_gene = gRNA_gene.drop_duplicates(subset=[':ID'],keep='first')\n",
    "gRNA_gene[':TYPE'] = gRNA_gene[':TYPE'].str.split(\", \").apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "gRNA_gene.to_pickle(unprocessed_property_data_location + 'addgene.pkl')\n",
    "gRNA_gene.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baac61ff",
   "metadata": {},
   "source": [
    "* [The MIT/ICBP siRNA Database](http://web.mit.edu/sirna/index.html) <br /> The MIT/ICBP siRNA Database has validated siRNA and shRNA sequences against over 100 genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c11713",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICBP = pd.read_html('http://web.mit.edu/sirna/sirnas-gene.html') # siRNA\n",
    "ICBP = ICBP[1]\n",
    "ICBP.columns = ICBP.iloc[[0]].squeeze()\n",
    "ICBP.drop(0, inplace=True)\n",
    "ICBP[['ID#']] = ICBP[['ID#']] + '.html'\n",
    "ICBP.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sirna_data(ICBPsiRNA):\n",
    "    \"\"\"\n",
    "    Processes a DataFrame of sirna data, fetches, extracts and processes information for each sirna ID.\n",
    "    \"\"\"\n",
    "    # Initialize an empty DataFrame to hold the results\n",
    "    property_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each unique sirna_id\n",
    "    for sirna_id in ICBPsiRNA['ID#'].unique():\n",
    "        \n",
    "        url = 'http://web.mit.edu/sirna/sequences/results-' + sirna_id\n",
    "        \n",
    "        # Read the HTML content and extract the table using pandas\n",
    "        ICBP = pd.read_html(url)\n",
    "        df = ICBP[1]\n",
    "        df = df.T  # Transpose the dataframe\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.rename(columns={3:'Sequence'}, inplace=True)\n",
    "        df=df[['Sequence']]\n",
    "\n",
    "        # Extract specific information from the columns using regex\n",
    "        df['Sequence'] = df['Sequence'].str.extract(r'Sense sequence: (.*)')\n",
    "\n",
    "        # Fill NaN values with empty strings\n",
    "        df['Sequence'] = df['Sequence'].fillna('')  \n",
    "\n",
    "        # Combine relevant rows into one DataFrame for a clean representation\n",
    "        df_combined = pd.DataFrame({\n",
    "            'Sequence': df.iloc[0]['Sequence']\n",
    "        }, index=[0])\n",
    "        df_combined['ID'] = sirna_id\n",
    "        property_df = pd.concat([property_df, df_combined], ignore_index=True)\n",
    "\n",
    "    # Return the final DataFrame containing all the processed data\n",
    "    return property_df\n",
    "\n",
    "ICBPsiRNA = ICBP.loc[(ICBP['siRNA'] == 'x') & (ICBP['Human'] == 'x')]\n",
    "sirna = process_sirna_data(ICBPsiRNA)\n",
    "sirna[':TYPE'] = \"RNA, ncRNA, sncRNA, small_regulatory_ncRNA, siRNA\"\n",
    "sirna.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2750893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_shrna_data(ICBPsiRNA):\n",
    "    # Initialize an empty DataFrame to hold the results\n",
    "    property_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each unique sirna_id\n",
    "    for sirna_id in ICBPsiRNA['ID#'].unique():\n",
    "        \n",
    "        url = 'http://web.mit.edu/sirna/sequences/results-' +sirna_id\n",
    "        \n",
    "        # Read the HTML content and extract the table using pandas\n",
    "        ICBP = pd.read_html(url)\n",
    "        #print(url)\n",
    "        df = ICBP[1]\n",
    "        df = df.T  # Transpose the dataframe\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.rename(columns={3:'Sequence'}, inplace=True)\n",
    "        df=df[[\"Sequence\"]]\n",
    "\n",
    "        # Extract specific information from the columns using regex\n",
    "        df['Sequence'] = df['Sequence'].str.extract(r'Sequence: (.*)')\n",
    "        df['Sequence'] = df['Sequence'].str.replace(\" \", \"\")\n",
    "        df['Sequence'] = df['Sequence'].fillna('')  \n",
    "\n",
    "        # Combine relevant rows into one DataFrame for a clean representation\n",
    "        df_combined = pd.DataFrame({\n",
    "            'Sequence': df.iloc[0]['Sequence']\n",
    "        }, index=[0])\n",
    "        df_combined['ID'] = sirna_id\n",
    "        property_df = pd.concat([property_df, df_combined])\n",
    "\n",
    "    return property_df\n",
    "\n",
    "ICBPshRNA = ICBP.loc[(ICBP['shRNA'] == 'x') & (ICBP['Human'] == 'x')] # shRNA\n",
    "shrna = process_shrna_data(ICBPshRNA)\n",
    "shrna[':TYPE'] = \"RNA, ncRNA, sncRNA, small_regulatory_ncRNA, shRNA\"\n",
    "shrna.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8182b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "icbp = pd.concat([sirna,shrna])\n",
    "icbp['Sequence'] = icbp['Sequence'].str.replace(\"T\", \"U\")\n",
    "icbp[':ID'] = \"http://web.mit.edu/sirna/sequences/results-\" + icbp['ID']\n",
    "icbp['ICBP_ID'] = icbp['ID'].str.replace(\".html\", \"\")\n",
    "icbp = icbp.drop_duplicates(subset=[':ID'],keep='first')\n",
    "icbp.drop(columns=['ID'],inplace=True)\n",
    "icbp[':TYPE'] = icbp[':TYPE'].str.split(\", \").apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "icbp.to_pickle(unprocessed_property_data_location + 'icbp.pkl')\n",
    "icbp.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf494085",
   "metadata": {},
   "source": [
    "* circBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3025f7d",
   "metadata": {},
   "source": [
    "First, we convert hg19 genomic coordinates to hg38 using:\n",
    "https://genome.ucsc.edu/cgi-bin/hgLiftOver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "circbase = pd.read_csv(unprocessed_data_location + 'hsa_hg19_circRNA.txt', sep='\\t')\n",
    "circbase_gen = circbase[['# chrom','start','end']]\n",
    "circbase_gen['Genomic_coordinates'] = circbase_gen['# chrom'].astype(str) + \":\" + circbase_gen['start'].astype(str) + \"-\" + circbase_gen['end'].astype(str)\n",
    "pd.DataFrame(circbase_gen['Genomic_coordinates']).to_csv(unprocessed_property_data_location + 'circbase_genomic_coordinateshg19.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41cd3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove convertion errors\n",
    "circbase_gen_err = pd.read_csv(unprocessed_property_data_location + 'hglft_genome_2e13fc_68d250.err', header=None, comment='#')\n",
    "circbase_gen = circbase_gen[['Genomic_coordinates']]\n",
    "circbase_gen = circbase_gen[~circbase_gen['Genomic_coordinates'].isin(circbase_gen_err[0])].reset_index(drop=True)\n",
    "\n",
    "circbase_gen38 = pd.read_csv(unprocessed_property_data_location + 'hglft_genome_2e13fc_68d250.bed', header=None)\n",
    "circbase_gen38 = pd.concat([circbase_gen38, circbase_gen], axis=1).rename(columns={0:'Genomic_location', 'Genomic_coordinates':'Genomic_location_hg19'})\n",
    "circbase_gen38.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a85ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "circbase = pd.read_csv(unprocessed_data_location + 'hsa_hg19_circRNA.txt', sep='\\t')\n",
    "\n",
    "def fetch_sequence(db, chrom, start, end):\n",
    "    base_url = \"http://genome.ucsc.edu/cgi-bin/das\"\n",
    "    url = f\"{base_url}/{db}/dna?segment={chrom}:{start},{end}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        xml_root = ET.fromstring(response.content)\n",
    "        dna_sequence = \"\".join(xml_root.find(\".//DNA\").text.splitlines())\n",
    "        return dna_sequence.upper().replace(\" \", \"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching sequence for {chrom}:{start}-{end}: {e}\")\n",
    "        return None\n",
    "\n",
    "# We can retrieve the full sequence only for circRNAs we know the spliced seq is the same as the genomic seq.\n",
    "# Without this filter, we would retrieve the full genomic sequence (DNA --> gene level) for all circRNAs. \n",
    "circbase['Genomic_location_hg19'] = circbase['# chrom'].astype(str) + \":\" + circbase['start'].astype(str) + \"-\" + circbase['end'].astype(str)\n",
    "circbase = pd.merge(circbase, circbase_gen38, left_on='Genomic_location_hg19', right_on='Genomic_location_hg19', how='left').drop(\n",
    "    columns=['Genomic_location_hg19', '# chrom','start','end'])\n",
    "\n",
    "circbase_seq = circbase[circbase['genomic length'] == circbase['spliced seq length']]\n",
    "circbase_seq['# chrom'] = circbase_seq['Genomic_location'].str.split(\":\").str[0]\n",
    "circbase_seq['start'] = circbase_seq['Genomic_location'].str.split(\":\").str[1].str.split(\"-\").str[0]\n",
    "circbase_seq['end'] = circbase_seq['Genomic_location'].str.split(\":\").str[1].str.split(\"-\").str[1]\n",
    "circbase_seq = circbase_seq[['Genomic_location','# chrom','start','end']].reset_index(drop=True)\n",
    "circbase_seq['Sequence'] = circbase_seq.apply(lambda x: fetch_sequence(\"hg38\", x['# chrom'], x['start'], x['end']), axis=1)\n",
    "circbase_seq.to_csv(unprocessed_property_data_location + 'circbase_seq.csv', index=False)\n",
    "#circbase_seq = pd.read_csv(unprocessed_property_data_location + 'circbase_seq.csv')\n",
    "circbase_seq.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "circbase_seq = pd.read_csv(unprocessed_property_data_location + 'circbase_seq.csv')\n",
    "circbase_seq.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6612cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "circbase['Genomic_location'] = circbase['# chrom'].astype(str) + \":\" + circbase['start'].astype(str) + \"-\" +\\\n",
    "    circbase['end'].astype(str) + circbase['strand'].astype(str)\n",
    "circbase = pd.merge(circbase, circbase_seq, on=['Genomic_location'], how='left')\n",
    "circbase = circbase.rename(columns={'circRNA ID':'circBase_ID'})\n",
    "circbase['Label'] = circbase['circBase_ID']\n",
    "circbase[':ID'] = \"http://circbase.org/cgi-bin/singlerecord.cgi?id=\" + circbase['circBase_ID']\n",
    "\n",
    "circbase = circbase.groupby(':ID').agg({\n",
    "    'circBase_ID': lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan,\n",
    "    'Label': lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan,\n",
    "    'Genomic_location': lambda x: set(x.dropna()) if x.dropna().any() else set(),\n",
    "    'Sequence': lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan\n",
    "}).reset_index()\n",
    "\n",
    "circbase[':TYPE'] = 'RNA, ncRNA, circRNA'\n",
    "circbase[':TYPE'] = circbase[':TYPE'].str.split(\", \").apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "circbase['Sequence'] = circbase['Sequence'].astype(str).str.replace('T','U')\n",
    "circbase['Sequence'] = circbase['Sequence'].replace('nan',np.nan)\n",
    "circbase['Genomic_location'] = circbase['Genomic_location'].apply(lambda x: json.dumps(list(x)))\n",
    "circbase['Species'] = 'Homo sapiens'\n",
    "circbase.to_pickle(unprocessed_property_data_location + 'circbase.pkl')\n",
    "circbase.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cb1ca4",
   "metadata": {},
   "source": [
    "* [eSkip-Finder](https://eskip-finder.org/cgi-bin/input.cgi) <br /> eSkip-Finder is the first machine learning-based design tool and database of antisense oligonucleotides (ASOs) for exon skipping. A significant challenge, however, is the difficulty in selecting an optimal target sequence for exon skipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfaa30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://eskip-finder.org/ --> Search the Database --> Search 'All' on Species=human\n",
    "ASO_mRNA = pd.read_html(unprocessed_data_location + 'eSkip-Finder.html')[2]\n",
    "ASO_mRNA = ASO_mRNA[ASO_mRNA['Species'] == 'human']\n",
    "ASO_mRNA = ASO_mRNA[ASO_mRNA['Oligo name in literature'] != 'Null']\n",
    "ASO_mRNA = ASO_mRNA[['Oligo name in literature','Oligo sequence /: Cocktail. -: weasel (connected).', 'Oligo chemistry']]\n",
    "print(ASO_mRNA['Oligo chemistry'].unique())\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('unspecified', 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('unspecified', 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('unspecified', 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('unspecified', 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('Others (unspecified)', 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('Others (tc-DNA)', 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace(\"Others (mixed 2'OMe, F, and stereochemistry)\", 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('Others (mixed (see Appendix))', 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace(\"Others (2'-OMePS conjugated to cyclic peptide)\",  'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('Others (2FPS)', 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace(\"Others (2'-MOE)\", 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace(\"Others (LNA with phosphodiester linkage)\", 'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('Null',  'nan')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].str.replace('2MOE', '2OMOE')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].str.replace(' (PPMO)', '')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].str.replace('mofified', 'modified')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].str.replace(' (BPMO)', '')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('unmodified PMO', 'PMO, unmodified PMO')\n",
    "ASO_mRNA['Oligo chemistry'] = ASO_mRNA['Oligo chemistry'].replace('modified PMO', 'PMO, modified PMO')\n",
    "print(ASO_mRNA['Oligo chemistry'].unique())\n",
    "ASO_mRNA[':TYPE'] = 'RNA, ncRNA, sncRNA, oligo, antisense_oligonucleotide, RNA_antisense_oligonucleotide, ' +\\\n",
    "    ASO_mRNA['Oligo chemistry'].str.replace(', nan', '')\n",
    "ASO_mRNA[':TYPE'] = ASO_mRNA[':TYPE'].str.split(\", \").apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "ASO_mRNA['Oligo sequence /: Cocktail. -: weasel (connected).'] = \\\n",
    "    ASO_mRNA['Oligo sequence /: Cocktail. -: weasel (connected).'].astype(str).str.replace(\"T\",'U')\n",
    "ASO_mRNA[':ID'] = 'https://eskip-finder.org/cgi-bin/input.cgi?' + ASO_mRNA['Oligo name in literature'].str.replace(r'\\s+', '_', regex=True)\n",
    "ASO_mRNA = ASO_mRNA.rename(columns={'Oligo sequence /: Cocktail. -: weasel (connected).':'Sequence','Oligo name in literature':'Label'})\n",
    "ASO_mRNA = ASO_mRNA[[':ID','Label',':TYPE','Sequence']].drop_duplicates(subset=[':ID'],keep='first')\n",
    "ASO_mRNA.to_pickle(unprocessed_property_data_location + 'eskipFinder.pkl')\n",
    "ASO_mRNA.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbef64b6",
   "metadata": {},
   "source": [
    "* tsRFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa872aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsRNA = pd.read_csv(unprocessed_data_location + 'newID_20210202.txt', sep=\"\\t\")[['type','seq','tsRNAid']]\n",
    "tsRNA[':TYPE'] = [[\"RNA\", \"ncRNA\", \"sncRNA\", \"tsRNA\", \"tRF\"]] * len(tsRNA)\n",
    "print(tsRNA['type'].unique())\n",
    "tsRNA[':TYPE'] = tsRNA.apply(lambda row: row[':TYPE'] + [row['type']], axis=1)\n",
    "tsRNA[':TYPE'] = tsRNA[':TYPE'].apply(json.dumps)\n",
    "tsRNA['seq'] = tsRNA['seq'].str.replace(\"T\",\"U\")\n",
    "tsRNA = tsRNA.rename(columns={'seq':'Sequence', 'tsRNAid':'tsRFun_ID'}).drop(columns=['type'])\n",
    "tsRNA[':ID'] = 'http://biomed.nscc-gz.cn/DB/tsRFun/searchDetail-tsRNA.php?tsRNAid=' + tsRNA['tsRFun_ID']\n",
    "tsRNA = tsRNA.drop_duplicates(subset=[':ID'],keep='first')\n",
    "tsRNA['Species'] = 'Homo sapiens'\n",
    "tsRNA.to_pickle(unprocessed_property_data_location + 'tsrfun.pkl')\n",
    "tsRNA.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457a07d",
   "metadata": {},
   "source": [
    "* tRFdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a49c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://genome.bioch.virginia.edu/trfdb/index.php\n",
    "tRF1_tRNA = pd.read_html(unprocessed_data_location+'trf1.html')[2]\n",
    "tRF1_tRNA.drop(columns=['Organism'],inplace=True)\n",
    "tRF1_tRNA.head()\n",
    "\n",
    "tRF3_tRNA = pd.read_html(unprocessed_data_location+'trf3.html')[2]\n",
    "tRF3_tRNA.drop(columns=['Organism'],inplace=True)\n",
    "\n",
    "tRF5_tRNA = pd.read_html(unprocessed_data_location+'trf5.html')[2]\n",
    "tRF5_tRNA.drop(columns=['Organism'],inplace=True)\n",
    "\n",
    "tRF_tRNA = pd.concat([tRF1_tRNA,tRF3_tRNA,tRF5_tRNA])\n",
    "tRF_tRNA = tRF_tRNA.drop(columns=['Experiment Info', 'Sequence'])\n",
    "tRF_tRNA['tRF ID'] = tRF_tRNA['tRF ID'].astype(str)\n",
    "tRF_tRNA.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_numbers(identifier):\n",
    "    \n",
    "    html_file_path = unprocessed_data_location + 'trf' + identifier + '.html'\n",
    "\n",
    "    with open(html_file_path, 'r', encoding='utf-8') as html_file:\n",
    "        html_content = html_file.read()\n",
    "\n",
    "    pattern = r'href=\\'sequence_display.php\\?seq_id=(\\d+)'\n",
    "    matches = re.findall(pattern, html_content)\n",
    "    numbers = [int(match) for match in matches]\n",
    "\n",
    "    pattern2 = r\"href='experiments_display.php\\?trf_id=(.*?)'\"\n",
    "    matches2 = re.findall(pattern2, html_content)\n",
    "    \n",
    "    # Return the numbers as a dictionary\n",
    "    return {'sequence_numbers': numbers, 'experiment_numbers': matches2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(original_html):\n",
    "\n",
    "    transformed_html = re.sub(r'<font face=', '\\n<font face=', original_html)\n",
    "    transformed_html = re.sub(r'<br><b>Organism:', \"</font><br>\\n<font face='Arial' size='2'><b>Organism:\", transformed_html)\n",
    "    transformed_html = re.sub(r'<br><b>tRF Sequence:', \"</font><br>\\n<font face='Arial' size='2'><b>tRF Sequence:\", transformed_html)\n",
    "    transformed_html = re.sub(r\"<font face='Courier' size='3'>\", \"</font><br>\\n<font face='Arial' size='2'>\", transformed_html)\n",
    "    transformed_html = re.sub(r\"<br><b>Map Position:\", \"\\n<font face='Arial' size='2'><b>Map Position:\", transformed_html)\n",
    "\n",
    "    return transformed_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9cd07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_html(identifier):\n",
    "    url = 'http://genome.bioch.virginia.edu/trfdb/sequence_display.php?seq_id=' + identifier\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 500:\n",
    "        html_content = response.text\n",
    "        return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "df = pd.DataFrame()\n",
    "result = get_numbers('1')\n",
    "numbers_mapping = dict(zip(result['sequence_numbers'], result['experiment_numbers']))\n",
    "\n",
    "for i in result['sequence_numbers'] :\n",
    "    \n",
    "    html_content = get_html(str(i))  # Retrieve HTML content\n",
    "    if html_content is not None:\n",
    "        # Apply the transformation to the HTML content\n",
    "        transformed_html = transform(html_content)\n",
    "\n",
    "        # Continue with parsing and DataFrame creation\n",
    "        soup = BeautifulSoup(transformed_html, 'html.parser')\n",
    "        values = [font.get_text() for font in soup.find_all('font')]\n",
    "        values = [value.split(\":\")[1].strip() if \":\" in value else value for value in values]\n",
    "        \n",
    "        corresponding_experiment_number = numbers_mapping.get(i, None)\n",
    "\n",
    "        # Create a DataFrame for the current HTML page\n",
    "        temp = pd.DataFrame(values).T\n",
    "        temp.columns = range(temp.shape[1])\n",
    "\n",
    "        # Add the 'Experiment Number' column\n",
    "        temp['Experiment Number'] = corresponding_experiment_number\n",
    "\n",
    "        # Concatenate the current DataFrame with the main DataFrame\n",
    "        df = pd.concat([df, temp], ignore_index=True)\n",
    " \n",
    "result = get_numbers('3')\n",
    "numbers_mapping = dict(zip(result['sequence_numbers'], result['experiment_numbers']))\n",
    "\n",
    "for i in result['sequence_numbers'] :\n",
    "    \n",
    "    html_content = get_html(str(i))  # Retrieve HTML content\n",
    "    if html_content is not None:\n",
    "        # Apply the transformation to the HTML content\n",
    "        transformed_html = transform(html_content)\n",
    "\n",
    "        # Continue with parsing and DataFrame creation\n",
    "        soup = BeautifulSoup(transformed_html, 'html.parser')\n",
    "        values = [font.get_text() for font in soup.find_all('font')]\n",
    "        values = [value.split(\":\")[1].strip() if \":\" in value else value for value in values]\n",
    "        \n",
    "        corresponding_experiment_number = numbers_mapping.get(i, None)\n",
    "\n",
    "        # Create a DataFrame for the current HTML page\n",
    "        temp = pd.DataFrame(values).T\n",
    "        temp.columns = range(temp.shape[1])\n",
    "\n",
    "        # Add the 'Experiment Number' column\n",
    "        temp['Experiment Number'] = corresponding_experiment_number\n",
    "\n",
    "        # Concatenate the current DataFrame with the main DataFrame\n",
    "        df = pd.concat([df, temp], ignore_index=True)\n",
    "\n",
    "result = get_numbers('5')\n",
    "numbers_mapping = dict(zip(result['sequence_numbers'], result['experiment_numbers']))\n",
    "\n",
    "for i in result['sequence_numbers'] :\n",
    "    \n",
    "    html_content = get_html(str(i))  # Retrieve HTML content\n",
    "    if html_content is not None:\n",
    "        # Apply the transformation to the HTML content\n",
    "        transformed_html = transform(html_content)\n",
    "\n",
    "        # Continue with parsing and DataFrame creation\n",
    "        soup = BeautifulSoup(transformed_html, 'html.parser')\n",
    "        values = [font.get_text() for font in soup.find_all('font')]\n",
    "        values = [value.split(\":\")[1].strip() if \":\" in value else value for value in values]\n",
    "        \n",
    "        corresponding_experiment_number = numbers_mapping.get(i, None)\n",
    "\n",
    "        # Create a DataFrame for the current HTML page\n",
    "        temp = pd.DataFrame(values).T\n",
    "        temp.columns = range(temp.shape[1])\n",
    "\n",
    "        # Add the 'Experiment Number' column\n",
    "        temp['Experiment Number'] = corresponding_experiment_number\n",
    "\n",
    "        # Concatenate the current DataFrame with the main DataFrame\n",
    "        df = pd.concat([df, temp], ignore_index=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chr_substring(text):\n",
    "    start_index = text.find('chr')\n",
    "    if start_index != -1:\n",
    "        end_index = text.find('&', start_index)\n",
    "        if end_index != -1:\n",
    "            return text[start_index:end_index]\n",
    "    return ''\n",
    "\n",
    "#df['Experiment Number'] = df['Experiment Number'].apply(extract_chr_substring)\n",
    "df.columns = ['tRF ID','organism','empty','Sequence','Map Position','tRNA Gene Co-ordinates']\n",
    "df = df.drop(columns=['organism','empty'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tRF = pd.merge(tRF_tRNA,df,on=['tRF ID', 'tRNA Gene Co-ordinates'])\n",
    "tRF['tRF ID'] = \"trfdb?\" + tRF['tRF ID'].astype(str)\n",
    "tRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tRF.drop_duplicates().to_csv(properties_location + 'tRF_tRFdb.csv', index=None)\n",
    "tRF = pd.read_csv(unprocessed_property_data_location + 'tRF_tRFdb.csv')\n",
    "print(tRF.Type.unique())\n",
    "tRF['tRNA Gene Co-ordinates'] = tRF['tRNA Gene Co-ordinates'].str.split(\"-\")\n",
    "tRF['Chromosome'] = tRF['tRNA Gene Co-ordinates'].str[0]\n",
    "tRF['Map Position'] = tRF['Map Position'].str.split(\"-\")\n",
    "tRF['Start'] = tRF['tRNA Gene Co-ordinates'].str[1].astype(int) + tRF['Map Position'].str[0].astype(int)\n",
    "tRF['End'] = tRF['tRNA Gene Co-ordinates'].str[2].astype(int) + tRF['Map Position'].str[1].astype(int)\n",
    "tRF['Genomic_location'] = tRF['Chromosome'] + \":\" + tRF['Start'].astype(str) + \"-\" + tRF['End'].astype(str)\n",
    "tRF.Type = tRF.Type.str.replace('trf', 'tRF')\n",
    "tRF[':TYPE'] = [[\"RNA\", \"ncRNA\", \"sncRNA\", \"tsRNA\", \"tRF\"]] * len(tRF)\n",
    "tRF[':TYPE'] = tRF.apply(lambda row: row[':TYPE'] + [row['Type']], axis=1)\n",
    "tRF = tRF.explode(':TYPE')\n",
    "tRF['Sequence'] = tRF['Sequence'].str.replace(\"T\",\"U\")\n",
    "tRF = tRF.groupby(['tRF ID']).agg({'Sequence':'first', ':TYPE':set, \"Genomic_location\":lambda x: set(x.dropna()) if x.dropna().any() else set()}).reset_index()\n",
    "tRF['Species'] = 'Homo sapiens'\n",
    "tRF[':ID'] = \"http://genome.bioch.virginia.edu/trfdb/experiments_display.php?\" + tRF['tRF ID']\n",
    "tRF['tRF_ID'] = tRF['tRF ID'].str.replace(\"trfdb?\",\"\")\n",
    "tRF[':TYPE'] = tRF[':TYPE'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "tRF = tRF.drop(columns=['tRF ID'])\n",
    "tRF.to_pickle(unprocessed_property_data_location + 'trfdb.pkl')\n",
    "tRF.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7c71a",
   "metadata": {},
   "source": [
    "* MINTBASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74308fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tRNA_MINTbase_GtRNAdb_map=pd.read_csv(\n",
    "    processed_data_location + 'tRNA_MINTbase_GtRNAdb_MAP.txt', header=None, sep='\\t')\n",
    "tRNA_MINTbase_GtRNAdb_map=tRNA_MINTbase_GtRNAdb_map.rename(columns={0:'MINTbase tRNA name',1:'gtRNAdb name'})\n",
    "tRNA_MINTbase_GtRNAdb_map.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cm.jefferson.edu/MINTbase/InputController?g=GRCh37&d=y&v=g&e=1.0&cl=,4,5,11,12,16,18,19,21,22,26,27,#ttop\n",
    "tRF_tRNA2 = pd.read_csv(unprocessed_data_location+'MINTbase.txt',sep='\\t')\n",
    "tRF_tRNA2['MINTbase Alternative IDs (GRCh37 assembly-derived)'] = tRF_tRNA2['MINTbase Alternative IDs (GRCh37 assembly-derived)'].str.split('@').str[0]\n",
    "tRF_tRNA2.rename(columns={'MINTbase Alternative IDs (GRCh37 assembly-derived)':'MINTbase tRNA name'},inplace=True)\n",
    "tRF_tRNA2 = pd.merge(tRF_tRNA2, tRNA_MINTbase_GtRNAdb_map, on='MINTbase tRNA name')\n",
    "print(tRF_tRNA2['Type'].unique())\n",
    "tRF_tRNA2['Type'] = tRF_tRNA2['Type'].str.replace(\"5'-tRF\", \"tRF-5\")\n",
    "tRF_tRNA2['Type'] = tRF_tRNA2['Type'].str.replace(\"3'-tRF\", \"tRF-3\")\n",
    "tRF_tRNA2['Type'] = tRF_tRNA2['Type'].str.replace('i-tRF', 'tRF-i')\n",
    "tRF_tRNA2['Type'] = tRF_tRNA2['Type'].str.replace(\"5'-half\", \"tRF-5, tRF-5-half\")\n",
    "tRF_tRNA2['Type'] = tRF_tRNA2['Type'].str.replace(\"3'-half\", \"tRF-3, tRF-3-half\")\n",
    "tRF_tRNA2[':TYPE'] = 'RNA, ncRNA, sncRNA, tsRNA, tRF, ' + tRF_tRNA2['Type'].astype(str)\n",
    "tRF_tRNA2['Genomic_location'] = \"chr\" + tRF_tRNA2['Chromosome'].astype(str) + \":\" + tRF_tRNA2['Chromosome start position'].astype(str) \\\n",
    "    + \"-\" + tRF_tRNA2['Chromosome end position'].astype(str) + tRF_tRNA2['Chromosome strand'].astype(str)\n",
    "tRF_tRNA2[':TYPE'] = tRF_tRNA2[':TYPE'].str.split(\", \")\n",
    "tRF_tRNA2 = tRF_tRNA2.explode(':TYPE')\n",
    "tRF_tRNA2['Fragment sequence'] = tRF_tRNA2['Fragment sequence'].str.replace(\"T\",\"U\")\n",
    "tRF_tRNA2 = tRF_tRNA2.groupby(['License Plate (sequence derived)']).agg({'Fragment sequence':'first', ':TYPE':set,\n",
    "                                                                         'Genomic_location':lambda x: set(x.dropna())\n",
    "                                                                            if x.dropna().any() else set()}).reset_index()\n",
    "tRF_tRNA2['Species'] = 'Homo sapiens'\n",
    "tRF_tRNA2[':ID'] = \"https://cm.jefferson.edu/MINTbase/InputController?v=g&g=GRCh37&fn=\" + tRF_tRNA2['License Plate (sequence derived)']\n",
    "tRF_tRNA2[':TYPE'] = tRF_tRNA2[':TYPE'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "tRF_tRNA2 = tRF_tRNA2.rename(columns={'License Plate (sequence derived)':'Label','Fragment sequence':'Sequence'})\n",
    "tRF_tRNA2['MINTbase_ID'] = tRF_tRNA2['Label']\n",
    "tRF_tRNA2.to_pickle(unprocessed_property_data_location + 'mintbase.pkl')\n",
    "tRF_tRNA2.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5fcf6c",
   "metadata": {},
   "source": [
    "* TBDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "riboswitch_protein = pd.read_csv(unprocessed_data_location+'tbdb.csv', sep=',') \n",
    "riboswitch_protein['Genomic_location'] = \"chr:\" + riboswitch_protein['locus_start'].astype(str) + \"-\" + riboswitch_protein['locus_end'].astype(str)\n",
    "riboswitch_protein = riboswitch_protein[['accession_url','FASTA_sequence','unique_name','GBSeq_organism',\n",
    "                                         'Genomic_location','Structure','accession_name']].rename(\n",
    "                                             columns={'accession_url':':ID','FASTA_sequence':'Sequence','unique_name':'TBDB_ID',\n",
    "                                                      'GBSeq_organism':'Species','accession_name':'Label'})\n",
    "riboswitch_protein['Sequence'] = riboswitch_protein['Sequence'].str.replace(\"T\",\"U\")\n",
    "riboswitch_protein[':TYPE'] = [[\"RNA\", 'bacterial_RNA', \"ncRNA\", \"riboswitch\", \"T-box_riboswitch\"]] * len(riboswitch_protein)\n",
    "riboswitch_protein = riboswitch_protein.explode(':TYPE')\n",
    "riboswitch_protein = riboswitch_protein.groupby([':ID']).agg({'Sequence':'first','TBDB_ID':'first','Species':'first','Genomic_location':\n",
    "                                                              lambda x: set(x.dropna()) if x.dropna().any() else set(),'Structure':'first',\n",
    "                                                              'Label':'first',':TYPE':set}).reset_index()\n",
    "riboswitch_protein[':TYPE'] = riboswitch_protein[':TYPE'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "riboswitch_protein.to_pickle(unprocessed_property_data_location + 'tbdb.pkl')\n",
    "riboswitch_protein.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fe48c",
   "metadata": {},
   "source": [
    "* RSwitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e3fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "riboswitch_bactStrain = pd.read_csv(unprocessed_data_location + 'rswitch.csv', header=None) \n",
    "riboswitch_bactStrain.rename(columns={0:'ID', 1:':TYPE', 2:'Species'},inplace=True)\n",
    "print(riboswitch_bactStrain[':TYPE'].unique())\n",
    "riboswitch_bactStrain[':TYPE'] = riboswitch_bactStrain[':TYPE'].str.replace('Sitemap:', 'nan')\n",
    "riboswitch_bactStrain[':TYPE'] = riboswitch_bactStrain[':TYPE'].fillna('nan')\n",
    "riboswitch_bactStrain[':TYPE'] = \"RNA, bacterial_RNA, ncRNA, riboswitch, \" + riboswitch_bactStrain[':TYPE'].astype(str).str.replace(\" \", \"_\")\n",
    "riboswitch_bactStrain[':TYPE'] = riboswitch_bactStrain[':TYPE'].str.replace(', nan', '')\n",
    "riboswitch_bactStrain[':ID'] = \"https://penchovsky.atwebpages.com/applications.php?page=58?\" + riboswitch_bactStrain['ID']\n",
    "riboswitch_bactStrain[':TYPE'] = riboswitch_bactStrain[':TYPE'].str.split(\", \")\n",
    "riboswitch_bactStrain = riboswitch_bactStrain.explode(':TYPE')\n",
    "riboswitch_bactStrain = riboswitch_bactStrain.groupby([':ID']).agg({'ID':'first','Species':'first',':TYPE':set}).reset_index()\n",
    "riboswitch_bactStrain[':TYPE'] = riboswitch_bactStrain[':TYPE'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "riboswitch_bactStrain.to_pickle(unprocessed_property_data_location + 'rswitch.pkl')\n",
    "riboswitch_bactStrain.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a409a7",
   "metadata": {},
   "source": [
    "* Apta-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa81552",
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_protein = pd.read_csv(unprocessed_data_location + 'aptaindex.csv',names=['Label', 'ID', 'Target', 'Sequence'],skiprows=[0]) \n",
    "aptamer_protein.Target = aptamer_protein.Target.str.lower()\n",
    "aptamer_protein['ID'] = 'aptamer-details/?id=' + aptamer_protein['ID'].astype(str)\n",
    "aptamer_protein = aptamer_protein.drop(columns=['Target'])\n",
    "aptamer_protein = aptamer_protein[['ID','Sequence']]\n",
    "aptamer_protein['Sequence'] = aptamer_protein['Sequence'].str.replace('[^ATCGU]', '', regex=True)\n",
    "aptamer_protein['Sequence'] = aptamer_protein['Sequence'].str.replace('T', 'U')\n",
    "aptamer_protein['Sequence'] = aptamer_protein['Sequence'].fillna('nan')\n",
    "aptamer_protein['Sequence'] = aptamer_protein['Sequence'].replace('', 'nan', regex=True)\n",
    "aptamer_protein[':TYPE'] = [[\"RNA\", \"ncRNA\", \"sncRNA\", 'oligo', \"aptamer\", \"RNA_aptamer\"]] * len(aptamer_protein)\n",
    "aptamer_protein = aptamer_protein.explode(':TYPE')\n",
    "aptamer_protein = aptamer_protein.groupby(['ID']).agg({'Sequence':lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan, ':TYPE':set}).reset_index()\n",
    "aptamer_protein[':TYPE'] = aptamer_protein[':TYPE'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "aptamer_protein[':ID'] = \"https://www.aptagen.com/\" + aptamer_protein['ID']\n",
    "aptamer_protein['Apta-Index_ID'] = aptamer_protein['ID'].str.replace(\"aptamer-details/?id=\",\"\")\n",
    "aptamer_protein.drop(columns=['ID'],inplace=True)\n",
    "aptamer_protein.to_pickle(unprocessed_property_data_location + 'aptaindex.pkl')\n",
    "aptamer_protein.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639ba11",
   "metadata": {},
   "source": [
    "* snoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ad33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "snoDB = pd.read_csv(unprocessed_data_location + 'download_all', sep=\"\\t\")\n",
    "snoDB = snoDB[['rna_central_id','host_gene_id','rrna_targets','snrna_targets','lncrna_targets','protein_coding_targets','snorna_targets',\n",
    "               'mirna_targets','trna_targets','ncrna_targets','pseudogene_targets','other_targets','is_expressed']]\n",
    "snoDB = snoDB[snoDB['rna_central_id'].notna()]\n",
    "snoDB = snoDB.rename(columns={'rna_central_id':':START_ID'})\n",
    "for col in snoDB.columns:\n",
    "    snoDB[col] = snoDB[col].astype(str).str.split(';')\n",
    "for col in snoDB.columns:\n",
    "    snoDB = snoDB.explode(col)\n",
    "\n",
    "snoRNA_rRNA = snoDB[['rrna_targets']].drop_duplicates().rename(columns={'rrna_targets':'Label'})\n",
    "snoRNA_rRNA = snoRNA_rRNA[snoRNA_rRNA['Label'] != 'nan']\n",
    "snoRNA_rRNA['Label'] = snoRNA_rRNA['Label'].str.split('.').str[0].str.strip()\n",
    "snoRNA_rRNA[':TYPE'] = [['RNA', 'ncRNA', 'rRNA']] * len(snoRNA_rRNA)\n",
    "snoRNA_rRNA[':TYPE'] = snoRNA_rRNA[':TYPE'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "snoRNA_rRNA[':ID'] = \"http://scottgroup.med.usherbrooke.ca/snoDB?\" + snoRNA_rRNA['Label']\n",
    "snoRNA_rRNA['Species'] = 'Homo sapiens'\n",
    "snoRNA_rRNA.to_pickle(unprocessed_property_data_location + 'snodb.pkl')\n",
    "snoRNA_rRNA.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba977c2",
   "metadata": {},
   "source": [
    "***\n",
    "# Genome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd0593",
   "metadata": {},
   "source": [
    "* ViroidDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9610bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vRNA_ribozyme = pd.read_json(unprocessed_data_location + 'all.json').T \n",
    "\n",
    "# Extract ribozymes \n",
    "myre = re.compile(r\"\\n>> .*?\\n\")\n",
    "ribozyme = [myre.findall(i) for i in vRNA_ribozyme.ribozymes]\n",
    "ribozyme = [[j.replace(\"\\n\",'').replace(\">> \",'') for j in i] for i in ribozyme]\n",
    "\n",
    "rnacentral_map_rfam = pd.read_csv(processed_data_location + \"RNAcentral_MAP/rfam.tsv\",sep='\\t',\n",
    "                                     names=['RNAcentral ID', 'DB', 'Rfam ID', 'Organism', 'RNA category', \"nan\"]).drop(columns=\"nan\")\n",
    "rnacentral_map_human_rfam = rnacentral_map_rfam[rnacentral_map_rfam['Organism'] == 9606].drop(\n",
    "    columns=['Organism', 'DB', 'RNA category'])\n",
    "\n",
    "vRNA_ribozyme = pd.concat([vRNA_ribozyme.reset_index().drop(columns=['index']), # Genome --> NCBI nuccore \n",
    "                           pd.Series(ribozyme)], axis=1)\n",
    "vRNA_ribozyme = vRNA_ribozyme.explode(0)\n",
    "vRNA_ribozyme[0] = vRNA_ribozyme[0].str.split().str[0]\n",
    "vRNA_ribozyme.drop(columns=['isolationSource','collectionDate','gc','bioSample','identicalSeqs','genBankTitle','displayTitle',\n",
    "                            'length','sequenceType','nucCompleteness','genotype','segment','moleculeType','publications',\n",
    "                           'geoLocation','country','usa','submitters','releaseDate','isolate',\n",
    "                            'sequence','type','Cls_ID80','genus','family','ribozymes',\n",
    "                            'Cls_ID70','Cls_ID85','Cls_ID75','Cls_ID95','Cls_ID90','sraAccession','submitters','host'],\n",
    "                   inplace=True)\n",
    "vRNA_ribozyme.insert(0,1,vRNA_ribozyme.pop(0))\n",
    "vRNA_ribozyme['accession'] = vRNA_ribozyme['accession'].str.split(\".\").str[0]\n",
    "\n",
    "print(vRNA_ribozyme.species.unique()[:3])\n",
    "# Among them, only Hepatitis delta virus (NCBI taxid: 12475) is a human pathogen\n",
    "vRNA_ribozyme = vRNA_ribozyme[vRNA_ribozyme.species == 'Hepatitis delta virus']\n",
    "rnacentral_map_rfam_delta = rnacentral_map_rfam[rnacentral_map_rfam['Organism'] == 12475]\n",
    "ribozyme_rfam_map = pd.read_csv(processed_data_location + 'ribozyme_RFAM_MAP.txt', header=None, sep='\\t')\n",
    "\n",
    "vRNA_ribozyme = pd.merge(ribozyme_rfam_map,vRNA_ribozyme,left_on=0,right_on=1).drop(columns=['1_y'])\n",
    "vRNA_ribozyme = pd.merge(vRNA_ribozyme.rename(columns={'1_x':'Rfam ID'}),rnacentral_map_rfam_delta[['RNAcentral ID','Rfam ID']].drop_duplicates(),\n",
    "                         on='Rfam ID').drop(columns=['Rfam ID',0,'species'])\n",
    "\n",
    "vRNA_ribozyme.rename(columns={'RNAcentral ID':':START_ID','accession':':END_ID', 'structure':'Structure'},inplace=True)\n",
    "vRNA_ribozyme.Structure = vRNA_ribozyme.Structure.astype(str).str.split(\"'minus': {'dbn': '\").str[1].str.split(\"'\").str[0]\n",
    "vRNA_ribozyme['Source'] = 'ViroidDB'\n",
    "vRNA_ribozyme = vRNA_ribozyme[[':END_ID','Structure']].drop_duplicates(subset=[':END_ID'],keep='first').rename(columns={':END_ID':'NCBI_ID'})\n",
    "vRNA_ribozyme[':ID'] = \"https://www.ncbi.nlm.nih.gov/nuccore/\" + vRNA_ribozyme['NCBI_ID']\n",
    "vRNA_ribozyme[':TYPE'] = [['Genome', 'Viral_genome', 'RNA_genome', 'ss-RNA']] * len(vRNA_ribozyme)\n",
    "vRNA_ribozyme['Species'] = \"Hepatitis delta virus\"\n",
    "vRNA_ribozyme['Description'] = \"Hepatitis delta virus, complete genome\"\n",
    "vRNA_ribozyme['Label'] = \"Complete genome \" + vRNA_ribozyme['NCBI_ID']\n",
    "vRNA_ribozyme[':TYPE'] = vRNA_ribozyme[':TYPE'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "vRNA_ribozyme.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd577e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sequence(accession, api_key=None):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "    params = {\n",
    "        \"db\": \"nuccore\",\n",
    "        \"id\": accession,\n",
    "        \"rettype\": \"fasta\",\n",
    "        \"retmode\": \"text\"\n",
    "    }\n",
    "    if api_key:\n",
    "        params[\"api_key\"] = api_key\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "vRNA_ribozyme['Sequence'] = vRNA_ribozyme['NCBI_ID'].apply(lambda acc: fetch_sequence(acc, api_key='8d88dc3d63cd73854f0034baa217b05a9808'))\n",
    "vRNA_ribozyme['Sequence'] = vRNA_ribozyme['Sequence'].str.upper().str.strip().str.split(\"GENOME\").str[1].str.replace(\"T\",\"U\").str.replace(\"\\n\",\"\").str.strip()\n",
    "vRNA_ribozyme['Sequence'] = vRNA_ribozyme['Sequence'].replace(\"nan\",np.nan)\n",
    "vRNA_ribozyme.to_pickle(unprocessed_property_data_location + 'genome.pkl')\n",
    "vRNA_ribozyme.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6a1de9",
   "metadata": {},
   "source": [
    "***\n",
    "## Chemical modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tRNA_mod = pd.read_csv(edge_data_location+'modification-tRNA2314.txt', sep='\\t')[['Modification']].drop_duplicates().dropna()\n",
    "tRNA_mod = tRNA_mod.rename(columns={'Modification':'Label'})\n",
    "tRNA_mod['Modomics_ID'] = tRNA_mod['Label'].str.strip().str.replace(r'\\s+', '_', regex=True)\n",
    "tRNA_mod[':ID'] = \"https://genesilico.pl/modomics?\" + tRNA_mod['Modomics_ID']\n",
    "tRNA_mod[':TYPE'] = [[\"Genomic_feature\", \"Epigenetic_modification\"]] * len(tRNA_mod)\n",
    "tRNA_mod[':TYPE'] = tRNA_mod[':TYPE'].apply(json.dumps)\n",
    "tRNA_mod.to_pickle(unprocessed_property_data_location + 'chemicalModification.pkl')\n",
    "tRNA_mod.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62807e14",
   "metadata": {},
   "source": [
    "***\n",
    "# Biological role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = ['https://www.genome.gov/genetics-glossary/Tumor-Suppressor-Gene', 'https://www.genome.gov/genetics-glossary/Oncogene', 'https://www.genome.gov/genetics-glossary/General']\n",
    "name = ['Tumor-Suppressor-Gene', 'Oncogene', 'General']\n",
    "label = ['Tumor Suppressor Gene', 'Oncogene', 'General']\n",
    "definition = ['A tumor suppressor gene encodes a protein that acts to regulate cell division, keeping it in check. When a tumor suppressor gene is inactivated by a mutation, the protein it encodes is not produced or does not function properly, and as a result, uncontrolled cell division may occur. Such mutations may contribute to the development of a cancer.\\\n",
    "              Tumor Suppressor Gene. Tumor suppressor genes are present in all cells in our body. When they are switched on, they prevent ourselves from growing and dividing. You can think of them as being like the brakes of a car. However, when a tumor suppressor gene is switched off, either because the cell mistakenly deletes it or mutates it, the brake is released and the cell may start to grow and divide uncontrollably and potentially drive the cell to turn into a cancer cell.',\n",
    "              'An oncogene is a mutated gene that has the potential to cause cancer. Before an oncogene becomes mutated, it is called a proto-oncogene, and it plays a role in regulating normal cell division. Cancer can arise when a proto-oncogene is mutated, changing it into an oncogene and causing the cell to divide and multiply uncontrollably. Some oncogenes work like an accelerator pedal in a car, pushing a cell to divide again and again. Others work like a faulty brake in a car parked on a hill, also causing the cell to divide unchecked.\\\n",
    "                Oncogene. The name of oncogene suggests it is a gene that can cause cancer. Initially, oncogenes were identified in viruses, which could cause cancers in animals. Later, it was found that oncogenes can be mutated copies of certain normal cellular genes also called proto-oncogenes. Intact proto-oncogenes play important functions, regulating normal cellular growth, division, and apoptosis, which is the name for programmed or controlled cell death. Oncogenes or mutated copies of the proto-oncogenes may lead to uncontrolled cell growth and the escape from cell death, which may result in cancer development.',\n",
    "              np.nan]\n",
    "role = pd.DataFrame({':ID': id, 'NIH_ID': name, 'Description': definition, 'Label': label}) \n",
    "role[':TYPE'] = [[\"Biological_role\"]] * len(role)\n",
    "role[':TYPE'] = role[':TYPE'].apply(json.dumps)\n",
    "role.to_pickle(unprocessed_property_data_location + 'biologicalRole.pkl')\n",
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd7da0",
   "metadata": {},
   "source": [
    "***\n",
    "# Small protein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22041544",
   "metadata": {},
   "source": [
    "* SmProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "lncRNA_protein = pd.read_csv(unprocessed_data_location + 'sprotein_LncBook2.0.csv.gz') \n",
    "lncRNA_protein['SmProt Protein Sequence'] = lncRNA_protein['SmProt Protein Sequence'].str.replace('*', '', regex=False)\n",
    "lncRNA_protein = lncRNA_protein[['SmProt ID','SmProt Protein Sequence']].rename(columns={'SmProt ID':'SmProt_ID','SmProt Protein Sequence':'Sequence'})\n",
    "lncRNA_protein[':ID'] = \"http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=\" + lncRNA_protein['SmProt_ID']\n",
    "lncRNA_protein = lncRNA_protein.drop_duplicates(subset=[':ID'],keep='first')\n",
    "lncRNA_protein[':TYPE'] = [[\"Protein\", \"Human_protein\", \"Small_protein\"]] * len(lncRNA_protein)\n",
    "lncRNA_protein[':TYPE'] = lncRNA_protein[':TYPE'].apply(json.dumps)\n",
    "lncRNA_protein['Species'] = 'Homo sapiens'\n",
    "lncRNA_protein.to_pickle(unprocessed_property_data_location + 'smprot.pkl')\n",
    "lncRNA_protein.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a594b",
   "metadata": {},
   "source": [
    "* cncRNAdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNA_anatomy = pd.read_excel(unprocessed_data_location + 'Translated ncRNA.xlsx')\n",
    "RNA_anatomy = RNA_anatomy[RNA_anatomy.Organism.str.contains('apiens')]\n",
    "RNA_anatomy = RNA_anatomy[RNA_anatomy['Gene.ID'].notna()]\n",
    "RNA_anatomy = RNA_anatomy[RNA_anatomy.Notes != 'It has been re-annotated as protein coding gene now']\n",
    "RNA_anatomy = RNA_anatomy[['cncRNAdb.ID','Peptide']].rename(columns={'cncRNAdb.ID':'cncRNAdb_ID','Peptide':'Sequence'})\n",
    "RNA_anatomy[':ID'] = \"https://www.rna-society.org/cncrnadb?\" + RNA_anatomy['cncRNAdb_ID']\n",
    "RNA_anatomy = RNA_anatomy.drop_duplicates(subset=[':ID'],keep='first')\n",
    "RNA_anatomy[':TYPE'] = [[\"Protein\", \"Human_protein\", \"Small_protein\"]] * len(RNA_anatomy)\n",
    "RNA_anatomy[':TYPE'] = RNA_anatomy[':TYPE'].apply(json.dumps)\n",
    "RNA_anatomy['Species'] = 'Homo sapiens'\n",
    "RNA_anatomy.to_pickle(unprocessed_property_data_location + 'cncrnadb.pkl')\n",
    "RNA_anatomy.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba31ab4",
   "metadata": {},
   "source": [
    "***\n",
    "# Reactome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e306c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_pathways = pd.read_csv(unprocessed_data_location + 'ReactomePathways.txt', header=None, delimiter='\\t', low_memory=False)\n",
    "reactome_pathways = reactome_pathways.loc[reactome_pathways[2].apply(lambda x: x == 'Homo sapiens')].drop(columns=[2])\n",
    "reactome_pathways[':TYPE'] = [[\"Pathway\"]] * len(reactome_pathways)\n",
    "reactome_pathways[':TYPE'] = reactome_pathways[':TYPE'].apply(json.dumps)\n",
    "reactome_pathways['Species'] = 'Homo sapiens'\n",
    "reactome_pathways[':ID'] = \"https://reactome.org/content/detail/\" + reactome_pathways[0]\n",
    "reactome_pathways = reactome_pathways.rename(columns={0:'Reactome_ID',1:'Label'})\n",
    "reactome_pathways.to_pickle(unprocessed_property_data_location + 'reactome.pkl')\n",
    "reactome_pathways.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13e68c0",
   "metadata": {},
   "source": [
    "***\n",
    "# Wikipathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852cc8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "with open(unprocessed_data_location+'wpw_reactome.csv', 'r') as file:\n",
    "    data = file.read().rstrip()\n",
    "    \n",
    "desc_wpw_map = pd.DataFrame([ ln.rstrip().split('\\t') for ln in\n",
    "    io.StringIO(data).readlines() ]).fillna('')\n",
    "\n",
    "desc_wpw_map = desc_wpw_map[[0,1]]\n",
    "desc_wpw_map[':TYPE'] = 'Pathway'\n",
    "desc_wpw_map[0] = desc_wpw_map[0].astype(str).str.replace(r'%WikiPathways_20240410%WP.*%Homo sapiens','',regex=True)\n",
    "\n",
    "desc_wpw_map[':TYPE'] = [[\"Pathway\"]] * len(desc_wpw_map)\n",
    "desc_wpw_map[':TYPE'] = desc_wpw_map[':TYPE'].apply(json.dumps)\n",
    "desc_wpw_map['Species'] = 'Homo sapiens'\n",
    "desc_wpw_map['WikiPathways_ID'] = desc_wpw_map[1].str.split(\"/\").str[-1]\n",
    "desc_wpw_map = desc_wpw_map.rename(columns={0:'Label',1:':ID'})\n",
    "desc_wpw_map.to_pickle(unprocessed_property_data_location + 'wikipathways.pkl')\n",
    "desc_wpw_map.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f09998",
   "metadata": {},
   "source": [
    "***\n",
    "# SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99518d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_data = pd.read_csv(unprocessed_data_location + 'variant_summary.txt', header=0, delimiter='\\t', low_memory=False)\n",
    "\n",
    "variant_data = variant_data[(variant_data['Assembly'] == 'GRCh38') & (variant_data['RS# (dbSNP)'] != -1)]\n",
    "variant_data['RS# (dbSNP)'] = 'rs' + variant_data['RS# (dbSNP)'].astype(str)\n",
    "variant_data['Genomic_location'] = \"chr\"+variant_data['Chromosome'].astype(str)+\":\"+variant_data['Start'].astype(str)+\"-\"+variant_data['Stop'].astype(str)\n",
    "variant_data['Mutation'] = variant_data['ReferenceAlleleVCF'] + \">\" + variant_data['AlternateAlleleVCF'] \n",
    "variant_data = variant_data[[\"RS# (dbSNP)\",\"Type\",\"Genomic_location\",\"Mutation\"]]\n",
    "\n",
    "print(variant_data.Type.unique())\n",
    "variant_data.Type = variant_data.Type.replace('single nucleotide variant', 'Variant, SNP, SNV')\n",
    "variant_data.Type = variant_data.Type.replace('Indel', 'Variant, SNP, Indel')\n",
    "variant_data.Type = variant_data.Type.replace('Deletion', 'Variant, SNP, Deletion')\n",
    "variant_data.Type = variant_data.Type.replace('Duplication', 'Variant, SNP, Duplication')\n",
    "variant_data.Type = variant_data.Type.replace('Microsatellite', 'Variant, SNP')\n",
    "variant_data.Type = variant_data.Type.replace('Insertion', 'Variant, SNP, Insertion')\n",
    "variant_data.Type = variant_data.Type.replace('Variation', 'Variant, SNP')\n",
    "variant_data.Type = variant_data.Type.replace('Inversion', 'Variant, SNP, Inversion')\n",
    "print(variant_data.Type.unique())\n",
    "\n",
    "variant_data = variant_data.groupby(['RS# (dbSNP)']).agg({'Mutation':'first', 'Genomic_location':lambda x: set(x.dropna()) if x.dropna().any() else set(),\n",
    "                                                          'Type':'first'}).reset_index()\n",
    "variant_data[':TYPE'] = variant_data['Type'].str.split(\", \").apply(json.dumps)\n",
    "variant_data[':ID'] = \"https://www.ncbi.nlm.nih.gov/snp/\" + variant_data['RS# (dbSNP)']\n",
    "variant_data['Label'] = variant_data['RS# (dbSNP)']\n",
    "variant_data = variant_data[[':ID','Label','Mutation','Genomic_location',':TYPE']]\n",
    "variant_data['NCBI_ID'] = variant_data['Label']\n",
    "variant_data['Genomic_location'] = variant_data['Genomic_location'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "variant_data.to_pickle(unprocessed_property_data_location + 'snp.pkl')\n",
    "variant_data.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c51fe3",
   "metadata": {},
   "source": [
    "***\n",
    "# COSMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic = pd.read_csv(unprocessed_data_location + \"Cosmic_NonCodingVariants_Normal_v101_GRCh38.vcf\",\n",
    "                     sep=\"\\t\", comment=\"#\", names=['CHROM','POS','ID','REF','ALT','QUAL','FILTER','INFO'], low_memory=False)\n",
    "cosmic = cosmic[cosmic['ID'] != \".\"]\n",
    "cosmic['Mutation'] = cosmic['REF'] + '>' + cosmic['ALT']\n",
    "cosmic['INFO'] = cosmic['INFO'].str.split(';')\n",
    "info_dicts = cosmic['INFO'].apply(lambda items: dict(part.split('=', 1) for part in items if '=' in part))\n",
    "info_df = pd.json_normalize(info_dicts)\n",
    "cosmic = pd.concat([cosmic, info_df], axis=1)\n",
    "cosmic = cosmic[cosmic['IS_CANONICAL'] == 'y']\n",
    "cosmic['Genomic_location'] = \"chr\" + cosmic['CHROM'].astype(str) + ':' + cosmic['POS'].astype(str) + \"-\" +\\\n",
    "    (cosmic['POS'].astype(int) + cosmic['REF'].str.len()).astype(str) + cosmic['STRAND'].astype(str)\n",
    "\n",
    "print(cosmic.SO_TERM.unique())\n",
    "cosmic.SO_TERM = cosmic.SO_TERM.replace('SNV', 'Variant, Somatic_variant, SNV')\n",
    "cosmic.SO_TERM = cosmic.SO_TERM.replace('indel', 'Variant, Somatic_variant, Indel')\n",
    "cosmic.SO_TERM = cosmic.SO_TERM.replace('deletion', 'Variant, Somatic_variant, Deletion')\n",
    "cosmic.SO_TERM = cosmic.SO_TERM.replace('duplication', 'Variant, Somatic_variant, Duplication')\n",
    "cosmic.SO_TERM = cosmic.SO_TERM.replace('microsatellite', 'Variant, Somatic_variant')\n",
    "cosmic.SO_TERM = cosmic.SO_TERM.replace('insertion', 'Variant, Somatic_variant, Insertion')\n",
    "cosmic.SO_TERM = cosmic.SO_TERM.replace('variation', 'Variant, Somatic_variant')\n",
    "cosmic.SO_TERM = cosmic.SO_TERM.replace('inversion', 'Variant, Somatic_variant, Inversion')\n",
    "print(cosmic.SO_TERM.unique())\n",
    "\n",
    "cosmic = cosmic.groupby(['ID']).agg({'Mutation':'first', 'Genomic_location':lambda x: set(x.dropna()) if x.dropna().any() else set(),\n",
    "                                     'SO_TERM':'first'}).reset_index()\n",
    "cosmic[':TYPE'] = cosmic['SO_TERM'].str.split(\", \").apply(json.dumps)\n",
    "cosmic[':ID'] = \"https://cancer.sanger.ac.uk/cosmic/mutation/overview?id=\" + cosmic['ID']\n",
    "cosmic['Label'] = cosmic['ID']\n",
    "cosmic = cosmic[[':ID','Label','Mutation','Genomic_location',':TYPE']]\n",
    "cosmic['Species'] = 'Homo sapiens'\n",
    "cosmic['COSMIC_ID'] = cosmic['Label']\n",
    "cosmic['Genomic_location'] = cosmic['Genomic_location'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "cosmic.to_pickle(unprocessed_property_data_location + 'cosmic.pkl')\n",
    "cosmic.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b11fbf",
   "metadata": {},
   "source": [
    "***\n",
    "# Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dfbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_clean = pd.read_csv(processed_data_location + 'Merged_Human_Ensembl_Entrez_HGNC_Uniprot_Identifiers.txt',\n",
    "                                sep='\\t', dtype={'entrez_id':str})[['ensembl_gene_id', 'symbol', 'ensembl_gene_type',\n",
    "                                                                    'entrez_id', 'synonyms']]\n",
    "merged_data_clean = merged_data_clean[(merged_data_clean['entrez_id'].astype(str).str.match(r'^\\d'))].drop_duplicates()\n",
    "\n",
    "ensembl_geneset = pd.read_csv(unprocessed_data_location + 'Homo_sapiens.GRCh38.113.gtf',\n",
    "                                  header = None, delimiter='\\t', skiprows=5, low_memory=False)\n",
    "ensembl_geneset = ensembl_geneset[ensembl_geneset[2] == 'gene']\n",
    "ensembl_geneset[8] = ensembl_geneset[8].str.split(\"gene_id \\\"\").str[1].str.split(\"\\\"\").str[0]\n",
    "ensembl_geneset['Genomic_location'] = \"chr\" + ensembl_geneset[0].astype(str)+\":\"+ensembl_geneset[3].astype(str)+\"-\"+\\\n",
    "      ensembl_geneset[4].astype(str) + ensembl_geneset[6].astype(str)\n",
    "ensembl_geneset = ensembl_geneset[[8, \"Genomic_location\"]]\n",
    "\n",
    "merged_data_clean = merged_data_clean.merge(ensembl_geneset, left_on='ensembl_gene_id', right_on=[8], how='left').drop(columns=[8])\n",
    "merged_data_clean.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cdf880",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_data_clean.ensembl_gene_type.unique())\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace(np.nan, 'Gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('protein-coding', 'Gene, Protein_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('unknown', 'Gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('TR_C_gene', 'Gene, Protein_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('miRNA', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('lncRNA', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('snoRNA', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('processed_pseudogene', 'Pseudogene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('unprocessed_pseudogene', 'Pseudogene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('transcribed_processed_pseudogene', 'Pseudogene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('transcribed_unitary_pseudogene', 'Pseudogene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('unitary_pseudogene', 'Pseudogene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('Mt_tRNA', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('rRNA_pseudogene', 'Pseudogene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('scaRNA', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('snRNA', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('scRNA', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('vaultRNA', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('rRNA', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('ribozyme', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('transcribed_unprocessed_pseudogene', 'Gene, Non_coding_gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('miscRNA', 'Gene')\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.replace('artifact', 'Gene')\n",
    "print(merged_data_clean.ensembl_gene_type.unique())\n",
    "\n",
    "merged_data_clean.ensembl_gene_type = merged_data_clean.ensembl_gene_type.str.split(\", \")\n",
    "merged_data_clean = merged_data_clean.explode('ensembl_gene_type')\n",
    "merged_data_clean.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_sequence(ensembl_gene_id):\n",
    "    base_url = \"https://rest.ensembl.org/sequence/id/\"\n",
    "    response = requests.get(base_url + ensembl_gene_id, headers={\"Content-Type\": \"application/json\"})\n",
    "    if response.ok:\n",
    "        return response.json()['seq']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "ensembl_id = pd.DataFrame(merged_data_clean['ensembl_gene_id'].unique())\n",
    "ensembl_id['Sequence'] = [get_sequence(x) for x in tqdm(ensembl_id[0])]\n",
    "ensembl_id['Sequence'] = ensembl_id['Sequence'].str.upper()\n",
    "ensembl_id.to_csv(unprocessed_property_data_location + 'ensembl_sequences.csv', index=None)\n",
    "#ensembl_id = pd.read_csv(unprocessed_property_data_location + 'ensembl_sequences.csv')\n",
    "merged_data_clean = merged_data_clean.merge(ensembl_id, left_on='ensembl_gene_id', right_on='0', how='left').drop(columns=['0'])\n",
    "merged_data_clean.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a36d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_clean = merged_data_clean.groupby(['entrez_id']).agg({'synonyms':lambda x: set(x.dropna()) if x.dropna().any() else set(),\n",
    "                                                                  \"ensembl_gene_id\":lambda x: x.dropna().iloc[0]\n",
    "                                                                    if not x.dropna().empty else np.nan,\n",
    "                                                                  'ensembl_gene_type':set,\n",
    "                                                                  'Genomic_location':lambda x: set(x.dropna()) if x.dropna().any() else set(),\n",
    "                                                                  \"Sequence\":lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan,\n",
    "                                                                  'symbol':lambda x: x.dropna().iloc[0] if not x.dropna().empty else np.nan})\\\n",
    "                                                                    .reset_index()\n",
    "\n",
    "merged_data_clean[':ID'] = \"http://www.ncbi.nlm.nih.gov/gene/\" + merged_data_clean['entrez_id'].astype(str)\n",
    "merged_data_clean = merged_data_clean[merged_data_clean[':ID'] != 'http://www.ncbi.nlm.nih.gov/gene/nan']\n",
    "merged_data_clean['synonyms'] = merged_data_clean['synonyms'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "merged_data_clean['ensembl_gene_type'] = merged_data_clean['ensembl_gene_type'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "merged_data_clean['Genomic_location'] = merged_data_clean['Genomic_location'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "merged_data_clean = merged_data_clean.rename(columns={'entrez_id':'NCBI_ID', 'ensembl_gene_id': 'Ensembl_ID',\n",
    "                                  'symbol': 'Symbol', 'synonyms':'Synonym', 'ensembl_gene_type':':TYPE'})\n",
    "merged_data_clean.to_pickle(unprocessed_property_data_location + 'gene.pkl')\n",
    "merged_data_clean.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533f1a1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac7b96",
   "metadata": {},
   "source": [
    "<!-- We keep db entities for which we processed properties only if they are within nodes coming from linked open data edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c037812",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral = pd.read_pickle(unprocessed_property_data_location + \"RNAcentral.pkl\")\n",
    "rnacentral['KG_ID'] = rnacentral['RNAcentral_ID']\n",
    "ensembl = pd.read_pickle(unprocessed_property_data_location + \"ensembl.pkl\")\n",
    "ensembl['KG_ID'] = ensembl['Ensembl_ID']\n",
    "addgene = pd.read_pickle(unprocessed_property_data_location + \"addgene.pkl\")\n",
    "addgene['KG_ID'] = addgene[':ID'].str.replace(\"https://\",\"\")\n",
    "icbp = pd.read_pickle(unprocessed_property_data_location + \"icbp.pkl\")\n",
    "icbp['KG_ID'] = icbp[':ID'].str.replace(\"http://web.mit.edu/sirna/sequences/results-\",\"\")\n",
    "circbase = pd.read_pickle(unprocessed_property_data_location + \"circbase.pkl\")\n",
    "circbase['KG_ID'] = circbase['circBase_ID']\n",
    "eskipFinder = pd.read_pickle(unprocessed_property_data_location + \"eskipFinder.pkl\")\n",
    "eskipFinder['KG_ID'] = eskipFinder['Label'].str.strip().str.replace(' ', '')\n",
    "tsrfun = pd.read_pickle(unprocessed_property_data_location + \"tsrfun.pkl\")\n",
    "tsrfun['KG_ID'] = tsrfun['tsRFun_ID']\n",
    "trfdb = pd.read_pickle(unprocessed_property_data_location + \"trfdb.pkl\")\n",
    "trfdb['Genomic_location'] = trfdb['Genomic_location'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "trfdb['KG_ID'] = \"trfdb?\" + trfdb['tRF_ID']\n",
    "mintbase = pd.read_pickle(unprocessed_property_data_location + \"mintbase.pkl\")\n",
    "mintbase['Genomic_location'] = mintbase['Genomic_location'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "mintbase['KG_ID'] = mintbase['MINTbase_ID']\n",
    "tbdb = pd.read_pickle(unprocessed_property_data_location + \"tbdb.pkl\")\n",
    "tbdb['KG_ID'] = tbdb[':ID']\n",
    "rswitch = pd.read_pickle(unprocessed_property_data_location + \"rswitch.pkl\")\n",
    "rswitch.rename(columns={'ID':'RSwitch_ID'},inplace=True)\n",
    "rswitch['KG_ID'] = rswitch['RSwitch_ID']\n",
    "aptaindex = pd.read_pickle(unprocessed_property_data_location + \"aptaindex.pkl\")\n",
    "aptaindex['KG_ID'] = aptaindex[':ID'].str.replace(\"https://www.aptagen.com/\",\"\")\n",
    "snodb = pd.read_pickle(unprocessed_property_data_location + \"snodb.pkl\")\n",
    "snodb['KG_ID'] = snodb['Label']\n",
    "genome = pd.read_pickle(unprocessed_property_data_location + \"genome.pkl\")\n",
    "genome['KG_ID'] = genome['NCBI_ID']\n",
    "chemicalModification = pd.read_pickle(unprocessed_property_data_location + \"chemicalModification.pkl\")\n",
    "chemicalModification['KG_ID'] = chemicalModification['Modomics_ID']\n",
    "biologicalRole = pd.read_pickle(unprocessed_property_data_location + \"biologicalRole.pkl\")\n",
    "biologicalRole['KG_ID'] = biologicalRole['NIH_ID']\n",
    "smprot = pd.read_pickle(unprocessed_property_data_location + \"smprot.pkl\")\n",
    "smprot['KG_ID'] = smprot['SmProt_ID']\n",
    "cncrnadb = pd.read_pickle(unprocessed_property_data_location + \"cncrnadb.pkl\")\n",
    "cncrnadb['KG_ID'] = cncrnadb['cncRNAdb_ID']\n",
    "reactome = pd.read_pickle(unprocessed_property_data_location + \"reactome.pkl\")\n",
    "reactome['KG_ID'] = reactome['Reactome_ID']\n",
    "wikipathways = pd.read_pickle(unprocessed_property_data_location + \"wikipathways.pkl\")\n",
    "wikipathways['KG_ID'] = wikipathways['WikiPathways_ID']\n",
    "snp = pd.read_pickle(unprocessed_property_data_location + \"snp.pkl\")\n",
    "snp['KG_ID'] = snp['NCBI_ID']\n",
    "cosmic = pd.read_pickle(unprocessed_property_data_location + \"cosmic.pkl\")\n",
    "cosmic['Genomic_location'] = cosmic['Genomic_location'].str.replace(\".0\",\"\")\n",
    "cosmic['KG_ID'] = cosmic['COSMIC_ID']\n",
    "gene = pd.read_pickle(unprocessed_property_data_location + \"gene.pkl\")\n",
    "gene['KG_ID'] = gene['NCBI_ID']\n",
    "gene['Species'] = 'Homo sapiens'\n",
    "db_entities = pd.concat([rnacentral,ensembl,addgene,icbp,circbase,eskipFinder,tsrfun,trfdb,mintbase,\n",
    "                         tbdb,rswitch,aptaindex,snodb,genome,chemicalModification,biologicalRole,\n",
    "                         smprot,cncrnadb,reactome,wikipathways,snp,cosmic,gene])\n",
    "\n",
    "db_entities['Label'] = db_entities['Label'].fillna(db_entities['Symbol'])\n",
    "db_entities = db_entities.drop(columns=['Symbol'])\n",
    "db_entities['ID'] = \"RNAcentral:\" + db_entities['RNAcentral_ID'] + \"_9606\"\n",
    "db_entities['Ensembl_ID'] = \"Ensembl:\" + db_entities['Ensembl_ID']\n",
    "db_entities['Addgene_ID'] = \"Addgene:\" + db_entities['Addgene_ID']\n",
    "db_entities['ICBP_ID'] = \"ICBP:\" + db_entities['ICBP_ID']\n",
    "db_entities['circBase_ID'] = \"circBase:\" + db_entities['circBase_ID']\n",
    "db_entities['tsRFun_ID'] = \"tsRFun:\" + db_entities['tsRFun_ID']\n",
    "db_entities['tRF_ID'] = \"tRF:\" + db_entities['tRF_ID']\n",
    "db_entities['MINTbase_ID'] = \"MINTbase:\" + db_entities['MINTbase_ID']\n",
    "db_entities['TBDB_ID'] = \"TBDB:\" + db_entities['TBDB_ID']\n",
    "db_entities['RSwitch_ID'] = \"RSwitch:\" + db_entities['RSwitch_ID']\n",
    "db_entities['Apta-Index_ID'] = \"Apta-Index:\" + db_entities['Apta-Index_ID']\n",
    "db_entities['NCBI_ID'] = \"NCBI:\" + db_entities['NCBI_ID']\n",
    "db_entities['Modomics_ID'] = \"Modomics:\" + db_entities['Modomics_ID']\n",
    "db_entities['NIH_ID'] = \"NIH:\" + db_entities['NIH_ID']\n",
    "db_entities['SmProt_ID'] = \"SmProt:\" + db_entities['SmProt_ID']\n",
    "db_entities['cncRNAdb_ID'] = \"cncRNAdb:\" + db_entities['cncRNAdb_ID']\n",
    "db_entities['Reactome_ID'] = \"Reactome:\" + db_entities['Reactome_ID']\n",
    "db_entities['WikiPathways_ID'] = \"WikiPathways:\" + db_entities['WikiPathways_ID']\n",
    "db_entities['COSMIC_ID'] = \"COSMIC:\" + db_entities['COSMIC_ID']\n",
    "\n",
    "db_entities['ID'] = db_entities['ID'].fillna(db_entities['Ensembl_ID']).fillna(db_entities['Addgene_ID']).fillna(\n",
    "    db_entities['ICBP_ID']).fillna(db_entities['circBase_ID']).fillna(db_entities['tsRFun_ID']).fillna(\n",
    "        db_entities['tRF_ID']).fillna(db_entities['MINTbase_ID']).fillna(db_entities['TBDB_ID']).fillna(\n",
    "            db_entities['RSwitch_ID']).fillna(db_entities['Apta-Index_ID']).fillna(\n",
    "                db_entities['NCBI_ID']).fillna(db_entities['Modomics_ID']).fillna(\n",
    "                    db_entities['NIH_ID']).fillna(db_entities['SmProt_ID']).fillna(\n",
    "                        db_entities['Reactome_ID']).fillna(\n",
    "                        db_entities['WikiPathways_ID']).fillna(\n",
    "                        db_entities['cncRNAdb_ID']).fillna(\n",
    "                        db_entities['COSMIC_ID'])\n",
    "\n",
    "db_entities = db_entities.drop(columns=['Ensembl_ID','Addgene_ID','ICBP_ID','circBase_ID','tsRFun_ID',\n",
    "                                        'tRF_ID','MINTbase_ID','TBDB_ID','RSwitch_ID','Apta-Index_ID',\n",
    "                                        'NCBI_ID','Modomics_ID','NIH_ID','SmProt_ID','Reactome_ID',\n",
    "                                        'WikiPathways_ID','cncRNAdb_ID','COSMIC_ID','RNAcentral_ID'])\n",
    "\n",
    "db_entities.to_pickle(unprocessed_property_data_location + 'db_entities.pkl')\n",
    "db_entities.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''file = []\n",
    "for filename in os.listdir(unprocessed_edge_data_location):\n",
    "    if filename.endswith('.pkl') and filename.split('_')[0] != 'OBO':\n",
    "        file.append(filename)\n",
    "\n",
    "start_id = set()\n",
    "for f in file :\n",
    "    df = pd.read_pickle(unprocessed_edge_data_location + f)\n",
    "    print(f)\n",
    "    start_id.update(df[':START_ID'].unique())\n",
    "    print(list(start_id)[:3])\n",
    "    print(list(start_id)[-3:])\n",
    "\n",
    "file = []\n",
    "for filename in os.listdir(unprocessed_edge_data_location):\n",
    "    if filename.endswith('.pkl') and filename.split('_')[-1].replace('.pkl', '') != 'OBO':\n",
    "        file.append(filename)  \n",
    "\n",
    "end_id = set()\n",
    "for f in file :\n",
    "    df = pd.read_pickle(unprocessed_edge_data_location + f)\n",
    "    print(f)\n",
    "    end_id.update(df[':END_ID'].unique())\n",
    "    print(list(end_id)[:3])\n",
    "    print(list(end_id)[-3:])\n",
    "\n",
    "db_entities_in_KG = pd.DataFrame(list(start_id.union(end_id))).drop_duplicates().reset_index(drop=True)\n",
    "db_entities_in_KG.to_pickle(unprocessed_property_data_location + 'db_entities_in_KG.pkl')\n",
    "db_entities_in_KG.head(n=3)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''db_entities_in_KG = pd.read_pickle(unprocessed_property_data_location + 'db_entities_in_KG.pkl')\n",
    "db_entities_in_KG[0] = db_entities_in_KG[0].astype(str)\n",
    "db_entities = pd.read_pickle(unprocessed_property_data_location + 'db_entities.pkl')\n",
    "db_entities['KG_ID'] = db_entities['KG_ID'].astype(str)\n",
    "db_entities = db_entities[db_entities['KG_ID'].isin(db_entities_in_KG[0])]\n",
    "db_entities.head(n=3)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b67dd",
   "metadata": {},
   "source": [
    "***\n",
    "# OBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54639d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 35/50 minutes\n",
    "obo_graph = Graph()\n",
    "obo_graph.parse(ontology_data_location + 'merged_with_imports.owl')\n",
    "print('There are {} edges in the ontology.'.format(len(obo_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasOBONamespace = URIRef(\"http://www.geneontology.org/formats/oboInOwl#hasOBONamespace\")\n",
    "dbxref_uri = URIRef(\"http://www.geneontology.org/formats/oboInOwl#hasDbXref\")\n",
    "chargeName = URIRef(\"http://purl.obolibrary.org/obo/chebi/charge\")\n",
    "massName = URIRef(\"http://purl.obolibrary.org/obo/chebi/mass\")\n",
    "smilesName = URIRef(\"http://purl.obolibrary.org/obo/chebi/smiles\")\n",
    "formulaName = URIRef(\"http://purl.obolibrary.org/obo/chebi/formula\")\n",
    "inchikeyName = URIRef(\"http://purl.obolibrary.org/obo/chebi/inchikey\")\n",
    "'''\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "cls = {x for x in gets_ontology_classes(obo_graph)}\n",
    "master_synonyms = {x for x in obo_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)}\n",
    "\n",
    "print(\"Caching...\")\n",
    "cache_labels = {\n",
    "    x: next(\n",
    "        iter(\n",
    "            {val for val in obo_graph.objects(x, RDFS.label) if val.language == 'en'} or\n",
    "            {val for val in obo_graph.objects(x, RDFS.label) if val.language is None} or\n",
    "            {val for val in obo_graph.objects(x, RDFS.label)} or\n",
    "            {val for val in obo_graph.objects(x, obo.VO_0003158)}\n",
    "        ),\n",
    "        np.nan\n",
    "    )\n",
    "    for x in cls\n",
    "}\n",
    "cache_synonyms = {\n",
    "    x: {val for val in obo_graph.objects(x, RDFS.label)}.union(\n",
    "            {val for val in obo_graph.objects(x, obo.VO_0003158)}).union(\n",
    "                {val for val in obo_graph.objects(x, obo.IAO_0000118)}).union(\n",
    "                    {val for val in obo_graph.objects(x, obo.VO_0003099)}).union(\n",
    "                        {val for val in obo_graph.objects(x, obo.OBI_9991118)})\n",
    "    for x in cls\n",
    "}\n",
    "cache_descriptions = {\n",
    "    x: next(\n",
    "        iter(\n",
    "            {str(desc).lower().strip() for desc in obo_graph.objects(x, obo.IAO_0000115) if desc.language == 'en'} or\n",
    "            {str(desc).lower().strip() for desc in obo_graph.objects(x, obo.IAO_0000115) if desc.language is None} or\n",
    "            {str(desc).lower().strip() for desc in obo_graph.objects(x, obo.IAO_0000115)}\n",
    "        ),\n",
    "        np.nan\n",
    "    )\n",
    "    for x in cls\n",
    "}\n",
    "\n",
    "cache_go_vocab = {x: set(obo_graph.objects(x, hasOBONamespace)) for x in cls}\n",
    "cache_fda = {x: set(obo_graph.objects(x, obo.VO_0003160)) for x in cls}\n",
    "cache_charge = {x: set(obo_graph.objects(x, chargeName)) for x in cls}\n",
    "cache_mass = {x: set(obo_graph.objects(x, massName)) for x in cls}\n",
    "cache_smiles = {x: set(obo_graph.objects(x, smilesName)) for x in cls}\n",
    "cache_formula = {x: set(obo_graph.objects(x, formulaName)) for x in cls}\n",
    "cache_inchikey = {x: set(obo_graph.objects(x, inchikeyName)) for x in cls}\n",
    "cache_dbxref = {x: set(obo_graph.objects(x, dbxref_uri)) for x in cls}\n",
    "\n",
    "cache_dict = {\n",
    "    \"classes\": cls,\n",
    "    \"syn\": master_synonyms,\n",
    "    \"labels\": cache_labels,\n",
    "    \"synonyms\": cache_synonyms,\n",
    "    \"descriptions\": cache_descriptions,\n",
    "    \"go_vocab\": cache_go_vocab,\n",
    "    \"fda\": cache_fda,\n",
    "    \"charge\": cache_charge,\n",
    "    \"mass\": cache_mass,\n",
    "    \"smiles\": cache_smiles,\n",
    "    \"formula\": cache_formula,\n",
    "    \"inchikey\": cache_inchikey,\n",
    "    \"dbxref\": cache_dbxref\n",
    "}\n",
    "\n",
    "cache_path = unprocessed_property_data_location + \"obo_cache.pkl\"\n",
    "\n",
    "with open(cache_path, \"wb\") as f:\n",
    "    pickle.dump(cache_dict, f)\n",
    "\n",
    "print(\"Cache saved\")\n",
    "\n",
    "'''\n",
    "\n",
    "cache_path = unprocessed_property_data_location + \"obo_cache.pkl\"\n",
    "\n",
    "if os.path.exists(cache_path):\n",
    "    with open(cache_path, \"rb\") as f:\n",
    "        cache_dict = pickle.load(f)\n",
    "    \n",
    "    cls = cache_dict[\"classes\"]\n",
    "    master_synonyms = cache_dict[\"syn\"]\n",
    "    cache_labels = cache_dict[\"labels\"]\n",
    "    cache_synonyms = cache_dict[\"synonyms\"]\n",
    "    cache_descriptions = cache_dict[\"descriptions\"]\n",
    "    cache_go_vocab = cache_dict[\"go_vocab\"]\n",
    "    cache_fda = cache_dict[\"fda\"]\n",
    "    cache_charge = cache_dict[\"charge\"]\n",
    "    cache_mass = cache_dict[\"mass\"]\n",
    "    cache_smiles = cache_dict[\"smiles\"]\n",
    "    cache_formula = cache_dict[\"formula\"]\n",
    "    cache_inchikey = cache_dict[\"inchikey\"]\n",
    "    cache_dbxref = cache_dict[\"dbxref\"]\n",
    "\n",
    "    print(\"Cache loaded\")\n",
    "else:\n",
    "    print(\"Cache non found\")\n",
    "\n",
    "def process_class_metadata(cls_item):\n",
    "    #print(\"Processing: \", cache_labels.get(cls_item, np.nan))\n",
    "    fda = cache_fda.get(cls_item, set())\n",
    "    charge = cache_charge.get(cls_item, set())\n",
    "    mass = cache_mass.get(cls_item, set())\n",
    "    smiles = cache_smiles.get(cls_item, set())\n",
    "    formula = cache_formula.get(cls_item, set())\n",
    "    inchikey = cache_inchikey.get(cls_item, set())\n",
    "\n",
    "    return str(cls_item), {\n",
    "        'Label': cache_labels.get(cls_item, np.nan),\n",
    "        'Description': cache_descriptions.get(cls_item, np.nan),\n",
    "        'Synonym': cache_synonyms.get(cls_item, set()),\n",
    "        \"GOvocab\": cache_go_vocab.get(cls_item, set()),\n",
    "        'FDA_indications': next(iter(fda if isinstance(fda, set) else set()), np.nan),\n",
    "        'Charge': next(iter(charge if isinstance(charge, set) else set()), np.nan),\n",
    "        'Mass': next(iter(mass if isinstance(mass, set) else set()), np.nan),\n",
    "        'SMILES': next(iter(smiles if isinstance(smiles, set) else set()), np.nan),\n",
    "        'Formula': next(iter(formula if isinstance(formula, set) else set()), np.nan),\n",
    "        'InChIKey': next(iter(inchikey if isinstance(inchikey, set) else set()), np.nan),\n",
    "        'DbXref': cache_dbxref.get(cls_item, set())\n",
    "    }\n",
    "\n",
    "results = []\n",
    "for cls_item in tqdm(cls, desc=\"Processing classes\"):\n",
    "    results.append(process_class_metadata(cls_item))\n",
    "\n",
    "relation_metadata_dict = dict(results)\n",
    "pd.DataFrame.from_dict(relation_metadata_dict, orient='index').to_pickle(unprocessed_property_data_location + 'obo_raw2.pkl')\n",
    "\n",
    "# Adjust values\n",
    "for x in relation_metadata_dict.values():\n",
    "    if x['Label'] and x['Synonym']:\n",
    "        x['Synonym'] = {str(i) for i in x['Synonym'].union({x['Label']}) - {x['Label']}}  # The rest as synonyms\n",
    "    else:\n",
    "        x['Label'] = np.nan \n",
    "    \n",
    "    if not x['Label'] and x['Synonym']:\n",
    "        label = list(x['Synonym'])\n",
    "        x['Label'] = label[0]  # Keep the first synonym as label\n",
    "        x['Synonym'] = {str(i) for i in x['Synonym'].union(label) - {x['Label']}}  # The rest as synonyms\n",
    "    \n",
    "    if x['Synonym']:\n",
    "        x['Synonym'] = {str(i) for i in x['Synonym']}  \n",
    "\n",
    "    if x['FDA_indications']:\n",
    "        x['FDA_indications'] = str(x['FDA_indications'])\n",
    "        if x['FDA_indications'] == 'nan':\n",
    "            x['FDA_indications'] = np.nan\n",
    "\n",
    "    if x['Description']:\n",
    "        x['Description'] = str(x['Description'])\n",
    "        if x['Description'] == 'nan':\n",
    "            x['Description'] = np.nan\n",
    "\n",
    "    if x['SMILES']:\n",
    "        x['SMILES'] = str(x['SMILES'])\n",
    "        if x['SMILES'] == 'nan':\n",
    "            x['SMILES'] = np.nan\n",
    "\n",
    "    if x['InChIKey']:\n",
    "        x['InChIKey'] = str(x['InChIKey'])\n",
    "        if x['InChIKey'] == 'nan':\n",
    "            x['InChIKey'] = np.nan\n",
    "\n",
    "    if x['Formula']:\n",
    "        x['Formula'] = str(x['Formula'])\n",
    "        if x['Formula'] == 'nan':\n",
    "            x['Formula'] = np.nan\n",
    "\n",
    "    if x['GOvocab']:\n",
    "        x['GOvocab'] = {str(i).capitalize() for i in x['GOvocab'] if str(i) == 'biological_process' or \n",
    "                        str(i) == 'molecular_function' or  str(i) == 'cellular_component'}  \n",
    "        \n",
    "df = pd.DataFrame.from_dict(relation_metadata_dict, orient='index')\n",
    "\n",
    "df['Charge'] = df['Charge'].astype(str).str.replace(r'^\\+', '', regex=True)  # Remove `+`\n",
    "df['Charge'] = pd.to_numeric(df['Charge'], errors='coerce')\n",
    "\n",
    "df['Mass'] = df['Mass'].astype(str).str.replace(r'^\\+', '', regex=True)  # Remove `+`\n",
    "df['Mass'] = pd.to_numeric(df['Mass'], errors='coerce')\n",
    "\n",
    "df[':ID'] = df.index\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_pickle(unprocessed_property_data_location + 'obo2.pkl')\n",
    "#df = pd.read_pickle(unprocessed_property_data_location + 'obo2.pkl')\n",
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deef534",
   "metadata": {},
   "source": [
    "We add properties for DrugBank nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DrugBank = pd.read_csv(processed_data_location + 'DrugBank/drugbank vocabulary.csv')[[\n",
    "    'DrugBank ID','Common name','CAS','Synonyms','Standard InChI Key']]\n",
    "links = pd.read_csv(processed_data_location + 'DrugBank/drug links.csv',dtype={'ChEBI ID':str})[['DrugBank ID', 'ChEBI ID']]\n",
    "links['ChEBI ID'] = 'CHEBI_' + links['ChEBI ID']\n",
    "DrugBank = pd.merge(DrugBank,links,on='DrugBank ID')\n",
    "DrugBank['ChEBI ID'] = DrugBank['ChEBI ID'].fillna(DrugBank['DrugBank ID'])\n",
    "DrugBank.rename(columns={'ChEBI ID':'ID'},inplace=True)\n",
    "sequences = pd.DataFrame([\n",
    "    {'ID': record.id.replace(\"drugbank_drug|\", \"\"), 'Sequence': str(record.seq)}\n",
    "    for record in SeqIO.parse(processed_data_location + 'DrugBank/drug sequences.fasta', 'fasta')\n",
    "])\n",
    "DrugBank = pd.merge(DrugBank,sequences,on='ID',how='outer')\n",
    "DrugBank['ID'] = \"http://purl.obolibrary.org/obo/\" + DrugBank['ID']\n",
    "DrugBank['DrugBank ID'] = \"https://go.drugbank.com/drugs/\" + DrugBank['DrugBank ID']\n",
    "DrugBank['Type'] = \"Chemical, Drug\"\n",
    "DrugBank.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = []\n",
    "for filename in os.listdir(processed_data_location+\"/DrugBank\"): \n",
    "    if filename.endswith('.txt'):\n",
    "        tmp = pd.read_csv(f'{processed_data_location}/DrugBank/{filename}', sep=\"\\t\")\n",
    "        tmp['Type'] = 'Chemical, Drug, RNA, RNA_drug, ' + filename.split('-')[0]\n",
    "        file.append(tmp[['Drug', 'Type']].drop_duplicates())\n",
    "\n",
    "df_final = pd.concat(file, ignore_index=True)\n",
    "df_final['Type'] = df_final['Type'].str.replace(\"siRNA\", \"ncRNA, sncRNA, small_regulatory_ncRNA, siRNA\")\n",
    "df_final['Type'] = df_final['Type'].str.replace(\"aptamer\", \"ncRNA, sncRNA, oligo, aptamer, RNA_aptamer\")\n",
    "df_final['Type'] = df_final['Type'].str.replace(\"ASO\", \"ncRNA, sncRNA, oligo, antisense_oligonucleotide, RNA_antisense_oligonucleotide\")\n",
    "df_final['Type'] = df_final['Type'].str.replace(\"mRNAv\", \"Vaccine, mRNA, RNA_vaccine, mRNA_vaccine\")\n",
    "df_final.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253fdf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DrugBank = pd.merge(DrugBank,df_final,left_on='Common name',right_on='Drug',how='left')\n",
    "DrugBank['Type_y'] = DrugBank['Type_y'].fillna(DrugBank['Type_x'])\n",
    "DrugBank.rename(columns={'Type_y':'Type'},inplace=True)\n",
    "DrugBank.rename(columns={'Common name':'Label', 'Synonyms':'Synonym', 'Standard InChI Key':'InChIKey', 'ID':':ID'},inplace=True)\n",
    "DrugBank = DrugBank[[':ID', 'Label', 'CAS', 'Synonym', 'InChIKey', 'Sequence', 'Type']]\n",
    "DrugBank['Type'] = DrugBank['Type'].str.split(\", \")\n",
    "DrugBank['Type'] =  DrugBank['Type'].apply(lambda items: {i for i in items})\n",
    "DrugBank['Synonym'] = DrugBank['Synonym'].astype(str).str.split(\" \\| \")\n",
    "DrugBank['Synonym'] =  DrugBank['Synonym'].apply(lambda items: {i for i in items if i != 'nan'})\n",
    "\n",
    "def adjust_label(row):\n",
    "    label = (row['Label'])\n",
    "    row['Label'] = label\n",
    "    row['Synonym'] = row['Synonym'] - {label}\n",
    "    return row\n",
    "\n",
    "DrugBank = DrugBank.apply(adjust_label, axis=1)\n",
    "\n",
    "DrugBank.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(DrugBank, on=':ID', how='outer')\n",
    "df['Label_x'] = df['Label_x'].fillna(df['Label_y'])\n",
    "df.rename(columns={'Label_x':'Label'},inplace=True)\n",
    "df['InChIKey_x'] = df['InChIKey_x'].fillna(df['InChIKey_y'])\n",
    "df.rename(columns={'InChIKey_x':'InChIKey'},inplace=True)\n",
    "df['Synonym_x'] = df['Synonym_x'].apply(lambda x: x if isinstance(x, set) else set())\n",
    "df['Synonym_y'] = df['Synonym_y'].apply(lambda x: x if isinstance(x, set) else set())\n",
    "df['Synonym'] = df.apply(lambda row: row['Synonym_x'].union(row['Synonym_y']), axis=1).apply(lambda items: {i for i in items})\n",
    "df['Type'] = df['Type'].apply(lambda x: x if isinstance(x, set) else set())\n",
    "df['GOvocab'] = df['GOvocab'].apply(lambda x: x if isinstance(x, set) else set())\n",
    "df['Type'] = df.apply(lambda row: row['Type'].union(row['GOvocab']), axis=1).apply(lambda items: {i for i in items})\n",
    "df.drop(columns=['Label_y', 'Synonym_x', 'Synonym_y', 'GOvocab', 'InChIKey_y'], inplace=True)\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423788e3",
   "metadata": {},
   "source": [
    "We add protein sequences from UniProtKB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639bc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz -O $unprocessed_property_data_location/uniprot_sprot.fasta.gz\n",
    "!gunzip $unprocessed_property_data_location/uniprot_sprot.fasta.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0886743",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for rec in SeqIO.parse(unprocessed_property_data_location + 'uniprot_sprot.fasta', 'fasta'):\n",
    "    records.append({'ID': rec.id, 'Sequence': str(rec.seq)})\n",
    "sprot = pd.DataFrame(records)\n",
    "sprot.ID = sprot.ID.str.split(\"\\|\").str[1]\n",
    "sprot.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0bea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DbXref'].astype(str).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DbXref'] = df['DbXref'].apply(lambda x: x if isinstance(x, set) else set())\n",
    "df['DbXref'] = df['DbXref'].apply(lambda x: {i.split(\":\")[1] for i in x if i.startswith('UniProtKB:') and len(i.split(\":\")) > 1})\n",
    "df['DbXref'] = df['DbXref'].apply(lambda x: x.pop() if x else np.nan)\n",
    "\n",
    "df = pd.merge(df, sprot, left_on='DbXref', right_on='ID', how='left').drop(columns=['ID','DbXref'])\n",
    "df['Sequence_x'] = df['Sequence_x'].fillna(df['Sequence_y'])\n",
    "df.rename(columns={'Sequence_x':'Sequence'},inplace=True)\n",
    "df = df.drop(columns=['Sequence_y'])\n",
    "df.to_pickle(unprocessed_property_data_location + 'obo2.pkl')\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32570e3f",
   "metadata": {},
   "source": [
    "We add DrugBank to ontology kg as we treated them as ontology classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd17a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DrugBank = pd.read_csv(processed_data_location + 'DrugBank/drugbank vocabulary.csv')\n",
    "links = pd.read_csv(processed_data_location + 'DrugBank/drug links.csv',dtype={'ChEBI ID':str})[['DrugBank ID', 'ChEBI ID']]\n",
    "links['ChEBI ID'] = 'CHEBI_' + links['ChEBI ID']\n",
    "DrugBank = pd.merge(DrugBank,links,on='DrugBank ID')\n",
    "DrugBank['ChEBI ID'] = DrugBank['ChEBI ID'].fillna(DrugBank['DrugBank ID'])\n",
    "DrugBank = DrugBank[['ChEBI ID', 'Common name']]\n",
    "DrugBank.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = []\n",
    "for filename in os.listdir(processed_data_location+\"/DrugBank\"): \n",
    "    if filename.endswith('.txt'):\n",
    "        tmp = pd.read_csv(f'{processed_data_location}/DrugBank/{filename}', sep=\"\\t\")\n",
    "        tmp[':END_ID'] = \"http://purl.obolibrary.org/obo/CHEBI_23888, \" + filename.split('-')[0]\n",
    "        file.append(tmp[['Drug', ':END_ID']].drop_duplicates())\n",
    "\n",
    "df_final = pd.concat(file, ignore_index=True)\n",
    "df_final[':END_ID'] = df_final[':END_ID'].str.replace('ASO', 'http://purl.obolibrary.org/obo/SO_0001247, http://purl.obolibrary.org/obo/SO_0000644')\n",
    "df_final[':END_ID'] = df_final[':END_ID'].str.replace('aptamer', 'http://purl.obolibrary.org/obo/SO_0001247, http://purl.obolibrary.org/obo/SO_0000033')\n",
    "df_final[':END_ID'] = df_final[':END_ID'].str.replace('mRNAv', 'http://purl.obolibrary.org/obo/SO_0000234, http://purl.obolibrary.org/obo/VO_0000186, http://purl.obolibrary.org/obo/SO_0000351')\n",
    "df_final[':END_ID'] = df_final[':END_ID'].str.replace('siRNA', 'http://purl.obolibrary.org/obo/SO_0000646, http://purl.obolibrary.org/obo/SO_0000351')\n",
    "df_final.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318532e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DrugBank = pd.merge(DrugBank,df_final,left_on='Common name',right_on='Drug',how='outer')\n",
    "DrugBank[':END_ID'] = DrugBank[':END_ID'].fillna(\"http://purl.obolibrary.org/obo/CHEBI_23888\")\n",
    "DrugBank[':END_ID'] = DrugBank[':END_ID'].str.split(\", \")\n",
    "DrugBank = DrugBank.explode(':END_ID')\n",
    "DrugBank = DrugBank[['ChEBI ID', ':END_ID']].drop_duplicates().dropna()\n",
    "DrugBank.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ccbb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DrugBank['Source'] = 'Entity_linking'\n",
    "DrugBank[':TYPE'] = 'subclassof'\n",
    "DrugBank[':START_ID'] = DrugBank['ChEBI ID'].apply(\n",
    "    lambda val: f\"http://purl.obolibrary.org/obo/{val}\"\n",
    "        if val.startswith('CHEBI')\n",
    "        else f\"https://go.drugbank.com/drugs/{val}\"\n",
    "        if val.startswith('DB')\n",
    "        else val\n",
    ")\n",
    "DrugBank = DrugBank.drop(columns=['ChEBI ID'])\n",
    "DrugBank.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ontology_kg = pd.read_csv(ontology_data_location + 'merged_ontology_kg.txt', sep='\\t', names=[':START_ID', ':TYPE', ':END_ID', 'Source'])\n",
    "merged_ontology_kg[':START_ID'] = merged_ontology_kg[':START_ID'].str.replace(\"http://identifiers.org/ncbigene/\", \"http://www.ncbi.nlm.nih.gov/gene/\")\n",
    "merged_ontology_kg[':END_ID'] = merged_ontology_kg[':END_ID'].str.replace(\"http://identifiers.org/ncbigene/\", \"http://www.ncbi.nlm.nih.gov/gene/\")\n",
    "merged_ontology_kg['Source'] = merged_ontology_kg['Source'].str.replace(\"\\'\", \"\", regex=True)\n",
    "merged_ontology_kg['Source'] = merged_ontology_kg['Source'].str.replace(\"]\", \"\").str.replace(\"[\", \"\")\n",
    "merged_ontology_kg = pd.concat([merged_ontology_kg, DrugBank])\n",
    "merged_ontology_kg = merged_ontology_kg.groupby([':START_ID', ':TYPE', ':END_ID']).agg({'Source':set}).reset_index()\n",
    "\n",
    "obo_graph = nx.DiGraph()\n",
    "for _, row in tqdm(merged_ontology_kg.iterrows(), desc=\"Importing edges\", total=merged_ontology_kg.shape[0]):\n",
    "    obo_graph.add_edge(row[':START_ID'], row[':END_ID'], relation=row[':TYPE'])\n",
    "print(f'There are {obo_graph.number_of_edges()} edges in the ontology.')\n",
    "\n",
    "merged_ontology_kg.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684727ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_superclasses(cls, graph):\n",
    "    stack = [cls]\n",
    "    superclasses = set()\n",
    "    visited = set()\n",
    "    while stack:\n",
    "        current = stack.pop()\n",
    "        if current in visited:\n",
    "            continue\n",
    "        visited.add(current)\n",
    "        superclasses.add(str(current))\n",
    "        stack.extend(e for _, e, data in graph.out_edges(current, data=True) if data[\"relation\"] == \"subclassof\")\n",
    "    return superclasses\n",
    "\n",
    "relation_metadata_dict = {}\n",
    "\n",
    "# Estrazione delle informazioni dall'ontologia\n",
    "nodes = set(obo_graph.nodes)\n",
    "\n",
    "for x in tqdm(nodes, desc=\"Processing ontology nodes\"):\n",
    "    superclasses = get_superclasses(x, obo_graph)\n",
    "    relation_metadata_dict[str(x)] = {\"Hierarchy\": superclasses}\n",
    "\n",
    "# Creazione del DataFrame\n",
    "df = pd.DataFrame.from_dict(relation_metadata_dict, orient='index')\n",
    "df.to_pickle(unprocessed_property_data_location + 'obo_merged_raw.pkl')\n",
    "df = pd.read_pickle(unprocessed_property_data_location + 'obo_merged_raw.pkl')\n",
    "\n",
    "# Inizializzazione delle colonne\n",
    "categories = [\n",
    "    'Histone_modification', 'Epigenetic_modification', 'Cardiovascular_disease',\n",
    "    'Neurodegenerative_disease', 'Infectious_disease', 'Autoimmune_disease', 'Biological_role',\n",
    "    'Inflammatory_disease', 'Drug', 'Cancer', 'GO', 'Viral_protein', 'Human_protein'\n",
    "]\n",
    "for category in categories:\n",
    "    df[category] = \"\"\n",
    "\n",
    "# Popolamento delle categorie\n",
    "mapping = {\n",
    "    \"http://purl.obolibrary.org/obo/SO_0001700\": 'Histone_modification',\n",
    "    \"http://purl.obolibrary.org/obo/SO_0001720\": 'Epigenetic_modification',\n",
    "    \"http://purl.obolibrary.org/obo/MONDO_0005267\": 'Cardiovascular_disease',\n",
    "    \"http://purl.obolibrary.org/obo/MONDO_0005559\": 'Neurodegenerative_disease',\n",
    "    \"http://purl.obolibrary.org/obo/MONDO_0005550\": 'Infectious_disease',\n",
    "    \"http://purl.obolibrary.org/obo/MONDO_0007179\": 'Autoimmune_disease',\n",
    "    \"http://purl.obolibrary.org/obo/MONDO_0045024\": 'Cancer',\n",
    "    \"http://purl.obolibrary.org/obo/CHEBI_23888\": 'Drug',\n",
    "    \"http://purl.obolibrary.org/obo/CHEBI_24432\": 'Biological_role',\n",
    "    \"http://purl.obolibrary.org/obo/PR_000029067\": 'Human_protein',\n",
    "    \"http://purl.obolibrary.org/obo/PR_000036197\": 'Viral_protein'\n",
    "}\n",
    "\n",
    "for uri, category in mapping.items():\n",
    "    df.loc[df['Hierarchy'].apply(lambda h: uri in h), category.split(':')[0]] += category.split(':')[-1] + \", \"\n",
    "\n",
    "df['Type'] = df[categories].apply(lambda x: \", \".join(filter(None, x)), axis=1)\n",
    "df['Type'] = df['Type'].str.replace(', , ', ', ')\n",
    "df['Type'] = df['Type'].str.replace(', $', '', regex=True)\n",
    "df['Type'] = df['Type'].replace('', np.nan)\n",
    "\n",
    "df.drop(columns=['Hierarchy'] + categories[:-1], inplace=True)\n",
    "df[':ID'] = df.index\n",
    "df['Type'] = df['Type'].apply(lambda x: x.split(\", \") if isinstance(x, str) else [])\n",
    "df['Type'] = df['Type'].apply(lambda items: {i for i in items if pd.notna(i)})\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_pickle(unprocessed_property_data_location + 'obo_merged.pkl')\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf119c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "species = pd.DataFrame(merged_ontology_kg[merged_ontology_kg[':TYPE'] == 'only_in_taxon'][':END_ID'].unique())\n",
    "species[0] = species[0].str.split(\"_\").str[-1]\n",
    "species[0] = species[0].str.lstrip(\"0\")\n",
    "\n",
    "def get_species_name(taxon_id):\n",
    "    Entrez.email = \"emanuele.cavalleri@unimi.it\"\n",
    "    try:\n",
    "        handle = Entrez.esummary(db=\"taxonomy\", id=taxon_id, retmode=\"xml\")\n",
    "        record = Entrez.read(handle)\n",
    "        species_name = record[0][\"ScientificName\"]\n",
    "    except Exception as e:\n",
    "        species_name = None  \n",
    "        print(f\"Errore nel recupero del nome per il taxon ID {taxon_id}: {e}\")\n",
    "    return species_name\n",
    "\n",
    "species[1] = species[0].apply(lambda x: get_species_name(x))\n",
    "species.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df = merged_ontology_kg[merged_ontology_kg[':TYPE'] == 'only_in_taxon'][[':START_ID',':END_ID']]\n",
    "species['Species'] = species[1]  \n",
    "species.drop(columns=[1], inplace=True) \n",
    "species[0] = \"http://purl.obolibrary.org/obo/NCBITaxon_\" + species[0]    \n",
    "species_df = pd.merge(species_df, species, left_on=':END_ID', right_on=0, how='left').drop(columns=[0])\n",
    "species_df.head(n=3)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719389cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Human_protein'], inplace=True)\n",
    "df = pd.merge(df, species_df, left_on=':ID', right_on=':START_ID', how='left').drop(columns=[':START_ID',':END_ID'])\n",
    "df.to_pickle(unprocessed_property_data_location + 'obo_merged.pkl')\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(unprocessed_property_data_location + 'obo_merged.pkl')\n",
    "df2 = pd.read_pickle(unprocessed_property_data_location + 'obo2.pkl')\n",
    "df = pd.merge(df1, df2, on=':ID', how='left')\n",
    "df['Type_x'] = df['Type_x'].apply(lambda x: x if isinstance(x, set) else set())\n",
    "df['Type_y'] = df['Type_y'].apply(lambda x: x if isinstance(x, set) else set())\n",
    "df['Type'] = df.apply(lambda row: row['Type_x'].union(row['Type_y']), axis=1).apply(lambda items: {i for i in items})\n",
    "df.drop(columns=['Type_x', 'Type_y'], inplace=True)\n",
    "df.to_csv(unprocessed_property_data_location + 'obo.csv', index=None)\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754b8ec",
   "metadata": {},
   "source": [
    "We add and adjust nodes types according to the information extracted from the ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(unprocessed_property_data_location + 'obo.csv')\n",
    "\n",
    "def safe_to_set(x):\n",
    "    if pd.isna(x) or x.strip() == '' or x.strip() in ['set()', '{}']:\n",
    "        return set()\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(f\"Errore nel parsing: {x!r}\")\n",
    "        return set()\n",
    "\n",
    "df['Synonym'] = df['Synonym'].apply(safe_to_set)\n",
    "df['Type'] = df['Type'].apply(safe_to_set)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f8059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of nodes: ' + str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db4c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full mapping for all node types in RNA-KG\n",
    "RNAonly = False # when false all nodes are considered otherwise only RNA nodes are selected\n",
    "\n",
    "def uri2ntype(uri: str)->Union[str,None]:\n",
    "    \n",
    "    retval = None\n",
    "    \n",
    "    if not RNAonly:    \n",
    "        if (\"http://purl.obolibrary.org/obo/MONDO\" in uri) or (\"purl.obolibrary.org/obo/DOID\" in uri) or\\\n",
    "            (\"ghr.nlm.nih.gov/condition\" in uri) or (\"rarediseases.info.nih.gov/diseases\" in uri):\n",
    "            retval = \"Disease\"\n",
    "        elif (\"purl.obolibrary.org/obo/IDO\" in uri):\n",
    "            retval = \"Disease, Infectious_disease\"\n",
    "        elif (\"purl.obolibrary.org/obo/MFOMD\" in uri):\n",
    "            retval = \"Disease, Mental_disease\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/GO\" in uri):\n",
    "            retval = \"GO\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/CHR\" in uri):\n",
    "            retval = \"Chromosome\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/SO\" in uri):\n",
    "            retval = \"Genomic_feature\"\n",
    "        elif (\"//purl.obolibrary.org/obo/VO\" in uri):\n",
    "            retval = \"Vaccine\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/CHEBI\" in uri): \n",
    "            retval = \"Chemical\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/PR\" in uri) or (\"http://purl.obolibrary.org/obo/vo/ontorat/PR\" in uri): \n",
    "            retval = \"Protein\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/PW\" in uri): \n",
    "            retval = \"Pathway\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/FOODON\" in uri): \n",
    "            retval = \"Food\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/MF\" in uri): \n",
    "            retval = \"Mental_functioning\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/OGMS\" in uri): \n",
    "            retval = \"General_medical_science\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/MAXO\" in uri): \n",
    "            retval = \"Medical_action\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/NBO\" in uri):\n",
    "            retval = \"Neuro_behaviour\"\n",
    "        elif  (\"http://purl.obolibrary.org/obo/CARO\" in uri) or (\"http://purl.obolibrary.org/obo/UBERON\" in uri) or\\\n",
    "            (\"http://sig.uw.edu/fma\" in uri) or (\"http://purl.obolibrary.org/obo/FMA\" in uri): \n",
    "            retval = \"Anatomy\"  \n",
    "        elif  (\"http://purl.obolibrary.org/obo/NCIT\" in uri): \n",
    "            retval = \"NCI_thesaurus\" \n",
    "        elif (\"http://purl.obolibrary.org/obo/FBbt\" in uri):\n",
    "            retval = \"Anatomy, Drosophila_anatomy\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/CL\" in uri) or (\"http://www.ebi.ac.uk/cellline\" in uri): \n",
    "            retval = \"Cell\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/HP\" in uri) or (\"http://purl.obolibrary.org/obo/PATO\" in uri) or\\\n",
    "            (\"http://purl.obolibrary.org/obo/UPHENO\" in uri): \n",
    "            retval = \"Phenotype\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/GNO\" in uri): \n",
    "            retval = \"Glycan\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/BFO\" in uri): \n",
    "            retval = \"Basic_formal\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/ENVO\" in uri): \n",
    "            retval = \"Environment\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/ECTO\" in uri): \n",
    "            retval = \"Environmental_exposure\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/PO\" in uri): \n",
    "            retval = \"Plant\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/FAO\" in uri): \n",
    "            retval = \"Anatomy, Fungal_anatomy\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/MOD\" in uri): \n",
    "            retval = \"Protein_modification\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/OPL\" in uri): \n",
    "            retval = \"Parasite_lifecycle\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/MPATH\" in uri): \n",
    "            retval = \"Disease, Mouse_pathology\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/OBA\" in uri): \n",
    "            retval = \"Trait\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/DDANAT\" in uri): \n",
    "            retval = \"Anatomy, Dictyostelium_discoideum_anatomy\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/OAE\" in uri): \n",
    "            retval = \"Adverse_events\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/BTO\" in uri): \n",
    "            retval = \"Anatomy, Tissue\"\n",
    "        elif (\"www.ncbi.nlm.nih.gov/gene\" in uri) or (\"http://purl.obolibrary.org/obo/OGG\" in uri) or\\\n",
    "            (\"http://birdgenenames.org/cgnc/GeneReport?id=\" in uri) or (\"http://www.genenames.org/cgi-bin/gene_symbol_report?hgnc_id=\" in uri):\n",
    "            retval = \"Gene\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/OGG\" in uri):\n",
    "            retval = \"Genome\"\n",
    "        elif (\"purl.obolibrary.org/obo/NCBITaxon\" in uri): \n",
    "            retval = \"Species\"\n",
    "        elif (\"purl.obolibrary.org/obo/BSPO\" in uri): \n",
    "            retval = \"Spatial_concept\"\n",
    "        elif (\"purl.obolibrary.org/obo/OPMI\" in uri): \n",
    "            retval = \"Precision_medicine\"\n",
    "        elif (\"bigdata.ibp.ac.cn/SmProt/SmProt.php?ID\" in uri): \n",
    "            retval = \"Protein, Small_protein\"\n",
    "        elif (\"snomedct\" in uri) or (\"SNOMEDCT\" in uri): \n",
    "            retval = \"Snomed_thesaurus\"\n",
    "        elif (\"http://www.ebi.ac.uk/efo/EFO\" in uri): \n",
    "            retval = \"Experimental_factor\"\n",
    "        elif (\"https://go.drugbank.com/drugs/\" in uri): \n",
    "            retval = \"Drug\"\n",
    "        elif (\"http://purl.obolibrary.org/obo/HsapDv\" in uri): \n",
    "            retval = \"Human_developmental_stage\"\n",
    "        elif (\"http://www.w3.org/2002/07/owl#Nothing\" in uri): \n",
    "            retval = \"owlNothing\"\n",
    "            \n",
    "    else:\n",
    "        retval = np.nan\n",
    "\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af823a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ntypes_list = []\n",
    "for u in tqdm(df[\":ID\"].values):\n",
    "    nty = uri2ntype(u)\n",
    "    ntypes_list.append(nty)\n",
    "\n",
    "df.loc[:,\":TYPE\"] = ntypes_list\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[':TYPE'].unique())\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f76af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unassigned node types:\")\n",
    "print(df[df[':TYPE'].isna()]) # Must be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[':TYPE'] = df[':TYPE'].str.split(\", \").apply(lambda items: {i for i in items})\n",
    "df[':TYPE'] = df.apply(lambda row: row[':TYPE'].union(row['Type']), axis=1).apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "df.drop(columns=['Type'], inplace=True)\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bebf39",
   "metadata": {},
   "source": [
    "Finally, we save nodes.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_entities_in_KG = pd.read_pickle(unprocessed_property_data_location + 'db_entities_in_KG.pkl')\n",
    "db_entities_in_KG[0] = db_entities_in_KG[0].astype(str)\n",
    "db_entities = pd.read_pickle(unprocessed_property_data_location + 'db_entities.pkl')\n",
    "db_entities['KG_ID'] = db_entities['KG_ID'].astype(str)\n",
    "#db_entities = db_entities[db_entities['KG_ID'].isin(db_entities_in_KG[0])] # If you want to filter the entities according to the KG\n",
    "\n",
    "obo = df.copy()\n",
    "obo['Synonym'] = obo['Synonym'].apply(lambda x: x if isinstance(x, set) else set())\n",
    "obo['Synonym'] = obo['Synonym'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "obo['KG_ID'] = obo[':ID'].str.replace(\"http://purl.obolibrary.org/obo/\", \"\").str.replace(\"https://go.drugbank.com/drugs/\", \"\")\n",
    "obo['OBO_ID'] = np.where(\n",
    "    obo[':ID'].str.startswith(\"http://purl.obolibrary.org/obo/\"),\n",
    "    obo[':ID'].str.replace(\"http://purl.obolibrary.org/obo/\", \"\").str.replace(\"_\", \":\"),\n",
    "    np.nan\n",
    ")\n",
    "obo['DrugBank_ID'] = np.where(\n",
    "    obo[':ID'].str.startswith(\"https://go.drugbank.com/drugs/\"),\n",
    "    obo[':ID'].str.replace(\"https://go.drugbank.com/drugs/\", \"\"),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "obo['DrugBank_ID'] = \"DrugBank:\" + obo['DrugBank_ID']\n",
    "obo['ID'] = obo['OBO_ID'].fillna(obo['DrugBank_ID'])\n",
    "obo = obo.drop(columns=['OBO_ID','DrugBank_ID'])\n",
    "\n",
    "nodes = pd.concat([db_entities, obo], ignore_index=True)\n",
    "nodes.rename(columns={':ID':'URI:ID'}, inplace=True)\n",
    "nodes.drop_duplicates(subset=['URI:ID'], keep='first', inplace=True)\n",
    "nodes.to_csv(processed_data_location + 'nodes.csv', index=None)\n",
    "nodes.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb554884",
   "metadata": {},
   "source": [
    "For each edge file (.pkl) in unprocessed_edge_data_location, keep only the edges for which the ends are contained in nodes and map identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all names of edges' properties\n",
    "sett = set()\n",
    "for filename in os.listdir(unprocessed_edge_data_location):\n",
    "    if filename.endswith('.pkl'):\n",
    "        print(pd.read_pickle(unprocessed_edge_data_location + filename).columns)\n",
    "        for i in pd.read_pickle(unprocessed_edge_data_location + filename).columns:\n",
    "            sett.add(i)\n",
    "sett\n",
    "\n",
    "'''\n",
    "sett = {':END_ID', ':START_ID', ':TYPE',  'Abundance',  'Binding_pos', 'Distance', 'Drug', 'Exon', 'FDR', 'FPKM', 'Fold_Change', 'GO_evidence',\n",
    "         'GeneMANIA_weight', 'Interactor', 'Knockdown_percentage', 'Location', 'Maximum_RPM', 'Method', 'Minimum_free_energy_kcal_mol', 'Mutation',\n",
    "         'Number_of_oligos', 'Position', 'PubMedID', 'RCI', 'RNAsister_score', 'Regulator', 'Rfam_score', 'Source', 'TANRIC_score', 'TPM', 'TYPE',\n",
    "         'Weighted_CS_score', 'log2FC', 'miRDB_score', 'miTG_score', 'microT_score', 'p-value', 'zScore'}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76034b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(processed_data_location + 'nodes.csv')\n",
    "nodes_map = nodes[['KG_ID','URI:ID']].rename(columns={'URI:ID':':ID'})\n",
    "\n",
    "for filename in os.listdir(unprocessed_edge_data_location):\n",
    "    if filename.endswith('.pkl'):\n",
    "        print(\"Processing:\", filename)\n",
    "        df = pd.read_pickle(unprocessed_edge_data_location + filename)\n",
    "        df[':START_ID'] = df[':START_ID'].astype(str)\n",
    "        df[':END_ID'] = df[':END_ID'].astype(str)\n",
    "        df = df.drop_duplicates(subset=[':START_ID', ':END_ID'], keep='first')\n",
    "        df = df.merge(nodes_map, left_on=':START_ID', right_on='KG_ID', how='inner').drop(\n",
    "            columns=[':START_ID','KG_ID']).rename(columns={':ID':':START_ID'})\n",
    "        df = df.merge(nodes_map, left_on=':END_ID', right_on='KG_ID', how='inner').drop(\n",
    "            columns=[':END_ID','KG_ID']).rename(columns={':ID':':END_ID'})\n",
    "        df['Source'] = df['Source'].apply(lambda items: [i for i in items]).apply(json.dumps)\n",
    "        cols = df.columns\n",
    "        if 'TYPE' in cols:\n",
    "            df.rename(columns={'TYPE':':TYPE'}, inplace=True)\n",
    "        if ':TYPE' not in cols:\n",
    "            df[':TYPE'] = filename.split('_', 1)[-1].rsplit('_', 1)[0]\n",
    "        if 'Method' in cols:\n",
    "            df['Method'] = df['Method'].apply(lambda items: [i for i in items if i != 'nan' and pd.notna(i)]\n",
    "                                              ).apply(json.dumps)\n",
    "        if 'Location' in cols:\n",
    "            df['Location'] = df['Location'].apply(lambda items: [i for i in items if i != 'nan' and pd.notna(i)]\n",
    "                                                  ).apply(json.dumps)\n",
    "            df.rename(columns={'Location':'Context'}, inplace=True)\n",
    "        if 'GO_evidence' in cols:\n",
    "            df['GO_evidence'] = df['GO_evidence'].apply(lambda items: [i for i in items if i != 'nan' and pd.notna(i)]\n",
    "                                                        ).apply(json.dumps)\n",
    "        if 'PubMedID' in cols:\n",
    "            df['PubMedID'] = df['PubMedID'].apply(lambda items: [str(i) for i in items if str(i) != 'nan'\n",
    "                                                                 and pd.notna(i)]).apply(json.dumps)\n",
    "        if 'Mutation' in cols:\n",
    "            df['Mutation'] = df['Mutation'].apply(lambda items: [i for i in items if i != 'nan' and pd.notna(i)]\n",
    "                                                  ).apply(json.dumps)\n",
    "        if 'Interactor' in cols:\n",
    "            df['Interactor'] = df['Interactor'].apply(lambda items: [i for i in items if i != 'nan' and pd.notna(i)]\n",
    "                                                      ).apply(json.dumps)\n",
    "        if 'Regulator' in cols:\n",
    "            df['Regulator'] = df['Regulator'].apply(lambda items: [i for i in items if i != 'nan' and pd.notna(i)]\n",
    "                                                    ).apply(json.dumps)\n",
    "        if 'Exon' in cols:\n",
    "            df['Exon'] = df['Exon'].apply(lambda items: [i for i in items if i != 'nan' and pd.notna(i)]).apply(json.dumps)\n",
    "        if 'Drug' in cols:\n",
    "            df['Drug'] = df['Drug'].apply(lambda items: [i for i in items if i != 'nan' and pd.notna(i)]).apply(json.dumps)\n",
    "        if 'Knockdown_percentage' in cols:\n",
    "            df['Knockdown_percentage'] = df['Knockdown_percentage'].apply(lambda items: [i for i in items if i != 'nan' and\n",
    "                                                                                         pd.notna(i)]).apply(json.dumps)\n",
    "        if 'Binding_pos' in cols:\n",
    "            df['Binding_pos'] = df['Binding_pos'].apply(lambda items: [i for i in items if i != 'nan' and pd.notna(i)]\n",
    "                                                        ).apply(json.dumps)\n",
    "        df.to_csv(unprocessed_edge_data_location + filename.replace('.pkl', '') + \".csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55038fe",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Entity Linking\n",
    "Non-ontological entities must be linked to proper classes using the RDF's subClassOf relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b594e",
   "metadata": {},
   "source": [
    "* Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69cb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(processed_data_location + 'SO_GENE_TRANSCRIPT_VARIANT_TYPE_MAPPING.txt', sep='\\t', header=None)\n",
    "genes = genes[genes[0].astype(str).str[0].str.isdigit()]\n",
    "genes['Source'] = 'Entity_linking'\n",
    "genes[':START_ID'] = \"http://www.ncbi.nlm.nih.gov/gene/\" + genes[0].astype(str)\n",
    "genes[':END_ID'] = genes[1].str.replace(\"SO_\", 'http://purl.obolibrary.org/obo/SO_')\n",
    "genes[':TYPE'] = 'subclassof'\n",
    "genes = genes[[':START_ID', ':END_ID', ':TYPE', 'Source']]\n",
    "genes.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ad31b",
   "metadata": {},
   "source": [
    "* RNAcentral + Ensembl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_el = pd.read_pickle(unprocessed_property_data_location + 'rnacentral_el.pkl')\n",
    "rnacentral_el[':START_ID'] = \"https://rnacentral.org/rna/\" + rnacentral_el['Name'].astype(str) + '_9606'\n",
    "rnacentral_el[':TYPE'] = 'subclassof'\n",
    "rnacentral_el['Source'] = 'Entity_linking'\n",
    "rnacentral_el = rnacentral_el[[':START_ID', 'Name', 'Category', ':TYPE', 'Source']]\n",
    "rnacentral_el.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = pd.read_csv(processed_data_location + 'SO_GENE_TRANSCRIPT_VARIANT_TYPE_MAPPING.txt', sep='\\t', header=None)\n",
    "rna = rna[rna[0].str.startswith('ENST')]\n",
    "rna.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1cb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_map_ensembl = pd.read_csv(\n",
    "    processed_data_location + 'RNAcentral_MAP/ensembl.tsv',\n",
    "    sep='\\t', names=['RNAcentral ID', 'DB', 'Ensembl transcript ID', 'Organism', 'RNA category', 'Ensembl Gene ID'])\n",
    "rnacentral_map_human_ensembl = rnacentral_map_ensembl[rnacentral_map_ensembl['Organism'] == 9606].drop(\n",
    "    columns=['Organism', 'DB', 'RNA category', 'Ensembl Gene ID'])\n",
    "rnacentral_map_human_ensembl.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aded499",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = pd.merge(rna, rnacentral_map_human_ensembl, left_on=0, right_on='Ensembl transcript ID', how='left')\n",
    "rna['RNAcentral ID'] = rna['RNAcentral ID'].fillna(rna[0])\n",
    "rna = rna[['RNAcentral ID', 1]]\n",
    "rna.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_el = rnacentral_el[~rnacentral_el['Name'].isin(rna['RNAcentral ID'])]\n",
    "rnacentral_el.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9501d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_mapping_data = pd.read_excel(open(unprocessed_data_location + 'genomic_sequence_ontology_mappings.xlsx', 'rb'),\n",
    "                                 sheet_name='GenomicType_SO_Map_09Mar2020', header=0, engine='openpyxl')\n",
    "rna_mapping_data = rna_mapping_data[rna_mapping_data['Genomic'] == 'Transcript']\n",
    "rna_mapping_data = rna_mapping_data[['Term', 'SO ID']]\n",
    "rna_mapping_data = rna_mapping_data.sort_values(by='Term', key=lambda col: col.str.lower())\n",
    "\n",
    "new_rows = pd.DataFrame([\n",
    "    {'Term': 'RNase_P_RNA', 'SO ID': 'SO_0000386'},\n",
    "    {'Term': 'SRP_RNA', 'SO ID': 'SO_0000590'},\n",
    "    {'Term': 'Y_RNA', 'SO ID': 'SO_0000405'},\n",
    "    {'Term': 'hammerhead_ribozyme', 'SO ID': 'SO_0000380, SO_0000374'},\n",
    "    {'Term': 'ncRNA', 'SO ID': 'SO_0000655'},\n",
    "    {'Term': 'pre_miRNA', 'SO ID': 'SO_0001244, SO_0000276'},\n",
    "    {'Term': 'tRNA', 'SO ID': 'SO_0000253'},\n",
    "    {'Term': 'telomerase_RNA', 'SO ID': 'SO_0000390'},\n",
    "    {'Term': 'piRNA', 'SO ID': 'SO_0001035'},\n",
    "    {'Term': 'antisense_RNA', 'SO ID': 'SO_0000644'},\n",
    "    {'Term': 'precursor_RNA', 'SO ID': 'SO_0000835'},\n",
    "    {'Term': 'guide_RNA', 'SO ID': 'SO_0000602'},\n",
    "    {'Term': 'autocatalytically_spliced_intron', 'SO ID': 'SO_0000588'},\n",
    "    {'Term': 'RNase_MRP_RNA', 'SO ID': 'SO_0000385'},\n",
    "    {'Term': 'tmRNA', 'SO ID': 'SO_0000584'},\n",
    "    {'Term': 'other', 'SO ID': 'SO_0000655'},\n",
    "    {'Term': 'circRNA', 'SO ID': 'SO_0002291'},\n",
    "    {'Term': 'vault_RNA', 'SO ID': 'SO_0000404'},\n",
    "])\n",
    "\n",
    "rna_mapping_data = pd.concat([rna_mapping_data, new_rows], ignore_index=True)\n",
    "rna_mapping_data['SO ID'] = rna_mapping_data['SO ID'].str.split(\", \")\n",
    "rna_mapping_data = rna_mapping_data.explode('SO ID')\n",
    "rna_mapping_data.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58147522",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_el = pd.merge(rna_mapping_data, rnacentral_el, left_on='Term', right_on='Category', how='right')\n",
    "rnacentral_el.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d860243",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_el[rnacentral_el['SO ID'].isnull()]['Category'].unique() # must be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnacentral_el = rnacentral_el[['Name', 'SO ID']].rename(columns={'Name': 'RNAcentral ID', 'SO ID':1})\n",
    "rnacentral_el = pd.concat([rna, rnacentral_el]).drop_duplicates()\n",
    "rnacentral_el['Source'] = 'Entity_linking'\n",
    "rnacentral_el = rnacentral_el.rename(columns={'RNAcentral ID':':START_ID', 1:':END_ID'})\n",
    "rnacentral_el[':START_ID'] = rnacentral_el[':START_ID'].apply(\n",
    "    lambda val: f\"https://www.ensembl.org/Homo_sapiens/Transcript/Summary?t={val}\"\n",
    "        if val.startswith('ENST')\n",
    "        else f\"https://rnacentral.org/rna/{val}_9606\"\n",
    "        if val.startswith('URS')\n",
    "        else val\n",
    ")\n",
    "rnacentral_el[':TYPE'] = 'subclassof'\n",
    "rnacentral_el[':END_ID'] = \"http://purl.obolibrary.org/obo/\" + rnacentral_el[':END_ID'].astype(str)\n",
    "rnacentral_el.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576994f9",
   "metadata": {},
   "source": [
    "* Addgene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6239fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gRNA_gene = pd.read_csv(unprocessed_data_location + 'grna_sequences_addgene.txt', sep='\\t', dtype = {\"Plasmid ID\":str})  \n",
    "gRNA_gene = gRNA_gene[['Plasmid ID']].drop_duplicates().dropna()\n",
    "gRNA_gene[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0000602'\n",
    "gRNA_gene['Source'] = 'Entity_linking'\n",
    "gRNA_gene[':TYPE'] = 'subclassof'\n",
    "gRNA_gene[':START_ID'] = \"https://www.addgene.org/\" + gRNA_gene['Plasmid ID']\n",
    "gRNA_gene = gRNA_gene.drop(columns=['Plasmid ID'])\n",
    "gRNA_gene.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c367b8a",
   "metadata": {},
   "source": [
    "* [The MIT/ICBP siRNA Database](http://web.mit.edu/sirna/index.html) <br /> The MIT/ICBP siRNA Database has validated siRNA and shRNA sequences against over 100 genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87069194",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICBP = pd.read_html('http://web.mit.edu/sirna/sirnas-gene.html')\n",
    "ICBP = ICBP[1]\n",
    "ICBP.columns = ICBP.iloc[[0]].squeeze()\n",
    "ICBP.drop(0, inplace=True)\n",
    "ICBP[['ID#']] = ICBP[['ID#']] + '.html'\n",
    "ICBPsiRNA = ICBP.loc[(ICBP['siRNA'] == 'x') & (ICBP['Human'] == 'x')]\n",
    "ICBPsiRNA = ICBPsiRNA[['ID#']].drop_duplicates().dropna()\n",
    "ICBPsiRNA[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0000646'\n",
    "ICBPsiRNA['Source'] = 'Entity_linking'\n",
    "ICBPsiRNA[':TYPE'] = 'subclassof'\n",
    "\n",
    "ICBPshRNA = ICBP.loc[(ICBP['shRNA'] == 'x') & (ICBP['Human'] == 'x')] # shRNA\n",
    "ICBPshRNA = ICBPshRNA[['ID#']].drop_duplicates().dropna()\n",
    "ICBPshRNA[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0002031'\n",
    "ICBPshRNA['Source'] = 'Entity_linking'\n",
    "ICBPshRNA[':TYPE'] = 'subclassof'\n",
    "\n",
    "ICBP = pd.concat([ICBPsiRNA, ICBPshRNA])\n",
    "ICBP[':START_ID'] = \"http://web.mit.edu/sirna/sequences/results-\" + ICBP['ID#']\n",
    "ICBP = ICBP.drop(columns=['ID#'])\n",
    "ICBP.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166a9baf",
   "metadata": {},
   "source": [
    "* circBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af28694",
   "metadata": {},
   "outputs": [],
   "source": [
    "circbase = pd.read_csv(unprocessed_data_location + 'hsa_hg19_circRNA.txt', sep='\\t')\n",
    "circbase = circbase[['circRNA ID']].drop_duplicates().dropna()\n",
    "circbase[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0002291'\n",
    "circbase['Source'] = 'Entity_linking'\n",
    "circbase[':TYPE'] = 'subclassof'\n",
    "circbase[':START_ID'] = \"http://circbase.org/cgi-bin/singlerecord.cgi?id=\" + circbase['circRNA ID']\n",
    "circbase = circbase.drop(columns=['circRNA ID'])\n",
    "circbase.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caebb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translated ncRNA --> circular_mRNA\n",
    "RNA_anatomy = pd.read_excel(unprocessed_data_location + 'Translated ncRNA.xlsx')\n",
    "\n",
    "RNA_anatomy = RNA_anatomy[RNA_anatomy.Notes != 'It has been re-annotated as protein coding gene now']\n",
    "RNA_anatomy = RNA_anatomy[RNA_anatomy['Gene.ID'].notna()]\n",
    "circbase2 = pd.DataFrame(RNA_anatomy[(RNA_anatomy['Type']=='circRNA') & (RNA_anatomy['Name'].str.startswith('hsa_circ_'))]['Name'].unique())\n",
    "circbase2[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0002292'\n",
    "circbase2['Source'] = 'Entity_linking'\n",
    "circbase2[':TYPE'] = 'subclassof'\n",
    "circbase2[':START_ID'] = \"http://circbase.org/cgi-bin/singlerecord.cgi?id=\" + circbase2[0]\n",
    "circbase2 = circbase2.drop(columns=[0])\n",
    "circbase2.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a516d7b",
   "metadata": {},
   "source": [
    "* [eSkip-Finder](https://eskip-finder.org/cgi-bin/input.cgi) <br /> eSkip-Finder is the first machine learning-based design tool and database of antisense oligonucleotides (ASOs) for exon skipping. A significant challenge, however, is the difficulty in selecting an optimal target sequence for exon skipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASO_mRNA = pd.read_html(unprocessed_data_location + 'eSkip-Finder.html')[2]\n",
    "ASO_mRNA = ASO_mRNA[ASO_mRNA['Species'] == 'human']\n",
    "ASO_mRNA = ASO_mRNA[ASO_mRNA['Oligo name in literature'] != 'Null']\n",
    "ASO_mRNA = ASO_mRNA[['Oligo name in literature']]\n",
    "ASO_mRNA[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0000644, http://purl.obolibrary.org/obo/SO_0001247'\n",
    "ASO_mRNA['Source'] = 'Entity_linking'\n",
    "ASO_mRNA[':TYPE'] = 'subclassof'\n",
    "ASO_mRNA[':END_ID'] = ASO_mRNA[':END_ID'].str.split(\", \")\n",
    "ASO_mRNA = ASO_mRNA.explode(':END_ID')\n",
    "ASO_mRNA[':START_ID'] = 'https://eskip-finder.org/cgi-bin/input.cgi?' + ASO_mRNA['Oligo name in literature'].str.replace(r'\\s+', '_', regex=True)\n",
    "ASO_mRNA = ASO_mRNA.drop(columns=['Oligo name in literature'])\n",
    "ASO_mRNA.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2c45e",
   "metadata": {},
   "source": [
    "* tsRFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a08758",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsRNA = pd.read_csv(unprocessed_data_location + 'newID_20210202.txt', sep=\"\\t\")[['tsRNAid']].drop_duplicates().dropna()\n",
    "tsRNA[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0001172'\n",
    "tsRNA['Source'] = 'Entity_linking'\n",
    "tsRNA[':TYPE'] = 'subclassof'\n",
    "tsRNA[':START_ID'] = 'http://biomed.nscc-gz.cn/DB/tsRFun/searchDetail-tsRNA.php?tsRNAid=' + tsRNA['tsRNAid']\n",
    "tsRNA = tsRNA.drop(columns=['tsRNAid'])\n",
    "tsRNA.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835bb4c7",
   "metadata": {},
   "source": [
    "* tRFdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://genome.bioch.virginia.edu/trfdb/index.php\n",
    "tRF1_tRNA = pd.read_html(unprocessed_data_location+'trf1.html')[2]\n",
    "tRF1_tRNA.drop(columns=['Organism'],inplace=True)\n",
    "tRF1_tRNA.head()\n",
    "\n",
    "tRF3_tRNA = pd.read_html(unprocessed_data_location+'trf3.html')[2]\n",
    "tRF3_tRNA.drop(columns=['Organism'],inplace=True)\n",
    "\n",
    "tRF5_tRNA = pd.read_html(unprocessed_data_location+'trf5.html')[2]\n",
    "tRF5_tRNA.drop(columns=['Organism'],inplace=True)\n",
    "\n",
    "tRF_tRNA = pd.concat([tRF1_tRNA,tRF3_tRNA,tRF5_tRNA])\n",
    "tRF_tRNA = tRF_tRNA.drop(columns=['Experiment Info', 'Sequence'])\n",
    "tRF_tRNA['tRF ID'] = \"trfdb?\" + tRF_tRNA['tRF ID'].astype(str)\n",
    "tRF_tRNA = tRF_tRNA[['tRF ID']].drop_duplicates().dropna()\n",
    "tRF_tRNA[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0001172'\n",
    "tRF_tRNA['Source'] = 'Entity_linking'\n",
    "tRF_tRNA[':TYPE'] = 'subclassof'\n",
    "tRF_tRNA[':START_ID'] = 'http://genome.bioch.virginia.edu/trfdb/experiments_display.php?' + tRF_tRNA['tRF ID']\n",
    "tRF_tRNA = tRF_tRNA.drop(columns=['tRF ID'])\n",
    "tRF_tRNA.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf385f",
   "metadata": {},
   "source": [
    "* MINTBASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cm.jefferson.edu/MINTbase/InputController?g=GRCh37&d=y&v=g&e=1.0&cl=,4,5,11,12,16,18,19,21,22,26,27,#ttop\n",
    "tRF_tRNA2 = pd.read_csv(unprocessed_data_location+'MINTbase.txt',sep='\\t')[['License Plate (sequence derived)']].drop_duplicates().dropna()\n",
    "tRF_tRNA2[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0001172'\n",
    "tRF_tRNA2['Source'] = 'Entity_linking'\n",
    "tRF_tRNA2[':TYPE'] = 'subclassof'\n",
    "tRF_tRNA2[':START_ID'] = 'https://cm.jefferson.edu/MINTbase/InputController?v=g&g=GRCh37&fn=' + tRF_tRNA2['License Plate (sequence derived)']\n",
    "tRF_tRNA2 = tRF_tRNA2.drop(columns=['License Plate (sequence derived)'])\n",
    "tRF_tRNA2.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9b233",
   "metadata": {},
   "source": [
    "* TBDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "riboswitch_protein = pd.read_csv(unprocessed_data_location+'tbdb.csv', sep=',')[['accession_url']].drop_duplicates().dropna()\n",
    "riboswitch_protein[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0000035'\n",
    "riboswitch_protein['Source'] = 'Entity_linking'\n",
    "riboswitch_protein[':TYPE'] = 'subclassof'\n",
    "riboswitch_protein = riboswitch_protein.rename(columns={'accession_url':':START_ID'})\n",
    "riboswitch_protein.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7523755",
   "metadata": {},
   "source": [
    "* RSwitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27faaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "riboswitch_bactStrain = pd.read_csv(unprocessed_data_location + 'rswitch.csv', header=None)[[0]].drop_duplicates().dropna()\n",
    "riboswitch_bactStrain[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0000035'\n",
    "riboswitch_bactStrain['Source'] = 'Entity_linking'\n",
    "riboswitch_bactStrain[':TYPE'] = 'subclassof'\n",
    "riboswitch_bactStrain[':START_ID'] = 'https://penchovsky.atwebpages.com/applications.php?page=58?' + riboswitch_bactStrain[0]\n",
    "riboswitch_bactStrain = riboswitch_bactStrain.drop(columns=[0])\n",
    "riboswitch_bactStrain.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83e8f2",
   "metadata": {},
   "source": [
    "* ViroidDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f8e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "vRNA_ribozyme = pd.read_json(unprocessed_data_location + 'all.json').T \n",
    "\n",
    "# Extract ribozymes \n",
    "myre = re.compile(r\"\\n>> .*?\\n\")\n",
    "ribozyme = [myre.findall(i) for i in vRNA_ribozyme.ribozymes]\n",
    "ribozyme = [[j.replace(\"\\n\",'').replace(\">> \",'') for j in i] for i in ribozyme]\n",
    "\n",
    "vRNA_ribozyme = pd.concat([vRNA_ribozyme.reset_index().drop(columns=['index']), # Genome --> NCBI nuccore \n",
    "                           pd.Series(ribozyme)], axis=1)\n",
    "vRNA_ribozyme = vRNA_ribozyme.explode(0)\n",
    "vRNA_ribozyme[0] = vRNA_ribozyme[0].str.split().str[0]\n",
    "vRNA_ribozyme['accession'] = vRNA_ribozyme['accession'].str.split(\".\").str[0]\n",
    "vRNA_ribozyme = vRNA_ribozyme[vRNA_ribozyme.species == 'Hepatitis delta virus'][['accession']].drop_duplicates().dropna()\n",
    "vRNA_ribozyme[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0001200, http://purl.obolibrary.org/obo/SO_0001041'\n",
    "# they are all negative_sense_ssRNA_viral_sequence\n",
    "vRNA_ribozyme['Source'] = 'Entity_linking'\n",
    "vRNA_ribozyme[':TYPE'] = 'subclassof'\n",
    "vRNA_ribozyme[':END_ID'] = vRNA_ribozyme[':END_ID'].str.split(\", \")\n",
    "vRNA_ribozyme = vRNA_ribozyme.explode(':END_ID')\n",
    "vRNA_ribozyme[':START_ID'] = 'https://www.ncbi.nlm.nih.gov/nuccore/' + vRNA_ribozyme['accession']\n",
    "vRNA_ribozyme = vRNA_ribozyme.drop(columns=['accession'])\n",
    "vRNA_ribozyme.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae45c97",
   "metadata": {},
   "source": [
    "* Apta-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223fc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_protein = pd.read_csv(unprocessed_data_location + 'aptaindex.csv',names=['Label', 'ID', 'Target', 'Sequence'],skiprows=[0]) \n",
    "aptamer_protein['ID'] = 'aptamer-details/?id=' + aptamer_protein['ID'].astype(str)\n",
    "aptamer_protein = aptamer_protein[['ID']].drop_duplicates().dropna()\n",
    "aptamer_protein[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0000033'\n",
    "aptamer_protein['Source'] = 'Entity_linking'\n",
    "aptamer_protein[':TYPE'] = 'subclassof'\n",
    "aptamer_protein[':START_ID'] = 'https://www.aptagen.com/' + aptamer_protein['ID']\n",
    "aptamer_protein = aptamer_protein.drop(columns=['ID'])\n",
    "aptamer_protein.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415d8a0",
   "metadata": {},
   "source": [
    "* COSMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edf856",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic = pd.read_pickle(unprocessed_property_data_location + 'cosmic.pkl')[[':ID',':TYPE']]\n",
    "cosmic[':TYPE'] = cosmic[':TYPE'].str.replace('''[\"Variant\", \"Somatic_variant\", \"SNV\"]''',\"SNV\")\n",
    "cosmic[':TYPE'] = cosmic[':TYPE'].str.replace('''[\"Variant\", \"Somatic_variant\", \"Deletion\"]''',\"deletion\")\n",
    "cosmic[':TYPE'] = cosmic[':TYPE'].str.replace('''[\"Variant\", \"Somatic_variant\", \"Insertion\"]''',\"insertion\")\n",
    "cosmic[':TYPE'] = cosmic[':TYPE'].str.replace('''[\"Variant\", \"Somatic_variant\", \"Indel\"]''',\"indel\")\n",
    "cosmic[':TYPE'] = cosmic[':TYPE'].str.replace('''[\"substitution\"]''',\"substitution\")\n",
    "cosmic['SO_TERM'] = cosmic[':TYPE']\n",
    "\n",
    "cosmic.SO_TERM = cosmic.SO_TERM.replace('SNV', 'single nucleotide variant')\n",
    "print(cosmic.SO_TERM.unique())\n",
    "\n",
    "variant_mapping_data = pd.read_excel(open(unprocessed_data_location + 'genomic_sequence_ontology_mappings.xlsx', 'rb'),\n",
    "                                 sheet_name='GenomicType_SO_Map_09Mar2020', header=0, engine='openpyxl')\n",
    "variant_mapping_data = variant_mapping_data[variant_mapping_data['Genomic'] == 'Variant']\n",
    "variant_mapping_data = variant_mapping_data[['Term', 'SO ID']]\n",
    "\n",
    "print(variant_mapping_data['Term'].unique())\n",
    "\n",
    "cosmic = pd.merge(variant_mapping_data, cosmic, left_on='Term', right_on='SO_TERM', how='right')\n",
    "cosmic2 = cosmic.copy()[[':ID']].drop_duplicates()\n",
    "cosmic2['SO ID'] = 'SO_0001777'\n",
    "cosmic = pd.concat([cosmic, cosmic2]).drop(columns=['Term', 'SO_TERM'])\n",
    "cosmic[':TYPE'] = 'subclassof'\n",
    "cosmic['Source'] = 'Entity_linking'\n",
    "cosmic[':END_ID'] = 'http://purl.obolibrary.org/obo/' + cosmic['SO ID']\n",
    "cosmic[':START_ID'] = cosmic[':ID']\n",
    "cosmic = cosmic.drop(columns=['SO ID', ':ID'])\n",
    "cosmic.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c2aa0",
   "metadata": {},
   "source": [
    "* SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = pd.read_csv(processed_data_location + 'SO_GENE_TRANSCRIPT_VARIANT_TYPE_MAPPING.txt', sep='\\t', header=None)\n",
    "variant = variant[variant[0].str.startswith('rs')]\n",
    "variant['Source'] = 'Entity_linking'\n",
    "variant.rename(columns={0:':START_ID', 1:':END_ID'}, inplace=True)\n",
    "variant[':TYPE'] = 'subclassof'\n",
    "variant[':START_ID'] = \"https://www.ncbi.nlm.nih.gov/snp/\" + variant[':START_ID']\n",
    "variant[':END_ID'] = \"http://purl.obolibrary.org/obo/\" + variant[':END_ID']\n",
    "variant.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4e2bc",
   "metadata": {},
   "source": [
    "* Reactome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd7fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome = pd.read_csv(processed_data_location + 'REACTOME_PW_GO_MAPPINGS.txt', sep='\\t', header=None)\n",
    "reactome['Source'] = 'Entity_linking'\n",
    "reactome[':TYPE'] = 'subclassof'\n",
    "reactome.rename(columns={0:':START_ID', 1:':END_ID'}, inplace=True)\n",
    "reactome[':START_ID'] = \"https://reactome.org/content/detail/\" + reactome[':START_ID']\n",
    "reactome[':END_ID'] = \"http://purl.obolibrary.org/obo/\" + reactome[':END_ID']\n",
    "reactome.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad88cade",
   "metadata": {},
   "source": [
    "* Wikipathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de538035",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpwnonO_data = pd.read_csv('../resources/processed_data/DESC_WIKIPATHWAYS_MAP.txt', header=None, sep='\\t')[1]\n",
    "\n",
    "wpwnonO_data = pd.DataFrame(wpwnonO_data)\n",
    "wpwnonO_data[':END_ID'] = 'http://purl.obolibrary.org/obo/PW_0000001'\n",
    "wpwnonO_data['Source'] = 'Entity_linking'\n",
    "wpwnonO_data[':TYPE'] = 'subclassof'\n",
    "wpwnonO_data.rename(columns={1:':START_ID'}, inplace=True)\n",
    "wpwnonO_data[':START_ID'] = \"https://www.wikipathways.org/instance/\" + wpwnonO_data[':START_ID']\n",
    "wpwnonO_data.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79139d1f",
   "metadata": {},
   "source": [
    "* Biological roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3af72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['https://www.genome.gov/genetics-glossary/Tumor-Suppressor-Gene', 'https://www.genome.gov/genetics-glossary/Oncogene',\n",
    "        'https://www.genome.gov/genetics-glossary/General']\n",
    "role = pd.DataFrame({'Name': name})\n",
    "role[':END_ID'] = 'http://purl.obolibrary.org/obo/CHEBI_24432'\n",
    "role['Source'] = 'Entity_linking'\n",
    "role[':TYPE'] = 'subclassof'\n",
    "role.rename(columns={'Name':':START_ID'}, inplace=True)\n",
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77846013",
   "metadata": {},
   "source": [
    "* Small proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lncRNA_protein = pd.read_csv(unprocessed_data_location + 'sprotein_LncBook2.0.csv.gz') \n",
    "lncRNA_protein['SmProt ID'] = 'http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=' + lncRNA_protein['SmProt ID']\n",
    "lncRNA_protein['SmProt Protein Sequence'] = lncRNA_protein['SmProt Protein Sequence'].str.replace('*', '', regex=False)\n",
    "lncRNA_protein = lncRNA_protein[['SmProt ID']].drop_duplicates().dropna()\n",
    "\n",
    "RNA_anatomy = pd.read_excel(unprocessed_data_location + 'Translated ncRNA.xlsx').rename(columns={'cncRNAdb.ID':'SmProt ID'})\n",
    "RNA_anatomy['SmProt ID'] = \"https://www.rna-society.org/cncrnadb?\" + RNA_anatomy['SmProt ID']\n",
    "RNA_anatomy = RNA_anatomy[RNA_anatomy.Organism.str.contains('apiens')]\n",
    "RNA_anatomy = RNA_anatomy[RNA_anatomy.Notes != 'It has been re-annotated as protein coding gene now']\n",
    "RNA_anatomy = RNA_anatomy[['SmProt ID']].drop_duplicates().dropna()\n",
    "\n",
    "lncRNA_protein = pd.concat([lncRNA_protein, RNA_anatomy])\n",
    "lncRNA_protein[':END_ID'] = 'http://purl.obolibrary.org/obo/SO_0000104, http://purl.obolibrary.org/obo/PR_000018263'\n",
    "lncRNA_protein[':END_ID'] = lncRNA_protein[':END_ID'].str.split(\", \")\n",
    "lncRNA_protein = lncRNA_protein.explode(':END_ID')\n",
    "lncRNA_protein['Source'] = 'Entity_linking'\n",
    "lncRNA_protein[':TYPE'] = 'subclassof'\n",
    "lncRNA_protein.rename(columns={'SmProt ID':':START_ID'}, inplace=True)\n",
    "lncRNA_protein.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e14198",
   "metadata": {},
   "source": [
    "* Chemical modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tRNA_mod = pd.read_csv(edge_data_location+'modification-tRNA2314.txt', sep='\\t')[['Modification']].drop_duplicates().dropna()\n",
    "tRNA_mod[':END_ID'] = 'http://purl.obolibrary.org/obo/GO_0009451, http://purl.obolibrary.org/obo/SO_0001720'\n",
    "tRNA_mod[':END_ID'] = tRNA_mod[':END_ID'].str.split(\", \")\n",
    "tRNA_mod = tRNA_mod.explode(':END_ID')\n",
    "tRNA_mod['Source'] = 'Entity_linking'\n",
    "tRNA_mod[':TYPE'] = 'subclassof'\n",
    "tRNA_mod[':START_ID'] = 'https://genesilico.pl/modomics?' + tRNA_mod['Modification']\n",
    "tRNA_mod = tRNA_mod.drop(columns=['Modification'])\n",
    "tRNA_mod.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_linking = pd.concat([genes, rnacentral_el, gRNA_gene, ICBP, circbase, circbase2, ASO_mRNA, tsRNA, tRF_tRNA,\n",
    "                            tRF_tRNA2, riboswitch_protein, riboswitch_bactStrain, vRNA_ribozyme, aptamer_protein,\n",
    "                            cosmic, variant, reactome, wpwnonO_data, role, lncRNA_protein, tRNA_mod]).drop_duplicates()\n",
    "entity_linking = entity_linking[(entity_linking[':START_ID'].isin(nodes['URI:ID'])) & (entity_linking[':END_ID'].isin(nodes['URI:ID']))]\n",
    "entity_linking['Source'] = entity_linking['Source'].apply(lambda x: [x]).apply(json.dumps)\n",
    "entity_linking.to_csv(unprocessed_edge_data_location + 'entity_linking.csv', index=False)\n",
    "entity_linking.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e48427b",
   "metadata": {},
   "source": [
    "We outer join each CSV in unprocessed_edges with merged_ontology_kg to check for repeated relationships. We do that by excluding relationships we are sure can not occur in the merged_ontology_kg such as ones involving the db entities representing RNAs or COSMIC mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52771db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = set()\n",
    "for filename in os.listdir(unprocessed_edge_data_location):\n",
    "    if filename.endswith('.csv') and \"RNA\" not in filename and \"COSMIC\" not in filename and \"smallProtein\" not in filename and \"genome\" not in filename:\n",
    "        type.add(filename)\n",
    "list(type)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1cc5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = []\n",
    "for filename in tqdm(os.listdir(unprocessed_edge_data_location)):\n",
    "    if filename in list(type):\n",
    "        print(\"Processing:\", filename)\n",
    "        lod = pd.read_csv(unprocessed_edge_data_location + filename)\n",
    "        file.append(lod)\n",
    "lod = pd.concat(file, ignore_index=True)\n",
    "lod['Source'] = lod['Source'].str.replace('\\\"', '').str.replace('[', '').str.replace(']', '').str.split(', ')\n",
    "lod['Source'] = lod['Source'].apply(lambda x: set(x))\n",
    "lod.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ontology_kg = pd.read_csv(ontology_data_location + 'merged_ontology_kg.txt', sep='\\t', names=[':START_ID', ':TYPE', ':END_ID', 'Source'])\n",
    "merged_ontology_kg[':START_ID'] = merged_ontology_kg[':START_ID'].str.replace(\"http://identifiers.org/ncbigene/\", \"http://www.ncbi.nlm.nih.gov/gene/\")\n",
    "merged_ontology_kg[':END_ID'] = merged_ontology_kg[':END_ID'].str.replace(\"http://identifiers.org/ncbigene/\", \"http://www.ncbi.nlm.nih.gov/gene/\")\n",
    "merged_ontology_kg['Source'] = merged_ontology_kg['Source'].str.replace(\"\\'\", \"\", regex=True)\n",
    "merged_ontology_kg['Source'] = merged_ontology_kg['Source'].str.replace(\"]\", \"\").str.replace(\"[\", \"\")\n",
    "merged_ontology_kg = pd.concat([merged_ontology_kg, DrugBank])\n",
    "merged_ontology_kg = merged_ontology_kg.groupby([':START_ID', ':TYPE', ':END_ID']).agg({'Source':set}).reset_index()\n",
    "merged_ontology_kg.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc707f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ontology_and_lod_kg = pd.merge(merged_ontology_kg, lod, on=[':START_ID', ':TYPE', ':END_ID'], how='outer')\n",
    "merged_ontology_and_lod_kg['Source_x'] = merged_ontology_and_lod_kg['Source_x'].apply(lambda x: set() if pd.isna(x) else x)\n",
    "merged_ontology_and_lod_kg['Source_y'] = merged_ontology_and_lod_kg['Source_y'].apply(lambda x: set() if pd.isna(x) else x)\n",
    "merged_ontology_and_lod_kg['Source'] = merged_ontology_and_lod_kg.apply(lambda row: row['Source_x'].union(row['Source_y']), axis=1).apply(\n",
    "    lambda items: [i for i in items]).apply(json.dumps)\n",
    "merged_ontology_and_lod_kg.drop(columns=['Source_x', 'Source_y'], inplace=True)\n",
    "merged_ontology_and_lod_kg.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc515e",
   "metadata": {},
   "source": [
    "<!-- We append information of \"meta-edges\" from RO to each relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ro_graph = Graph()\n",
    "ro_graph.parse(ontology_data_location + 'ro_with_imports.owl')\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "\n",
    "def get_superproperties(axiom, ro_graph):\n",
    "    superproperties = set([str(axiom)])  # Initialize with the current property\n",
    "    direct_superproperties = [x for x in ro_graph.objects(axiom, RDFS.subPropertyOf)]  # Find direct superproperties of the axiom\n",
    "    for sp in direct_superproperties:\n",
    "        superproperties.update(get_superproperties(sp, ro_graph))  # Recurse on each superproperty\n",
    "    return superproperties\n",
    "\n",
    "cls = {x for x in gets_object_properties(ro_graph)}\n",
    "master_synonyms = {x for x in ro_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)}\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    labels = list({x for x in ro_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)})\n",
    "    labels = labels[0] if labels else np.nan\n",
    "    synonym = {str(i[2]).lower().strip().replace(\" \",\"_\").replace(\"-\",\"_\") for i in master_synonyms if x == i[0]}\n",
    "    desc = list({str(x).lower().strip() for x in ro_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)})\n",
    "    desc = desc[0] if desc else np.nan\n",
    "    superproperties = get_superproperties(x, ro_graph)\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {'Label': labels, 'Description': desc, 'Synonym': synonym, \"Hierarchy\": superproperties}\n",
    "\n",
    "ro_df = pd.DataFrame(relation_metadata_dict).T \n",
    "\n",
    "def clean_hierarchy(hierarchy, axiom): # Exclude the current axiom from its own superproperties hierarchy\n",
    "    if str(axiom) in hierarchy:\n",
    "        hierarchy.remove(str(axiom))\n",
    "    return ', '.join(hierarchy) if hierarchy else np.nan\n",
    "\n",
    "ro_df['Hierarchy'] = ro_df.apply(lambda row: clean_hierarchy(row['Hierarchy'], row.name), axis=1)\n",
    "uri_to_label = {}\n",
    "\n",
    "# We replace URIs with their labels in the hierarchy\n",
    "for s in ro_graph.subjects(RDFS.label, None):\n",
    "    labels = [str(o).replace(\" \", \"_\").replace(\"-\",\"_\") for o in ro_graph.objects(s, RDFS.label) if '@' not in str(o) or '@en' in str(o)]\n",
    "    if labels:\n",
    "        uri_to_label[str(s)] = labels[0]\n",
    "\n",
    "def replace_uris_with_labels(hierarchy):\n",
    "    if pd.isna(hierarchy) or not isinstance(hierarchy, str):\n",
    "        return set()\n",
    "    uris = hierarchy.split(', ')\n",
    "    labels = {uri_to_label.get(uri.strip(), uri) for uri in uris}\n",
    "    return labels if labels else set()\n",
    "\n",
    "ro_df['Hierarchy'] = ro_df['Hierarchy'].apply(replace_uris_with_labels)\n",
    "ro_df['Label'] = ro_df['Label'].str.replace(\" \",\"_\").str.replace(\"-\",\"_\")\n",
    "ro_df['Label'] = ro_df['Label'].dropna()\n",
    "ro_df = ro_df.reset_index(drop=True)\n",
    "\n",
    "ro_df = pd.concat([ro_df, pd.DataFrame([{\"Label\": \"subclassof\", \"Synonym\": set([\"is_a\"]), \"Description\": np.nan, \"Hierarchy\":set()}])], ignore_index=True)\n",
    "\n",
    "ro_df_neg = ro_df.copy()\n",
    "ro_df_neg['Label'] = \"not_\" + ro_df_neg['Label']\n",
    "ro_df_neg['Description'] = ro_df_neg['Description'].apply(lambda x: np.nan if pd.isna(x) else \"Negation of: \" + str(x))\n",
    "ro_df_neg['Hierarchy'] = ro_df_neg['Hierarchy'].apply(lambda x: set() if pd.isna(x) else {\"not_\" + i for i in x})\n",
    "ro_df_neg['Synonym'] = ro_df_neg['Synonym'].apply(lambda x: set() if pd.isna(x) else {\"not_\" + i for i in x})\n",
    "ro_df = pd.concat([ro_df, ro_df_neg])\n",
    "\n",
    "ro_df['Synonym'] = ro_df['Synonym'].apply(lambda x: json.dumps(list(x)))\n",
    "ro_df['Hierarchy'] = ro_df['Hierarchy'].apply(lambda x: json.dumps(list(x)))\n",
    "ro_df['Label'] = ro_df['Label']\n",
    "ro_df.rename(columns={'Hierarchy':'Parent'}).to_csv(unprocessed_edge_data_location + 'relation_metadata.csv', index=False)\n",
    "ro_df.head(n=3)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7075ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_ontology_and_lod_kg = pd.merge(merged_ontology_and_lod_kg, ro_df, left_on=':TYPE', right_on='Label', how='left').drop(columns=['Label'])\n",
    "merged_ontology_and_lod_kg.to_csv(processed_data_location + 'merged_ontology_and_lod_kg.csv', index=False)\n",
    "merged_ontology_and_lod_kg.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e4556",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(os.listdir(unprocessed_edge_data_location)):\n",
    "    if filename.endswith('.csv') and filename not in list(type):\n",
    "        print(\"Processing:\", filename)\n",
    "        df = pd.read_csv(unprocessed_edge_data_location + filename)\n",
    "        #df = pd.merge(df, ro_df, left_on=':TYPE', right_on='Label', how='left').drop(columns=['Label'])\n",
    "        df.to_csv(processed_data_location + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b74b67",
   "metadata": {},
   "source": [
    "***\n",
    "Fix Neo4j import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf53bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes = pd.read_csv(processed_data_location + 'nodes.csv', low_memory=False)\n",
    "df_nodes.rename(columns={':TYPE': ':LABEL','Genomic_location':'Genomic_coordinates:string[]',\n",
    "                   'Mutation':'Mutation:string[]', 'Synonym':'Synonym:string[]',\n",
    "                   'ID':'ID:string', 'Charge':'Charge:long','Mass':'Mass:double'}, inplace=True)\n",
    "df_nodes = df_nodes.drop(columns=['KG_ID'])\n",
    "\n",
    "for col in [':LABEL', 'Genomic_coordinates:string[]', 'Mutation:string[]', 'Synonym:string[]']:\n",
    "    df_nodes[col] = df_nodes[col].apply(lambda x: \";\".join([str(i).replace(\";\", \",\").strip() for i in ast.literal_eval(x)])  \n",
    "                                        if pd.notna(x) and isinstance(x, str) and x.startswith(\"[\") else x)\n",
    "    df_nodes[col] = df_nodes[col].replace(\"\", np.nan)\n",
    "\n",
    "df_nodes['Charge:long'] = df_nodes['Charge:long'].astype('Int64')\n",
    "df_nodes['ID:string'] = df_nodes['ID:string'].replace(r\"nan$\", np.nan, regex=True)\n",
    "df_nodes['ID:string'] = df_nodes['ID:string'].replace(r\"<NA>$\", np.nan, regex=True)\n",
    "df_nodes.loc[((df_nodes['Label'].fillna('').str.contains('RNA binding protein', case=False) |\n",
    "              df_nodes['Synonym:string[]'].fillna('').str.contains('RNA binding protein', case=False)) &\n",
    "              df_nodes['URI:ID'].fillna('').str.startswith('http://purl.obolibrary.org/obo/PR_')), ':LABEL'] += ';RBP'\n",
    "df_nodes.loc[((df_nodes['Label'].fillna('').str.contains('transcription factor', case=False) |\n",
    "              df_nodes['Synonym:string[]'].fillna('').str.contains('transcription factor', case=False)) &\n",
    "              df_nodes['URI:ID'].fillna('').str.startswith('http://purl.obolibrary.org/obo/PR_')), ':LABEL'] += ';TF'\n",
    "df_nodes.loc[df_nodes['Label'].fillna('').str.startswith('piR-'), ':LABEL'] += ';sncRNA;small_regulatory_ncRNA;piRNA'\n",
    "df_nodes.loc[df_nodes[':LABEL'].str.contains('RNA', na=False), 'Label'] = df_nodes.loc[\n",
    "    df_nodes[':LABEL'].str.contains('RNA', na=False), 'Label'].str.replace(\"(human) \", \"\", regex=False)\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\";nan;\",\";\")   \n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\";nan$\",\"\",regex=True)\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"2MOe\",\"2MOe_ASO\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"2OMOE\",\"2OMOE_ASO\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"2OMe\",\"2OMe_ASO\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"aptamer\",\"Aptamer\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"bacterial_RNA\",\"Bacterial_RNA\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"enzymatic_RNA\",\"Enzymatic_RNA\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"ribozyme\",\"Ribozyme\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"hammerhead_Ribozyme\",\"Hammerhead_ribozyme\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"intron\",\"Intron\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"retained_Intron\",\"Retained_intron\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"modified PMO\",\"Modified_PMO\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"unModified_PMO\",\"Unmodified_PMO\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"oligo\",\"Oligo\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"antisense_Oligonucleotide\",\"Antisense_oligonucleotide\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"RNA_Antisense_oligonucleotide\",\"RNA_antisense_oligonucleotide\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"precursor_RNA\",\"Precursor_RNA\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"riboswitch\",\"Riboswitch\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"small_regulatory_ncRNA\",\"Small_regulatory_ncRNA\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"substitution\",\"Variant;Somatic_variant;Substitution\")\n",
    "df_nodes[':LABEL'] = df_nodes[':LABEL'].str.replace(\"telomerase_RNA\",\"Telomerase_RNA\")\n",
    "\n",
    "df_nodes.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ontology_kg = pd.read_csv(processed_data_location + 'merged_ontology_and_lod_kg.csv', low_memory=False)\n",
    "\n",
    "merged_ontology_kg['Source'] = merged_ontology_kg['Source'].astype(str)\n",
    "merged_ontology_kg['Source'] = merged_ontology_kg['Source'].str.replace(\"\\\"\", \"\", regex=True)\n",
    "merged_ontology_kg['Source'] = merged_ontology_kg['Source'].str.replace(\"[\", \"\")\n",
    "merged_ontology_kg['Source'] = merged_ontology_kg['Source'].str.replace(\"]\", \"\")\n",
    "merged_ontology_kg['Source'] = merged_ontology_kg['Source'].str.split(\", \")\n",
    "merged_ontology_kg['Source'] = merged_ontology_kg['Source'].apply(lambda x: list(x)).apply(json.dumps)\n",
    "\n",
    "merged_ontology_kg.rename(columns={'PubMedID':'PubMedID:string[]','GO_evidence':'GO_evidence:string[]', #'Hierarchy':'Hierarchy:string[]',\n",
    "                                   'TPM':'TPM:double', 'Context':'Context:string[]', 'Method':'Method:string[]', 'p-value':'p-value:double',\n",
    "                                   'FDR':'FDR:double', 'RNAsister_score':'RNAsister_score:double', 'Interactor':'Interactor:string[]', \n",
    "                                   'GeneMANIA_weight':'GeneMANIA_weight:double', 'Source':'Source:string[]'#,'Description':'Description:string',\n",
    "                                   #'Synonym':'Synonym:string[]',\n",
    "                                   }, inplace=True)\n",
    "\n",
    "for col in ['PubMedID:string[]','GO_evidence:string[]','Context:string[]', 'Method:string[]',\n",
    "            'Interactor:string[]', 'Source:string[]'#,'Hierarchy:string[]', 'Synonym:string[]'\n",
    "            ]:\n",
    "    merged_ontology_kg[col] = merged_ontology_kg[col].apply(lambda x: \";\".join([str(i).replace(\";\", \",\").strip() for i in ast.literal_eval(x)])\n",
    "                                                            if pd.notna(x) and isinstance(x, str) and x.startswith(\"[\") else x)  \n",
    "    merged_ontology_kg[col] = merged_ontology_kg[col].replace(\"\", np.nan)\n",
    "\n",
    "#merged_ontology_kg.to_csv(processed_data_location + \"test_edges1.csv\", index=False)\n",
    "merged_ontology_kg.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "avoid = ['OBO_not_expresses_RNA.csv', 'RNA_not_expressed_in_OBO.csv', 'RNA_is_causal_somatic_mutation_in_OBO.csv','test_nodes.csv',\n",
    "         'RNA_in_similarity_relationship_with_RNA.csv', 'RNA_causally_influenced_by_COSMIC.csv', 'merged_ontology_and_lod_kg.csv',\n",
    "         'COSMIC_causally_influences_RNA.csv', 'RNA_interacts_with_RNA.csv', 'test_edges1.csv', 'test.csv', 'nodes.csv', 'test_nodes.csv',\n",
    "         'test_edges1.csv', 'test_edges2.csv', 'test_edges3.csv', 'test_edges4.csv', 'test_edges5.csv', 'test_edges.csv']\n",
    "lst = []\n",
    "\n",
    "for filename in tqdm(os.listdir(processed_data_location)):\n",
    "    if filename.endswith('.csv') and filename not in avoid:\n",
    "        print(\"Processing:\", filename)\n",
    "        lst.append(pd.read_csv(processed_data_location + filename, low_memory=False))\n",
    "\n",
    "df_edges2 = pd.concat(lst, ignore_index=True).drop(columns=['Unnamed: 0','Synonym','Hierarchy','Description'])\n",
    "\n",
    "df_edges2['Source'] = df_edges2['Source'].astype(str)\n",
    "df_edges2['Source'] = df_edges2['Source'].str.replace(\"\\\"\", \"\", regex=True)\n",
    "df_edges2['Source'] = df_edges2['Source'].str.replace(\"[\", \"\")\n",
    "df_edges2['Source'] = df_edges2['Source'].str.replace(\"]\", \"\")\n",
    "df_edges2['Source'] = df_edges2['Source'].str.split(\", \")\n",
    "df_edges2['Source'] = df_edges2['Source'].apply(lambda x: list(x)).apply(json.dumps)\n",
    "df_edges2['Knockdown_percentage'] = df_edges2['Knockdown_percentage'].astype(str)\n",
    "df_edges2['Knockdown_percentage'] = df_edges2['Knockdown_percentage'].str.replace(\"\\\"\", \"\", regex=True)\n",
    "df_edges2['Knockdown_percentage'] = df_edges2['Knockdown_percentage'].str.replace(\"[\", \"\")\n",
    "df_edges2['Knockdown_percentage'] = df_edges2['Knockdown_percentage'].str.replace(\"]\", \"\")\n",
    "df_edges2['Exon'] = df_edges2['Exon'].astype(str)\n",
    "df_edges2['Exon'] = df_edges2['Exon'].str.replace(\"\\\"\", \"\", regex=True)\n",
    "df_edges2['Exon'] = df_edges2['Exon'].str.replace(\"[\", \"\")\n",
    "df_edges2['Exon'] = df_edges2['Exon'].str.replace(\"]\", \"\")\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "df_edges2.rename(columns={'Regulator':'Regulator:string[]','Interactor':'Interactor:string[]','Source':'Source:string[]',\n",
    "                          'PubMedID':'PubMedID:string[]','Method':'Method:string[]','Context':'Context:string[]',\n",
    "                          'Drug':'Drug:string[]',#'Synonym':'Synonym:string[]','Hierarchy':'Hierarchy:string[]',\n",
    "                          'Mutation':'Mutation:string[]','GO_evidence':'GO_evidence:string[]','Exon':'Exon:string',\n",
    "                          'RNAsister_score':'RNAsister_score:double','zScore':'zScore:double','Distance':'Distance:double',\n",
    "                          'Maximum_RPM':'Maximum_RPM:double','Binding_pos':'Binding_pos:string[]','microT_score':'microT_score:double',\n",
    "                          'Knockdown_percentage':'Knockdown_percentage:string','Number_of_oligos':'Number_of_oligos:long',\n",
    "                          'Position':'Position:string[]', 'TPM':'TPM:double', 'FPKM':'FPKM:double', 'RCI':'RCI:double',\n",
    "                          'Abundance':'Abundance:double', 'FDR':'FDR:double', 'p-value':'p-value:double', 'GeneMANIA_weight':'GeneMANIA_weight:double',\n",
    "                          'Fold_Change':'Fold_Change:double', 'miRDB_score':'miRDB_score:double', 'Weighted_CS_score':'Weighted_CS_score:double',\n",
    "                          'TANRIC_score':'TANRIC_score:double','Minimum_free_energy_kcal_mol':'Minimum_free_energy_kcal_mol:double',\n",
    "                          'log2FC':'log2FC:double'#,'Description':'Description:string'\n",
    "                          }, inplace=True)\n",
    "\n",
    "for col in ['Regulator:string[]','Interactor:string[]','Source:string[]', 'PubMedID:string[]','Method:string[]','Context:string[]','Binding_pos:string[]',\n",
    "            'Drug:string[]'#,'Synonym:string[]','Hierarchy:string[]'\n",
    "            , 'Mutation:string[]','GO_evidence:string[]','Position:string[]']:\n",
    "    df_edges2[col] = df_edges2[col].apply(lambda x: \";\".join([str(i).replace(\";\", \",\").strip() for i in ast.literal_eval(x)])\n",
    "                                                            if pd.notna(x) and isinstance(x, str) and x.startswith(\"[\") else x)  \n",
    "    df_edges2[col] = df_edges2[col].replace(\"\", np.nan)\n",
    "\n",
    "df_edges2['Number_of_oligos:long'] = df_edges2['Number_of_oligos:long'].astype('Int64') \n",
    "\n",
    "#df_edges2.to_csv(processed_data_location + \"test_edges2.csv\", index=False)\n",
    "df_edges2.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges3 = pd.read_csv(processed_data_location + 'RNA_interacts_with_RNA.csv', low_memory=False).drop(columns=['Unnamed: 0','Description','Synonym','Hierarchy'])\n",
    "df_edges3.rename(columns={'RNAsister_score':'RNAsister_score:double'}, inplace=True)\n",
    "df_edges3['Source'] = df_edges3['Source'].astype(str)\n",
    "df_edges3['Source'] = df_edges3['Source'].str.replace(\"\\\"\", \"\", regex=True)\n",
    "df_edges3['Source'] = df_edges3['Source'].str.replace(\"[\", \"\")\n",
    "df_edges3['Source'] = df_edges3['Source'].str.replace(\"]\", \"\")\n",
    "df_edges3['Source'] = df_edges3['Source'].str.split(\", \")\n",
    "df_edges3['Source'] = df_edges3['Source'].apply(lambda x: list(x)).apply(json.dumps)\n",
    "df_edges3.rename(columns={'Source':'Source:string[]', 'PubMedID':'PubMedID:string[]',\n",
    "                   #'Description':'Description:string','Synonym':'Synonym:string[]','Hierarchy':'Hierarchy:string[]',\n",
    "                   'Context':'Context:string[]','miTG_score':'miTG_score:double','Drug':'Drug:string[]','Mutation':'Mutation:string[]',\n",
    "                   'Method':'Method:string[]','FDR':'FDR:double','Distance':'Distance:double','RNAsister_score':'RNAsister_score:double'}, inplace=True)\n",
    "for col in ['Source:string[]','PubMedID:string[]','Context:string[]','Drug:string[]',\n",
    "            #'Synonym:string[]','Hierarchy:string[]',\n",
    "            'Mutation:string[]','Method:string[]']:\n",
    "    df_edges3[col] = df_edges3[col].apply(lambda x: \";\".join([str(i).replace(\";\", \",\").strip() for i in ast.literal_eval(x)])\n",
    "                                                            if pd.notna(x) and isinstance(x, str) and x.startswith(\"[\") else x)  \n",
    "    df_edges3[col] = df_edges3[col].replace(\"\", np.nan)\n",
    "\n",
    "#df_edges3.to_csv(processed_data_location + 'test_edges3.csv', index=False)\n",
    "df_edges3.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a92be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges4 = pd.concat([pd.read_csv(processed_data_location + 'RNA_causally_influenced_by_COSMIC.csv', low_memory=False),\n",
    "               pd.read_csv(processed_data_location + 'COSMIC_causally_influences_RNA.csv', low_memory=False)]).drop(\n",
    "                   columns=['Unnamed: 0', 'Description','Synonym','Hierarchy'])\n",
    "df_edges4['Source'] = df_edges4['Source'].astype(str)\n",
    "df_edges4['Source'] = df_edges4['Source'].str.replace(\"\\\"\", \"\", regex=True)\n",
    "df_edges4['Source'] = df_edges4['Source'].str.replace(\"[\", \"\")\n",
    "df_edges4['Source'] = df_edges4['Source'].str.replace(\"]\", \"\")\n",
    "df_edges4['Source'] = df_edges4['Source'].str.split(\", \")\n",
    "df_edges4['Source'] = df_edges4['Source'].apply(lambda x: list(x)).apply(json.dumps)\n",
    "df_edges4.rename(columns={'Source':'Source:string[]', 'PubMedID':'PubMedID:string[]', 'Interactor':'Interactor:string[]',\n",
    "                   #'Description':'Description:string','Synonym':'Synonym:string[]','Hierarchy':'Hierarchy:string[]',\n",
    "                   'Context':'Context:string[]'}, inplace=True)\n",
    "for col in ['Source:string[]','PubMedID:string[]','Interactor:string[]','Context:string[]'#,'Synonym:string[]','Hierarchy:string[]'\n",
    "            ]:\n",
    "    df_edges4[col] = df_edges4[col].apply(lambda x: \";\".join([str(i).replace(\";\", \",\").strip() for i in ast.literal_eval(x)])\n",
    "                                                            if pd.notna(x) and isinstance(x, str) and x.startswith(\"[\") else x)  \n",
    "    df_edges4[col] = df_edges4[col].replace(\"\", np.nan)\n",
    "\n",
    "#df_edges4.to_csv(processed_data_location + 'test_edges4.csv', index=False)\n",
    "df_edges4.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges5 = pd.concat([pd.read_csv(processed_data_location + 'RNA_is_causal_somatic_mutation_in_OBO.csv', low_memory=False),\n",
    "                pd.read_csv(processed_data_location + 'RNA_in_similarity_relationship_with_RNA.csv', low_memory=False),\n",
    "                pd.read_csv(processed_data_location + 'OBO_not_expresses_RNA.csv', low_memory=False),\n",
    "                pd.read_csv(processed_data_location + 'RNA_not_expressed_in_OBO.csv', low_memory=False)]).drop(columns=['Unnamed: 0',\n",
    "                                                                                                                        'Description','Synonym','Hierarchy'])\n",
    "df_edges5['Source'] = df_edges5['Source'].astype(str)\n",
    "df_edges5['Source'] = df_edges5['Source'].str.replace(\"\\\"\", \"\", regex=True)\n",
    "df_edges5['Source'] = df_edges5['Source'].str.replace(\"[\", \"\")\n",
    "df_edges5['Source'] = df_edges5['Source'].str.replace(\"]\", \"\")\n",
    "df_edges5['Source'] = df_edges5['Source'].str.split(\", \")\n",
    "df_edges5['Source'] = df_edges5['Source'].apply(lambda x: list(x)).apply(json.dumps)\n",
    "df_edges5.rename(columns={'Source':'Source:string[]', 'PubMedID':'PubMedID:string[]', 'Interactor':'Interactor:string[]',\n",
    "                  # 'Description':'Description:string','Synonym':'Synonym:string[]','Hierarchy':'Hierarchy:string[]',\n",
    "                   'Rfam_score':'Rfam_score:double','Mutation':'Mutation:string[]'}, inplace=True)\n",
    "for col in ['Source:string[]','PubMedID:string[]','Interactor:string[]','Mutation:string[]'#,'Synonym:string[]','Hierarchy:string[]'\n",
    "            ]:\n",
    "    df_edges5[col] = df_edges5[col].apply(lambda x: \";\".join([str(i).replace(\";\", \",\").strip() for i in ast.literal_eval(x)])\n",
    "                                                            if pd.notna(x) and isinstance(x, str) and x.startswith(\"[\") else x)  \n",
    "    df_edges5[col] = df_edges5[col].replace(\"\", np.nan)\n",
    "    \n",
    "#df_edges5.to_csv(processed_data_location + 'test_edges5.csv', index=False)\n",
    "df_edges5.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fbe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = pd.concat([merged_ontology_kg, df_edges2, df_edges3, df_edges4, df_edges5])#.drop(columns=['Description:string','Synonym:string[]','Hierarchy:string[]'])\n",
    "df_edges.drop_duplicates(subset=[':START_ID', ':TYPE', ':END_ID'], keep='first', inplace=True)\n",
    "df_edges.to_csv(processed_data_location + 'test_edges.csv', index=False)\n",
    "\n",
    "df_nodes = df_nodes[df_nodes['URI:ID'].isin(df_edges[':START_ID']) | df_nodes['URI:ID'].isin(df_edges[':END_ID'])]\n",
    "df_nodes.to_csv(processed_data_location + \"test_nodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3368025f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:LABEL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Label</th>\n",
       "      <th>Genomic_coordinates:string[]</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>URI:ID</th>\n",
       "      <th>Species</th>\n",
       "      <th>Structure</th>\n",
       "      <th>Mutation:string[]</th>\n",
       "      <th>Synonym:string[]</th>\n",
       "      <th>ID:string</th>\n",
       "      <th>FDA_indications</th>\n",
       "      <th>Charge:long</th>\n",
       "      <th>Mass:double</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Formula</th>\n",
       "      <th>InChIKey</th>\n",
       "      <th>CAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNA;ncRNA;lncRNA</td>\n",
       "      <td>homo sapiens (human) znf451 regulatory antisen...</td>\n",
       "      <td>ZNF451 regulatory antisense RNA 1</td>\n",
       "      <td>chr6:57173736-57174236-;chr6:57171005-57174236...</td>\n",
       "      <td>AUGGAGAGAUGUGUGUUACUUGUUAUGUGGCUCCCUAAAAAGAAAC...</td>\n",
       "      <td>https://rnacentral.org/rna/URS0000000055_9606</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RNAcentral:URS0000000055_9606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNA;ncRNA;sncRNA;Small_regulatory_ncRNA;piRNA</td>\n",
       "      <td>homo sapiens (human) pir-50304</td>\n",
       "      <td>piR-50304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UGCAACCAGUGUCUCUGCCUACCCGAUCCU</td>\n",
       "      <td>https://rnacentral.org/rna/URS0000000096_9606</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RNAcentral:URS0000000096_9606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RNA;ncRNA</td>\n",
       "      <td>homo sapiens (human) ncrna</td>\n",
       "      <td>ENSG00000251803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GGCUGGUCUGAAGGUAGUGAGUUAUCUCAAUUGAUUGUUCACCGUC...</td>\n",
       "      <td>https://rnacentral.org/rna/URS0000000098_9606</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RNAcentral:URS0000000098_9606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNA;ncRNA;lncRNA</td>\n",
       "      <td>homo sapiens (human) mef2c antisense rna 1</td>\n",
       "      <td>MEF2C antisense RNA 1</td>\n",
       "      <td>chr5:88889335-88967279+;chr5:88889335-88889480...</td>\n",
       "      <td>CUGCUCUCAUCACCUAUAUACUCUUCUCUCUGCCCGUCUCUGCUUC...</td>\n",
       "      <td>https://rnacentral.org/rna/URS00000000C9_9606</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RNAcentral:URS00000000C9_9606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNA;ncRNA;sncRNA;Small_regulatory_ncRNA;piRNA</td>\n",
       "      <td>homo sapiens (human) pir-55009</td>\n",
       "      <td>piR-55009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UGGCCCAGGAGGCCUCAAGGGCCCGGUGUU</td>\n",
       "      <td>https://rnacentral.org/rna/URS00000000D2_9606</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RNAcentral:URS00000000D2_9606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553991</th>\n",
       "      <td>Drug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://go.drugbank.com/drugs/DB16012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DrugBank:DB16012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553992</th>\n",
       "      <td>Chemical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{4-[(1E)-3-oxo-3-{2,3,4-trihydroxy-5-[hydroxy(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://purl.obolibrary.org/obo/CHEBI_194051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEBI:194051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>694.61000</td>\n",
       "      <td>C=1C=C(C=CC1\\C(\\[H])=C(/[H])\\C(C=2C(C(C(C3C(C(...</td>\n",
       "      <td>C27H34O19S</td>\n",
       "      <td>GPIKPRCHBDWSMS-ZZXKWVIFSA-N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553993</th>\n",
       "      <td>Chemical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4-tert-butylbenzoic acid [2-[(2-methoxy-3-dibe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://purl.obolibrary.org/obo/CHEBI_114246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEBI:114246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>431.48100</td>\n",
       "      <td>CC(C)(C)C1=CC=C(C=C1)C(=O)OCC(=O)NC2=C(C=C3C4=...</td>\n",
       "      <td>C26H25NO5</td>\n",
       "      <td>FUBUELHMJDMBQJ-UHFFFAOYSA-N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553994</th>\n",
       "      <td>Chemical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tetrakis(pyridine)silver(2+)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://purl.obolibrary.org/obo/CHEBI_30343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEBI:30343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>424.26796</td>\n",
       "      <td>C1=CC=[N](C=C1)[Ag++]([N]1=CC=CC=C1)([N]1=CC=C...</td>\n",
       "      <td>C20H20AgN4</td>\n",
       "      <td>OINDLVQQDGASSD-UHFFFAOYSA-N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553995</th>\n",
       "      <td>Protein;Human_protein</td>\n",
       "      <td>an ocia domain-containing protein 2 that is en...</td>\n",
       "      <td>OCIA domain-containing protein 2 (human)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MASASARGNQDKDAHFPPPSKQSLLFCPKSKLHIHRAEISKIMREC...</td>\n",
       "      <td>http://purl.obolibrary.org/obo/PR_Q56VL3</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR:Q56VL3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6553767 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                :LABEL  \\\n",
       "0                                     RNA;ncRNA;lncRNA   \n",
       "1        RNA;ncRNA;sncRNA;Small_regulatory_ncRNA;piRNA   \n",
       "2                                            RNA;ncRNA   \n",
       "3                                     RNA;ncRNA;lncRNA   \n",
       "4        RNA;ncRNA;sncRNA;Small_regulatory_ncRNA;piRNA   \n",
       "...                                                ...   \n",
       "6553991                                           Drug   \n",
       "6553992                                       Chemical   \n",
       "6553993                                       Chemical   \n",
       "6553994                                       Chemical   \n",
       "6553995                          Protein;Human_protein   \n",
       "\n",
       "                                               Description  \\\n",
       "0        homo sapiens (human) znf451 regulatory antisen...   \n",
       "1                           homo sapiens (human) pir-50304   \n",
       "2                               homo sapiens (human) ncrna   \n",
       "3               homo sapiens (human) mef2c antisense rna 1   \n",
       "4                           homo sapiens (human) pir-55009   \n",
       "...                                                    ...   \n",
       "6553991                                                NaN   \n",
       "6553992                                                NaN   \n",
       "6553993                                                NaN   \n",
       "6553994                                                NaN   \n",
       "6553995  an ocia domain-containing protein 2 that is en...   \n",
       "\n",
       "                                                     Label  \\\n",
       "0                        ZNF451 regulatory antisense RNA 1   \n",
       "1                                                piR-50304   \n",
       "2                                          ENSG00000251803   \n",
       "3                                    MEF2C antisense RNA 1   \n",
       "4                                                piR-55009   \n",
       "...                                                    ...   \n",
       "6553991                                                NaN   \n",
       "6553992  {4-[(1E)-3-oxo-3-{2,3,4-trihydroxy-5-[hydroxy(...   \n",
       "6553993  4-tert-butylbenzoic acid [2-[(2-methoxy-3-dibe...   \n",
       "6553994                       tetrakis(pyridine)silver(2+)   \n",
       "6553995           OCIA domain-containing protein 2 (human)   \n",
       "\n",
       "                              Genomic_coordinates:string[]  \\\n",
       "0        chr6:57173736-57174236-;chr6:57171005-57174236...   \n",
       "1                                                      NaN   \n",
       "2                                                      NaN   \n",
       "3        chr5:88889335-88967279+;chr5:88889335-88889480...   \n",
       "4                                                      NaN   \n",
       "...                                                    ...   \n",
       "6553991                                                NaN   \n",
       "6553992                                                NaN   \n",
       "6553993                                                NaN   \n",
       "6553994                                                NaN   \n",
       "6553995                                                NaN   \n",
       "\n",
       "                                                  Sequence  \\\n",
       "0        AUGGAGAGAUGUGUGUUACUUGUUAUGUGGCUCCCUAAAAAGAAAC...   \n",
       "1                           UGCAACCAGUGUCUCUGCCUACCCGAUCCU   \n",
       "2        GGCUGGUCUGAAGGUAGUGAGUUAUCUCAAUUGAUUGUUCACCGUC...   \n",
       "3        CUGCUCUCAUCACCUAUAUACUCUUCUCUCUGCCCGUCUCUGCUUC...   \n",
       "4                           UGGCCCAGGAGGCCUCAAGGGCCCGGUGUU   \n",
       "...                                                    ...   \n",
       "6553991                                                NaN   \n",
       "6553992                                                NaN   \n",
       "6553993                                                NaN   \n",
       "6553994                                                NaN   \n",
       "6553995  MASASARGNQDKDAHFPPPSKQSLLFCPKSKLHIHRAEISKIMREC...   \n",
       "\n",
       "                                                URI:ID       Species  \\\n",
       "0        https://rnacentral.org/rna/URS0000000055_9606  Homo sapiens   \n",
       "1        https://rnacentral.org/rna/URS0000000096_9606  Homo sapiens   \n",
       "2        https://rnacentral.org/rna/URS0000000098_9606  Homo sapiens   \n",
       "3        https://rnacentral.org/rna/URS00000000C9_9606  Homo sapiens   \n",
       "4        https://rnacentral.org/rna/URS00000000D2_9606  Homo sapiens   \n",
       "...                                                ...           ...   \n",
       "6553991          https://go.drugbank.com/drugs/DB16012           NaN   \n",
       "6553992    http://purl.obolibrary.org/obo/CHEBI_194051           NaN   \n",
       "6553993    http://purl.obolibrary.org/obo/CHEBI_114246           NaN   \n",
       "6553994     http://purl.obolibrary.org/obo/CHEBI_30343           NaN   \n",
       "6553995       http://purl.obolibrary.org/obo/PR_Q56VL3  Homo sapiens   \n",
       "\n",
       "        Structure Mutation:string[] Synonym:string[]  \\\n",
       "0             NaN               NaN              NaN   \n",
       "1             NaN               NaN              NaN   \n",
       "2             NaN               NaN              NaN   \n",
       "3             NaN               NaN              NaN   \n",
       "4             NaN               NaN              NaN   \n",
       "...           ...               ...              ...   \n",
       "6553991       NaN               NaN              NaN   \n",
       "6553992       NaN               NaN              NaN   \n",
       "6553993       NaN               NaN              NaN   \n",
       "6553994       NaN               NaN              NaN   \n",
       "6553995       NaN               NaN              NaN   \n",
       "\n",
       "                             ID:string FDA_indications  Charge:long  \\\n",
       "0        RNAcentral:URS0000000055_9606             NaN         <NA>   \n",
       "1        RNAcentral:URS0000000096_9606             NaN         <NA>   \n",
       "2        RNAcentral:URS0000000098_9606             NaN         <NA>   \n",
       "3        RNAcentral:URS00000000C9_9606             NaN         <NA>   \n",
       "4        RNAcentral:URS00000000D2_9606             NaN         <NA>   \n",
       "...                                ...             ...          ...   \n",
       "6553991               DrugBank:DB16012             NaN         <NA>   \n",
       "6553992                   CHEBI:194051             NaN            0   \n",
       "6553993                   CHEBI:114246             NaN            0   \n",
       "6553994                    CHEBI:30343             NaN            2   \n",
       "6553995                      PR:Q56VL3             NaN         <NA>   \n",
       "\n",
       "         Mass:double                                             SMILES  \\\n",
       "0                NaN                                                NaN   \n",
       "1                NaN                                                NaN   \n",
       "2                NaN                                                NaN   \n",
       "3                NaN                                                NaN   \n",
       "4                NaN                                                NaN   \n",
       "...              ...                                                ...   \n",
       "6553991          NaN                                                NaN   \n",
       "6553992    694.61000  C=1C=C(C=CC1\\C(\\[H])=C(/[H])\\C(C=2C(C(C(C3C(C(...   \n",
       "6553993    431.48100  CC(C)(C)C1=CC=C(C=C1)C(=O)OCC(=O)NC2=C(C=C3C4=...   \n",
       "6553994    424.26796  C1=CC=[N](C=C1)[Ag++]([N]1=CC=CC=C1)([N]1=CC=C...   \n",
       "6553995          NaN                                                NaN   \n",
       "\n",
       "            Formula                     InChIKey  CAS  \n",
       "0               NaN                          NaN  NaN  \n",
       "1               NaN                          NaN  NaN  \n",
       "2               NaN                          NaN  NaN  \n",
       "3               NaN                          NaN  NaN  \n",
       "4               NaN                          NaN  NaN  \n",
       "...             ...                          ...  ...  \n",
       "6553991         NaN                          NaN  NaN  \n",
       "6553992  C27H34O19S  GPIKPRCHBDWSMS-ZZXKWVIFSA-N  NaN  \n",
       "6553993   C26H25NO5  FUBUELHMJDMBQJ-UHFFFAOYSA-N  NaN  \n",
       "6553994  C20H20AgN4  OINDLVQQDGASSD-UHFFFAOYSA-N  NaN  \n",
       "6553995         NaN                          NaN  NaN  \n",
       "\n",
       "[6553767 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00bf670a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:START_ID</th>\n",
       "      <th>:TYPE</th>\n",
       "      <th>:END_ID</th>\n",
       "      <th>PubMedID:string[]</th>\n",
       "      <th>GO_evidence:string[]</th>\n",
       "      <th>TPM:double</th>\n",
       "      <th>Context:string[]</th>\n",
       "      <th>Method:string[]</th>\n",
       "      <th>FDR:double</th>\n",
       "      <th>RNAsister_score:double</th>\n",
       "      <th>Interactor:string[]</th>\n",
       "      <th>p-value:double</th>\n",
       "      <th>GeneMANIA_weight:double</th>\n",
       "      <th>Source:string[]</th>\n",
       "      <th>Regulator:string[]</th>\n",
       "      <th>Drug:string[]</th>\n",
       "      <th>Mutation:string[]</th>\n",
       "      <th>zScore:double</th>\n",
       "      <th>Distance:double</th>\n",
       "      <th>Maximum_RPM:double</th>\n",
       "      <th>Binding_pos:string[]</th>\n",
       "      <th>microT_score:double</th>\n",
       "      <th>Knockdown_percentage:string</th>\n",
       "      <th>Number_of_oligos:long</th>\n",
       "      <th>Exon:string</th>\n",
       "      <th>Position:string[]</th>\n",
       "      <th>FPKM:double</th>\n",
       "      <th>RCI:double</th>\n",
       "      <th>Abundance:double</th>\n",
       "      <th>Fold_Change:double</th>\n",
       "      <th>miRDB_score:double</th>\n",
       "      <th>Weighted_CS_score:double</th>\n",
       "      <th>TANRIC_score:double</th>\n",
       "      <th>Minimum_free_energy_kcal_mol:double</th>\n",
       "      <th>log2FC:double</th>\n",
       "      <th>miTG_score:double</th>\n",
       "      <th>Rfam_score:double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=...</td>\n",
       "      <td>subclassof</td>\n",
       "      <td>http://purl.obolibrary.org/obo/PR_000018263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entity_linking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=...</td>\n",
       "      <td>subclassof</td>\n",
       "      <td>http://purl.obolibrary.org/obo/SO_0000104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entity_linking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=...</td>\n",
       "      <td>subclassof</td>\n",
       "      <td>http://purl.obolibrary.org/obo/PR_000018263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entity_linking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=...</td>\n",
       "      <td>subclassof</td>\n",
       "      <td>http://purl.obolibrary.org/obo/SO_0000104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entity_linking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=...</td>\n",
       "      <td>subclassof</td>\n",
       "      <td>http://purl.obolibrary.org/obo/PR_000018263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entity_linking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653796</th>\n",
       "      <td>https://rnacentral.org/rna/URS0002349D57_9606</td>\n",
       "      <td>not_expressed_in</td>\n",
       "      <td>http://purl.obolibrary.org/obo/MONDO_0005108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LncBook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653797</th>\n",
       "      <td>https://rnacentral.org/rna/URS0002349D58_9606</td>\n",
       "      <td>not_expressed_in</td>\n",
       "      <td>http://purl.obolibrary.org/obo/GO_0007623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LncBook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653798</th>\n",
       "      <td>https://rnacentral.org/rna/URS0002349D58_9606</td>\n",
       "      <td>not_expressed_in</td>\n",
       "      <td>http://purl.obolibrary.org/obo/GO_0030154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LncBook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653799</th>\n",
       "      <td>https://rnacentral.org/rna/URS0002349D58_9606</td>\n",
       "      <td>not_expressed_in</td>\n",
       "      <td>http://purl.obolibrary.org/obo/GO_0051179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LncBook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653800</th>\n",
       "      <td>https://rnacentral.org/rna/URS0002349D58_9606</td>\n",
       "      <td>not_expressed_in</td>\n",
       "      <td>http://purl.obolibrary.org/obo/MONDO_0005108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LncBook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99937220 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 :START_ID             :TYPE  \\\n",
       "0        http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=...        subclassof   \n",
       "1        http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=...        subclassof   \n",
       "2        http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=...        subclassof   \n",
       "3        http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=...        subclassof   \n",
       "4        http://bigdata.ibp.ac.cn/SmProt/SmProt.php?ID=...        subclassof   \n",
       "...                                                    ...               ...   \n",
       "1653796      https://rnacentral.org/rna/URS0002349D57_9606  not_expressed_in   \n",
       "1653797      https://rnacentral.org/rna/URS0002349D58_9606  not_expressed_in   \n",
       "1653798      https://rnacentral.org/rna/URS0002349D58_9606  not_expressed_in   \n",
       "1653799      https://rnacentral.org/rna/URS0002349D58_9606  not_expressed_in   \n",
       "1653800      https://rnacentral.org/rna/URS0002349D58_9606  not_expressed_in   \n",
       "\n",
       "                                              :END_ID PubMedID:string[]  \\\n",
       "0         http://purl.obolibrary.org/obo/PR_000018263               NaN   \n",
       "1           http://purl.obolibrary.org/obo/SO_0000104               NaN   \n",
       "2         http://purl.obolibrary.org/obo/PR_000018263               NaN   \n",
       "3           http://purl.obolibrary.org/obo/SO_0000104               NaN   \n",
       "4         http://purl.obolibrary.org/obo/PR_000018263               NaN   \n",
       "...                                               ...               ...   \n",
       "1653796  http://purl.obolibrary.org/obo/MONDO_0005108               NaN   \n",
       "1653797     http://purl.obolibrary.org/obo/GO_0007623               NaN   \n",
       "1653798     http://purl.obolibrary.org/obo/GO_0030154               NaN   \n",
       "1653799     http://purl.obolibrary.org/obo/GO_0051179               NaN   \n",
       "1653800  http://purl.obolibrary.org/obo/MONDO_0005108               NaN   \n",
       "\n",
       "        GO_evidence:string[]  TPM:double Context:string[] Method:string[]  \\\n",
       "0                        NaN         NaN              NaN             NaN   \n",
       "1                        NaN         NaN              NaN             NaN   \n",
       "2                        NaN         NaN              NaN             NaN   \n",
       "3                        NaN         NaN              NaN             NaN   \n",
       "4                        NaN         NaN              NaN             NaN   \n",
       "...                      ...         ...              ...             ...   \n",
       "1653796                  NaN         NaN              NaN             NaN   \n",
       "1653797                  NaN         NaN              NaN             NaN   \n",
       "1653798                  NaN         NaN              NaN             NaN   \n",
       "1653799                  NaN         NaN              NaN             NaN   \n",
       "1653800                  NaN         NaN              NaN             NaN   \n",
       "\n",
       "         FDR:double  RNAsister_score:double Interactor:string[]  \\\n",
       "0               NaN                     NaN                 NaN   \n",
       "1               NaN                     NaN                 NaN   \n",
       "2               NaN                     NaN                 NaN   \n",
       "3               NaN                     NaN                 NaN   \n",
       "4               NaN                     NaN                 NaN   \n",
       "...             ...                     ...                 ...   \n",
       "1653796         NaN                     NaN                 NaN   \n",
       "1653797         NaN                     NaN                 NaN   \n",
       "1653798         NaN                     NaN                 NaN   \n",
       "1653799         NaN                     NaN                 NaN   \n",
       "1653800         NaN                     NaN                 NaN   \n",
       "\n",
       "         p-value:double  GeneMANIA_weight:double Source:string[]  \\\n",
       "0                   NaN                      NaN  Entity_linking   \n",
       "1                   NaN                      NaN  Entity_linking   \n",
       "2                   NaN                      NaN  Entity_linking   \n",
       "3                   NaN                      NaN  Entity_linking   \n",
       "4                   NaN                      NaN  Entity_linking   \n",
       "...                 ...                      ...             ...   \n",
       "1653796             NaN                      NaN         LncBook   \n",
       "1653797             NaN                      NaN         LncBook   \n",
       "1653798             NaN                      NaN         LncBook   \n",
       "1653799             NaN                      NaN         LncBook   \n",
       "1653800             NaN                      NaN         LncBook   \n",
       "\n",
       "        Regulator:string[] Drug:string[] Mutation:string[]  zScore:double  \\\n",
       "0                      NaN           NaN               NaN            NaN   \n",
       "1                      NaN           NaN               NaN            NaN   \n",
       "2                      NaN           NaN               NaN            NaN   \n",
       "3                      NaN           NaN               NaN            NaN   \n",
       "4                      NaN           NaN               NaN            NaN   \n",
       "...                    ...           ...               ...            ...   \n",
       "1653796                NaN           NaN               NaN            NaN   \n",
       "1653797                NaN           NaN               NaN            NaN   \n",
       "1653798                NaN           NaN               NaN            NaN   \n",
       "1653799                NaN           NaN               NaN            NaN   \n",
       "1653800                NaN           NaN               NaN            NaN   \n",
       "\n",
       "         Distance:double  Maximum_RPM:double Binding_pos:string[]  \\\n",
       "0                    NaN                 NaN                  NaN   \n",
       "1                    NaN                 NaN                  NaN   \n",
       "2                    NaN                 NaN                  NaN   \n",
       "3                    NaN                 NaN                  NaN   \n",
       "4                    NaN                 NaN                  NaN   \n",
       "...                  ...                 ...                  ...   \n",
       "1653796              NaN                 NaN                  NaN   \n",
       "1653797              NaN                 NaN                  NaN   \n",
       "1653798              NaN                 NaN                  NaN   \n",
       "1653799              NaN                 NaN                  NaN   \n",
       "1653800              NaN                 NaN                  NaN   \n",
       "\n",
       "         microT_score:double Knockdown_percentage:string  \\\n",
       "0                        NaN                         NaN   \n",
       "1                        NaN                         NaN   \n",
       "2                        NaN                         NaN   \n",
       "3                        NaN                         NaN   \n",
       "4                        NaN                         NaN   \n",
       "...                      ...                         ...   \n",
       "1653796                  NaN                         NaN   \n",
       "1653797                  NaN                         NaN   \n",
       "1653798                  NaN                         NaN   \n",
       "1653799                  NaN                         NaN   \n",
       "1653800                  NaN                         NaN   \n",
       "\n",
       "         Number_of_oligos:long Exon:string Position:string[]  FPKM:double  \\\n",
       "0                         <NA>         NaN               NaN          NaN   \n",
       "1                         <NA>         NaN               NaN          NaN   \n",
       "2                         <NA>         NaN               NaN          NaN   \n",
       "3                         <NA>         NaN               NaN          NaN   \n",
       "4                         <NA>         NaN               NaN          NaN   \n",
       "...                        ...         ...               ...          ...   \n",
       "1653796                   <NA>         NaN               NaN          NaN   \n",
       "1653797                   <NA>         NaN               NaN          NaN   \n",
       "1653798                   <NA>         NaN               NaN          NaN   \n",
       "1653799                   <NA>         NaN               NaN          NaN   \n",
       "1653800                   <NA>         NaN               NaN          NaN   \n",
       "\n",
       "         RCI:double  Abundance:double  Fold_Change:double  miRDB_score:double  \\\n",
       "0               NaN               NaN                 NaN                 NaN   \n",
       "1               NaN               NaN                 NaN                 NaN   \n",
       "2               NaN               NaN                 NaN                 NaN   \n",
       "3               NaN               NaN                 NaN                 NaN   \n",
       "4               NaN               NaN                 NaN                 NaN   \n",
       "...             ...               ...                 ...                 ...   \n",
       "1653796         NaN               NaN                 NaN                 NaN   \n",
       "1653797         NaN               NaN                 NaN                 NaN   \n",
       "1653798         NaN               NaN                 NaN                 NaN   \n",
       "1653799         NaN               NaN                 NaN                 NaN   \n",
       "1653800         NaN               NaN                 NaN                 NaN   \n",
       "\n",
       "         Weighted_CS_score:double  TANRIC_score:double  \\\n",
       "0                             NaN                  NaN   \n",
       "1                             NaN                  NaN   \n",
       "2                             NaN                  NaN   \n",
       "3                             NaN                  NaN   \n",
       "4                             NaN                  NaN   \n",
       "...                           ...                  ...   \n",
       "1653796                       NaN                  NaN   \n",
       "1653797                       NaN                  NaN   \n",
       "1653798                       NaN                  NaN   \n",
       "1653799                       NaN                  NaN   \n",
       "1653800                       NaN                  NaN   \n",
       "\n",
       "         Minimum_free_energy_kcal_mol:double  log2FC:double  \\\n",
       "0                                        NaN            NaN   \n",
       "1                                        NaN            NaN   \n",
       "2                                        NaN            NaN   \n",
       "3                                        NaN            NaN   \n",
       "4                                        NaN            NaN   \n",
       "...                                      ...            ...   \n",
       "1653796                                  NaN            NaN   \n",
       "1653797                                  NaN            NaN   \n",
       "1653798                                  NaN            NaN   \n",
       "1653799                                  NaN            NaN   \n",
       "1653800                                  NaN            NaN   \n",
       "\n",
       "         miTG_score:double  Rfam_score:double  \n",
       "0                      NaN                NaN  \n",
       "1                      NaN                NaN  \n",
       "2                      NaN                NaN  \n",
       "3                      NaN                NaN  \n",
       "4                      NaN                NaN  \n",
       "...                    ...                ...  \n",
       "1653796                NaN                NaN  \n",
       "1653797                NaN                NaN  \n",
       "1653798                NaN                NaN  \n",
       "1653799                NaN                NaN  \n",
       "1653800                NaN                NaN  \n",
       "\n",
       "[99937220 rows x 37 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafa36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.to_pickle(\"test_nodes.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14eb6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges.to_pickle(\"test_edges.pkl\")\n",
    "merged_ontology_kg.to_pickle(\"test_edges1.pkl\")\n",
    "df_edges2.to_pickle(\"test_edges2.pkl\")\n",
    "df_edges3.to_pickle(\"test_edges3.pkl\")\n",
    "df_edges4.to_pickle(\"test_edges4.pkl\")\n",
    "df_edges5.to_pickle(\"test_edges5.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9cc5e4",
   "metadata": {},
   "source": [
    "***\n",
    "### Remove unprocessed raw data\n",
    "Uncomment the following line if you want to delete the `unprocessed_data` subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9937cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.rmtree(unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a31daa",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "```\n",
    "@misc{cavalleri_e_2024_rna_kg,\n",
    "  author       = {Cavalleri, E},\n",
    "  title        = {RNA-KG},\n",
    "  year         = 2024,\n",
    "  doi          = {10.5281/zenodo.10078876},\n",
    "  url          = {https://doi.org/10.5281/zenodo.10078876}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
