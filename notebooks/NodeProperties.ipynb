{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aab6c15",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">RNA-KG node properties</p>\n",
    "    \n",
    "***\n",
    "***\n",
    "\n",
    "**Authors:** [ECavalleri](https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=emanuele.cavalleri@unimi.it)\n",
    "\n",
    "**GitHub Repositories:** [RNA-KG](https://github.com/AnacletoLAB/RNA-KG/)\n",
    "  \n",
    "<br>  \n",
    "  \n",
    "**Purpose:** This notebook serves as a script to add properties to entities within the RNA-centered Knowledge Graph.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Assumptions:**   \n",
    "- Property data write location ➞ `./resources/property_data`  \n",
    "- Ontologies ➞ `./resources/ontologies`    \n",
    "- Processed data write location ➞ `./resources/processed_data`  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Dependencies:**   \n",
    "- **Scripts**: This notebook utilizes several helper functions, which are stored in the [`data_utils.py`](https://github.com/callahantiff/PheKnowLator/blob/master/pkt_kg/utils/data_utils.py) and [`kg_utils.py`](https://github.com/callahantiff/PheKnowLator/blob/master/pkt_kg/utils/kg_utils.py) scripts.  \n",
    "- **Data**: All downloaded and generated data sources are provided through [10.5281/zenodo.10078876](https://zenodo.org/doi/10.5281/zenodo.10078876) dedicated repository. <u>This notebook will download everything that is needed for you</u>.  \n",
    "_____\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f86aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0254d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import datetime\n",
    "import glob\n",
    "import itertools\n",
    "import networkx\n",
    "import numpy\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import tarfile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import gffpandas.gffpandas as gffpd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "from reactome2py import content\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "\n",
    "from pkt_kg.utils import * \n",
    "from builds.ontology_cleaning import *\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6aa0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to store resources\n",
    "resource_data_location = '../resources/'\n",
    "\n",
    "# directory to use for unprocessed data\n",
    "unprocessed_data_location = '../resources/processed_data/unprocessed_data/'\n",
    "\n",
    "# directory to use for processed data\n",
    "processed_data_location = '../resources/processed_data/'\n",
    "\n",
    "# directory to write ontology data to\n",
    "ontology_data_location = '../resources/ontologies/'\n",
    "\n",
    "# directory to write edges data to\n",
    "edge_data_location = '../resources/edge_data/'\n",
    "\n",
    "# directory to write node properties to\n",
    "properties_location = '../resources/property_data/'\n",
    "\n",
    "# processed data url \n",
    "processed_url = 'https://storage.googleapis.com/pheknowlator/current_build/data/processed_data/'\n",
    "\n",
    "# original data url \n",
    "original_url = 'https://storage.googleapis.com/pheknowlator/current_build/data/original_data/'\n",
    "\n",
    "# owltools location\n",
    "owltools_location = '../pkt_kg/libs/owltools'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec013b6",
   "metadata": {},
   "source": [
    "***\n",
    "# pre-miRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "data_downloader('https://www.mirbase.org/download/miRNA.dat', processed_data_location)\n",
    "\n",
    "# Open the EMBL file\n",
    "embl_file = processed_data_location + 'miRNA.dat'\n",
    "\n",
    "# Create empty lists to store the data\n",
    "data = {\n",
    "    \"ID\": [],\n",
    "    \"Description\": [],\n",
    "    \"Sequence\": [],\n",
    "    \"Comments\": [],\n",
    "    \"References\": [],\n",
    "    \"Feature Table\": []\n",
    "}\n",
    "\n",
    "# Iterate through the records in the EMBL file\n",
    "for record in SeqIO.parse(embl_file, \"embl\"):\n",
    "    data[\"ID\"].append(record.id)\n",
    "    data[\"Description\"].append(record.description)\n",
    "    data[\"Sequence\"].append(str(record.seq))\n",
    "    data[\"Comments\"].append(str(record.annotations.get('comment', '')))\n",
    "    references = []\n",
    "    i = 0\n",
    "    for ref in record.annotations.get('references', []):\n",
    "        i = i + 1\n",
    "        references.append(f\"{[i], ref.pubmed_id}\")\n",
    "    data[\"References\"].append(\", \".join(references))\n",
    "    feature_table = \"\\n\".join(str(feature) for feature in record.features)\n",
    "    data[\"Feature Table\"].append(feature_table)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df[df['Description'].astype(str).str.contains('Homo sapiens')]\n",
    "\n",
    "df['Feature Table'] = df['Feature Table'].str.split(\"type: miRNA\")\n",
    "df = df.explode('Feature Table')\n",
    "df = df[df['Feature Table'] != '']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6326f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Feature Table'] = df['Feature Table'].str.split(\"\\n\")\n",
    "list(df['Feature Table'].loc[57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(row):\n",
    "    result = {}\n",
    "    for item in row:\n",
    "        if \"location: \" in item:\n",
    "            key_value = item.split(\"location: \")\n",
    "            value = key_value[1]\n",
    "            result['location'] = value\n",
    "        elif \"Key: \" in item:\n",
    "            key_value = item.split(\"Key: \")\n",
    "            key = key_value[1].split(\", Value:\")[0].strip()\n",
    "            value = key_value[1].split(\", Value:\")[1].strip(\" ['\").strip(\"'']\")\n",
    "            result[key] = value\n",
    "    return pd.Series(result)\n",
    "\n",
    "# Apply the function to create new columns\n",
    "new_columns = df['Feature Table'].apply(extract_values)\n",
    "\n",
    "# Concatenate the new columns with the original DataFrame\n",
    "df = pd.concat([df, new_columns], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "premirna = df[['ID', 'Description', 'Sequence', 'Comments', 'References', 'mod_base']]\n",
    "premirna = premirna.rename(columns={'mod_base':'Modification'})\n",
    "premirna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e4940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "miRBaseMap = pd.read_csv(processed_data_location + 'MIRNA_MIRBASE_MAP.txt', header=None, sep='\\t')\n",
    "miRBaseMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28234a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "premirna = pd.merge(df, miRBaseMap, left_on=['ID'], right_on=[1])\n",
    "premirna['Label'] = premirna[0]\n",
    "premirna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "miRNA_variant = pd.read_csv(unprocessed_data_location + \"miRNet-snp-mir-hsa.csv?dl=0\")\n",
    "miRNA_variant = miRNA_variant[miRNA_variant['High_Confidence']=='YES']\n",
    "miRNA_variant = miRNA_variant[['MIRNA_Name','Family_Name']]\n",
    "miRNA_variant = pd.merge(miRNA_variant, miRBaseMap, left_on=['MIRNA_Name'], right_on=[0]).drop(columns=['MIRNA_Name',0])\n",
    "\n",
    "miRNA_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12abab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "premirna = pd.merge(premirna, miRNA_variant, left_on=['ID'], right_on=[1], how='outer').rename(columns={'Family_Name':'Family name'})\n",
    "premirna[['ID','Label','Description','Sequence','Family name','Comments','References']].drop_duplicates().to_csv(properties_location + 'premiRNA.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db62c6c5",
   "metadata": {},
   "source": [
    "***\n",
    "# miRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna = df.drop(columns=['ID']).rename(columns={'accession':'ID',\n",
    "                                                'location':'Location',\n",
    "                                                'evidence':'Evidence',\n",
    "                                                'experiment':'Experiment',\n",
    "                                                'product':'Label'})\n",
    "mirna['Experiment'] = mirna['Experiment'] + ']'\n",
    "mirna.evidence = mirna.Evidence.replace('experimental',\n",
    "                                        'http://purl.obolibrary.org/obo/NCIT_C43622 (experimental method)')\n",
    "mirna = mirna[['ID','Label','References','Location','Evidence','Experiment']]\n",
    "mirna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirna.drop_duplicates().to_csv(properties_location + 'miRNA.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbef64b6",
   "metadata": {},
   "source": [
    "***\n",
    "# tsRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa872aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsRNA = pd.read_csv(unprocessed_data_location + 'newID_20210202.txt', sep=\"\\t\")  \n",
    "tsRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsRNA[['tsRNAid', 'seq']].drop_duplicates().to_csv(properties_location + 'tsRNA.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db9fc4",
   "metadata": {},
   "source": [
    "***\n",
    "# tRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457a07d",
   "metadata": {},
   "source": [
    "## tRFdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a49c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://genome.bioch.virginia.edu/trfdb/index.php\n",
    "tRF1_tRNA = pd.read_html(unprocessed_data_location+'trf1.html')[2]\n",
    "tRF1_tRNA.drop(columns=['Organism'],inplace=True)\n",
    "tRF1_tRNA.head()\n",
    "\n",
    "tRF3_tRNA = pd.read_html(unprocessed_data_location+'trf3.html')[2]\n",
    "tRF3_tRNA.drop(columns=['Organism'],inplace=True)\n",
    "\n",
    "tRF5_tRNA = pd.read_html(unprocessed_data_location+'trf5.html')[2]\n",
    "tRF5_tRNA.drop(columns=['Organism'],inplace=True)\n",
    "\n",
    "tRF_tRNA = pd.concat([tRF1_tRNA,tRF3_tRNA,tRF5_tRNA])\n",
    "tRF_tRNA = tRF_tRNA.drop(columns=['Experiment Info', 'Sequence'])\n",
    "tRF_tRNA['tRF ID'] = tRF_tRNA['tRF ID'].astype(str)\n",
    "tRF_tRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_numbers(identifier):\n",
    "    \n",
    "    html_file_path = unprocessed_data_location + 'trf' + identifier + '.html'\n",
    "\n",
    "    with open(html_file_path, 'r', encoding='utf-8') as html_file:\n",
    "        html_content = html_file.read()\n",
    "\n",
    "    pattern = r'href=\\'sequence_display.php\\?seq_id=(\\d+)'\n",
    "    matches = re.findall(pattern, html_content)\n",
    "    numbers = [int(match) for match in matches]\n",
    "\n",
    "    pattern2 = r\"href='experiments_display.php\\?trf_id=(.*?)'\"\n",
    "    matches2 = re.findall(pattern2, html_content)\n",
    "    \n",
    "    # Return the numbers as a dictionary\n",
    "    return {'sequence_numbers': numbers, 'experiment_numbers': matches2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(original_html):\n",
    "\n",
    "    transformed_html = re.sub(r'<font face=', '\\n<font face=', original_html)\n",
    "    transformed_html = re.sub(r'<br><b>Organism:', \"</font><br>\\n<font face='Arial' size='2'><b>Organism:\", transformed_html)\n",
    "    transformed_html = re.sub(r'<br><b>tRF Sequence:', \"</font><br>\\n<font face='Arial' size='2'><b>tRF Sequence:\", transformed_html)\n",
    "    transformed_html = re.sub(r\"<font face='Courier' size='3'>\", \"</font><br>\\n<font face='Arial' size='2'>\", transformed_html)\n",
    "    transformed_html = re.sub(r\"<br><b>Map Position:\", \"\\n<font face='Arial' size='2'><b>Map Position:\", transformed_html)\n",
    "\n",
    "    return transformed_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9cd07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_html(identifier):\n",
    "    url = 'http://genome.bioch.virginia.edu/trfdb/sequence_display.php?seq_id=' + identifier\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 500:\n",
    "        html_content = response.text\n",
    "        return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "df = pd.DataFrame()\n",
    "result = get_numbers('1')\n",
    "numbers_mapping = dict(zip(result['sequence_numbers'], result['experiment_numbers']))\n",
    "\n",
    "for i in result['sequence_numbers'] :\n",
    "    \n",
    "    html_content = get_html(str(i))  # Retrieve HTML content\n",
    "    if html_content is not None:\n",
    "        # Apply the transformation to the HTML content\n",
    "        transformed_html = transform(html_content)\n",
    "\n",
    "        # Continue with parsing and DataFrame creation\n",
    "        soup = BeautifulSoup(transformed_html, 'html.parser')\n",
    "        values = [font.get_text() for font in soup.find_all('font')]\n",
    "        values = [value.split(\":\")[1].strip() if \":\" in value else value for value in values]\n",
    "        \n",
    "        corresponding_experiment_number = numbers_mapping.get(i, None)\n",
    "\n",
    "        # Create a DataFrame for the current HTML page\n",
    "        temp = pd.DataFrame(values).T\n",
    "        temp.columns = range(temp.shape[1])\n",
    "\n",
    "        # Add the 'Experiment Number' column\n",
    "        temp['Experiment Number'] = corresponding_experiment_number\n",
    "\n",
    "        # Concatenate the current DataFrame with the main DataFrame\n",
    "        df = pd.concat([df, temp], ignore_index=True)\n",
    " \n",
    "result = get_numbers('3')\n",
    "numbers_mapping = dict(zip(result['sequence_numbers'], result['experiment_numbers']))\n",
    "\n",
    "for i in result['sequence_numbers'] :\n",
    "    \n",
    "    html_content = get_html(str(i))  # Retrieve HTML content\n",
    "    if html_content is not None:\n",
    "        # Apply the transformation to the HTML content\n",
    "        transformed_html = transform(html_content)\n",
    "\n",
    "        # Continue with parsing and DataFrame creation\n",
    "        soup = BeautifulSoup(transformed_html, 'html.parser')\n",
    "        values = [font.get_text() for font in soup.find_all('font')]\n",
    "        values = [value.split(\":\")[1].strip() if \":\" in value else value for value in values]\n",
    "        \n",
    "        corresponding_experiment_number = numbers_mapping.get(i, None)\n",
    "\n",
    "        # Create a DataFrame for the current HTML page\n",
    "        temp = pd.DataFrame(values).T\n",
    "        temp.columns = range(temp.shape[1])\n",
    "\n",
    "        # Add the 'Experiment Number' column\n",
    "        temp['Experiment Number'] = corresponding_experiment_number\n",
    "\n",
    "        # Concatenate the current DataFrame with the main DataFrame\n",
    "        df = pd.concat([df, temp], ignore_index=True)\n",
    "\n",
    "result = get_numbers('5')\n",
    "numbers_mapping = dict(zip(result['sequence_numbers'], result['experiment_numbers']))\n",
    "\n",
    "for i in result['sequence_numbers'] :\n",
    "    \n",
    "    html_content = get_html(str(i))  # Retrieve HTML content\n",
    "    if html_content is not None:\n",
    "        # Apply the transformation to the HTML content\n",
    "        transformed_html = transform(html_content)\n",
    "\n",
    "        # Continue with parsing and DataFrame creation\n",
    "        soup = BeautifulSoup(transformed_html, 'html.parser')\n",
    "        values = [font.get_text() for font in soup.find_all('font')]\n",
    "        values = [value.split(\":\")[1].strip() if \":\" in value else value for value in values]\n",
    "        \n",
    "        corresponding_experiment_number = numbers_mapping.get(i, None)\n",
    "\n",
    "        # Create a DataFrame for the current HTML page\n",
    "        temp = pd.DataFrame(values).T\n",
    "        temp.columns = range(temp.shape[1])\n",
    "\n",
    "        # Add the 'Experiment Number' column\n",
    "        temp['Experiment Number'] = corresponding_experiment_number\n",
    "\n",
    "        # Concatenate the current DataFrame with the main DataFrame\n",
    "        df = pd.concat([df, temp], ignore_index=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chr_substring(text):\n",
    "    start_index = text.find('chr')\n",
    "    if start_index != -1:\n",
    "        end_index = text.find('&', start_index)\n",
    "        if end_index != -1:\n",
    "            return text[start_index:end_index]\n",
    "    return ''\n",
    "\n",
    "df['Experiment Number'] = df['Experiment Number'].apply(extract_chr_substring)\n",
    "df.columns = ['tRF ID','organism','empty','Sequence','Map Position','tRNA Gene Co-ordinates']\n",
    "df = df.drop(columns=['organism','empty'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tRF = pd.merge(tRF_tRNA,df,on=['tRF ID', 'tRNA Gene Co-ordinates'])\n",
    "tRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tRF['tRF ID'] = \"trfdb?\" + tRF['tRF ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tRF.drop_duplicates().to_csv(properties_location + 'tRF_tRFdb.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7c71a",
   "metadata": {},
   "source": [
    "## MINTBASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74308fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tRNA_MINTbase_GtRNAdb_map=pd.read_csv(\n",
    "    processed_data_location + 'tRNA_MINTbase_GtRNAdb_MAP.txt', header=None, sep='\\t')\n",
    "tRNA_MINTbase_GtRNAdb_map=tRNA_MINTbase_GtRNAdb_map.rename(columns={0:'MINTbase tRNA name',1:'gtRNAdb name'})\n",
    "tRNA_MINTbase_GtRNAdb_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cm.jefferson.edu/MINTbase/InputController?g=GRCh37&d=y&v=g&e=1.0&cl=,4,5,11,12,16,18,19,21,22,26,27,#ttop\n",
    "tRF_tRNA2 = pd.read_csv(unprocessed_data_location+'MINTbasetRF-tRNA.txt',sep='\\t')\n",
    "tRF_tRNA2['MINTbase Alternative IDs (GRCh37 assembly-derived)'] = tRF_tRNA2['MINTbase Alternative IDs (GRCh37 assembly-derived)'].str.split('@').str[0]\n",
    "tRF_tRNA2.rename(columns={'MINTbase Alternative IDs (GRCh37 assembly-derived)':'MINTbase tRNA name'},inplace=True)\n",
    "tRF_tRNA2 = pd.merge(tRF_tRNA2, tRNA_MINTbase_GtRNAdb_map, on='MINTbase tRNA name')\n",
    "tRF_tRNA2 = tRF_tRNA2[['License Plate (sequence derived)','Type','Fragment sequence','gtRNAdb name','MINTbase tRNA name']]\n",
    "tRF_tRNA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddfb546",
   "metadata": {},
   "outputs": [],
   "source": [
    "tRF_tRNA2.drop_duplicates().to_csv(properties_location + 'tRF_MINTBASE.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a469f1",
   "metadata": {},
   "source": [
    "***\n",
    "# tRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://gtrnadb.ucsc.edu/genomes/eukaryota/Hsapi38/hg38-tRNAs.fa -P ../resources/processed_data/unprocessed_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "\n",
    "identifiers = []\n",
    "seq = []\n",
    "\n",
    "# Replace the URL with the path to your local FASTA file\n",
    "fasta_file_path = unprocessed_data_location + 'hg38-tRNAs.fa'\n",
    "\n",
    "with open(fasta_file_path) as fasta_file:\n",
    "    for title, sequence in SimpleFastaParser(fasta_file):\n",
    "        identifiers.append(title.split(None, 1)[0])  # First word is ID\n",
    "        seq.append(sequence)\n",
    "        \n",
    "data = {\"Identifier\": identifiers, \"Sequence\": seq}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8870a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all(df['Identifier'].str.startswith('Homo_sapiens_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Identifier'] = df['Identifier'].str[len('Homo_sapiens_'):]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f2f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tRNA = pd.read_html('http://gtrnadb.ucsc.edu/genomes/eukaryota/Hsapi38/genes/tRNA-Ala-AGC-1-1.html')[0].T\n",
    "tRNA2 = pd.read_html('http://gtrnadb.ucsc.edu/genomes/eukaryota/Hsapi38/genes/tRNA-Ala-AGC-1-1.html')[1].T\n",
    "tRNA = pd.concat([tRNA,tRNA2],axis=1)\n",
    "tRNA.columns = tRNA.iloc[0]\n",
    "tRNA = tRNA[1:]\n",
    "tRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for identifier in df['Identifier'] [1:] :\n",
    "\n",
    "    temp = pd.read_html('http://gtrnadb.ucsc.edu/genomes/eukaryota/Hsapi38/genes/' + identifier + '.html')[0].T\n",
    "    temp2 = pd.read_html('http://gtrnadb.ucsc.edu/genomes/eukaryota/Hsapi38/genes/' + identifier + '.html')[1].T\n",
    "    temp = pd.concat([temp,temp2],axis=1)\n",
    "    temp.columns = temp.iloc[0]\n",
    "    temp = temp[1:]\n",
    "    tRNA = pd.concat([tRNA, temp])\n",
    "\n",
    "tRNA.Locus = tRNA.Locus.str.replace(' View in Genome Browser', '')\n",
    "tRNA = tRNA.drop(columns=['Organism', 'Known Modifications (Modomics)'])\n",
    "\n",
    "tRNA['GtRNAdb Gene Symbol'] = tRNA['GtRNAdb Gene Symbol'].astype(str) + '.html'\n",
    "tRNA = tRNA[['GtRNAdb Gene Symbol'] + [col for col in tRNA.columns if col != 'GtRNAdb Gene Symbol']]\n",
    "tRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80680c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tRNA.drop_duplicates().to_csv(properties_location + 'tRNA.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b71c7",
   "metadata": {},
   "source": [
    "***\n",
    "# Small protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e231cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lncRNA_protein = pd.read_csv(unprocessed_data_location + 'sprotein_LncBook2.0.csv.gz') \n",
    "lncRNA_protein = lncRNA_protein[lncRNA_protein['Symbol']!='-']\n",
    "lncRNA_protein.drop(columns=['Gene ID','Symbol','Transcript ID','Experimental Evidence'],inplace=True)\n",
    "lncRNA_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de80508",
   "metadata": {},
   "outputs": [],
   "source": [
    "lncRNA_protein.drop_duplicates().to_csv(properties_location + 'smallProtein.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7669a374",
   "metadata": {},
   "source": [
    "***\n",
    "# Riboswitch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5fcf6c",
   "metadata": {},
   "source": [
    "## TBDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "riboswitch_protein = pd.read_csv(unprocessed_data_location+'tbdb.csv', sep=',') \n",
    "riboswitch_protein = riboswitch_protein[[\n",
    "    'unique_name', 'Name', 'Sequence', 'Tbox_start' , 'Tbox_end', 'Structure', 's1_start', 's1_loop_start',\n",
    "    's1_loop_end', 's1_end', 'antiterm_start', 'antiterm_end', 'term_start', 'term_end', 'codon_start',\n",
    "    'codon_end', 'codon', 'codon_region', 'discrim_start', 'discrim_end', 'discriminator', 'warnings',\n",
    "    'type', 'source', 'whole_antiterm_structure', 'other_stems', 'whole_antiterm_warnings', 'term_sequence',\n",
    "    'term_structure', 'terminator_energy', 'term_errors', 'antiterm_term_sequence',\n",
    "    'infernal_antiterminator_structure', 'vienna_antiterminator_structure', 'vienna_antiterminator_energy',\n",
    "    'vienna_antiterminator_errors', 'terminator_structure', 'terminator_errors', 'new_term_structure',\n",
    "    'new_term_energy', 'new_term_errors', 'whole_term_structure', 'folded_antiterm_structure', 'Trimmed_sequence',\n",
    "    'Trimmed_antiterm_struct', 'Trimmed_term_struct', 'accession_url', 'accession_name', 'locus_start', \n",
    "    'locus_end', 'locus_view_start', 'locus_view_end', 'deltadelta_g', 'TaxId'\n",
    "]]\n",
    "riboswitch_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "riboswitch_protein.drop_duplicates().to_csv(properties_location + 'riboswitch_TBDB.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fe48c",
   "metadata": {},
   "source": [
    "## RSwitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e3fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "riboswitch_bactStrain = pd.read_csv(unprocessed_data_location + 'rswitch.csv', header=None) \n",
    "riboswitch_bactStrain.rename(columns={0:'Riboswitch',1:'Type'},inplace=True)\n",
    "riboswitch_bactStrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e781398",
   "metadata": {},
   "outputs": [],
   "source": [
    "riboswitch_bactStrain[['Riboswitch','Type']].drop_duplicates().to_csv(properties_location + 'riboswitch_RSwitch.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf950557",
   "metadata": {},
   "source": [
    "***\n",
    "# Viral RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vRNA_ribozyme = pd.read_json(unprocessed_data_location + 'all.json').T \n",
    "\n",
    "# Extract ribozymes \n",
    "myre = re.compile(r\"\\n>> .*?\\n\")\n",
    "ribozyme = [myre.findall(i) for i in vRNA_ribozyme.ribozymes]\n",
    "ribozyme = [[j.replace(\"\\n\",'').replace(\">> \",'') for j in i] for i in ribozyme]\n",
    "\n",
    "# List of all possible ribozymes (useful for mapping)\n",
    "a = [i for j in ribozyme for i in j]\n",
    "set(a)\n",
    "\n",
    "vRNA_ribozyme = pd.concat([vRNA_ribozyme.reset_index().drop(columns=['index']),\n",
    "                           pd.Series(ribozyme)], axis=1)\n",
    "vRNA_ribozyme = vRNA_ribozyme.explode(0)\n",
    "vRNA_ribozyme[0] = vRNA_ribozyme[0].str.split().str[0]\n",
    "vRNA_ribozyme=vRNA_ribozyme[['accession', 'identicalSeqs', 'submitters', 'releaseDate', 'isolate', 'species',\n",
    "                            'genus', 'family', 'moleculeType', 'sequenceType', 'nucCompleteness', 'genotype', 'segment',\n",
    "                            'publications', 'geoLocation', 'host', 'isolationSource', 'collectionDate', 'bioSample',\n",
    "                            'genBankTitle', 'displayTitle', 'sequence', 'structure', 'type', 'ribozymes',\n",
    "                            'Cls_ID80', 'Cls_ID70', 'Cls_ID85', 'Cls_ID75', 'Cls_ID95', 'Cls_ID90']]\n",
    "\n",
    "vRNA_ribozyme['identicalSeqs'] = vRNA_ribozyme['identicalSeqs'].astype(str)\n",
    "vRNA_ribozyme['structure'] = vRNA_ribozyme['structure'].astype(str)\n",
    "vRNA_ribozyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459cf9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vRNA_ribozyme.drop_duplicates().to_csv(properties_location + 'viralRNA.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4540810",
   "metadata": {},
   "source": [
    "***\n",
    "# Aptamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99fc68",
   "metadata": {},
   "source": [
    "## Apta-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa81552",
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_protein = pd.read_csv(unprocessed_data_location + 'aptaindex.csv',names=['Name', 'ID', 'Target', 'Sequence'],skiprows=[0]) \n",
    "aptamer_protein.Target = aptamer_protein.Target.str.lower()\n",
    "aptamer_protein['ID'] = 'aptamer-details/?id=' + aptamer_protein['ID'].astype(str)\n",
    "aptamer_protein = aptamer_protein.drop(columns=['Target'])\n",
    "aptamer_protein = aptamer_protein[['ID','Name','Sequence']]\n",
    "aptamer_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eace9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_protein.drop_duplicates().to_csv(properties_location + 'aptamer.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289babe6",
   "metadata": {},
   "source": [
    "***\n",
    "# Ribozyme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b58322",
   "metadata": {},
   "source": [
    "## Rfam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "ribozyme_rfam_map = pd.DataFrame(data=[['LC ribozyme','family/RF00011'],\n",
    "                                 ['hammerhead ribozyme','clan/CL00010'],\n",
    "                                 ['glmS ribozyme','family/RF00234'],\n",
    "                                 ['HDV-F-prausnitzii','family/RF02682'],\n",
    "                                 ['HDV ribozyme','family/RF00094'],\n",
    "                                 ['HDV_ribozyme','family/RF00094'],\n",
    "                                 ['Hairpin','family/RF00173'],\n",
    "                                 ['Hammerhead_1','clan/CL00010'],\n",
    "                                 ['Hammerhead_HH9','clan/CL00010'],\n",
    "                                 ['Hammerhead_3','clan/CL00010'],\n",
    "                                 ['Hammerhead_HH10','clan/CL00010'],\n",
    "                                 ['Hammerhead_II','clan/CL00010'],\n",
    "                                 ['Pistol','family/RF02679'],\n",
    "                                 ['Pistol ribozyme','family/RF02679'],\n",
    "                                 ['twister ribozyme','clan/CL00120'],\n",
    "                                 ['Twister-P5','clan/CL00120'],\n",
    "                                 ['Twister-P3','clan/CL00120'],\n",
    "                                 ['RNAse P','family/RF00009']#,\n",
    "                                 #['VS ribozyme',''] absent in RFAM\n",
    "                                 ])\n",
    "\n",
    "ribozyme_rfam_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from Bio import SeqIO\n",
    "from io import StringIO\n",
    "\n",
    "ribozyme_family = ribozyme_rfam_map[ribozyme_rfam_map[1].str.contains('family')]\n",
    "ribozyme_sequences = {}\n",
    "\n",
    "for ribozyme in ribozyme_family[1]:\n",
    "    url = 'http://rfamlive.xfam.org/' + ribozyme + '/alignment?acc=' + ribozyme.rsplit('/')[1] + '&format=fasta&download=1'\n",
    "    response = requests.get(url)\n",
    "    fasta_data = response.text\n",
    "    fasta_handle = StringIO(fasta_data)\n",
    "    sequences = list(SeqIO.parse(fasta_handle, 'fasta'))\n",
    "    ribozyme_sequences[ribozyme] = sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af8fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for ribozyme, seq_records in ribozyme_sequences.items():\n",
    "    sequences = [str(seq_record.seq) for seq_record in seq_records]\n",
    "    data.append({'ribozyme': ribozyme, 'sequence(s)': sequences})\n",
    "\n",
    "# Create a Pandas DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a087ac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ribozyme_rfam_map = pd.merge(ribozyme_rfam_map,df,left_on=[1],right_on=['ribozyme'], how='outer').drop(columns=['ribozyme'])\n",
    "ribozyme_rfam_map['sequence(s)'] = ribozyme_rfam_map['sequence(s)'].apply(\n",
    "    lambda x: '; '.join(map(str, x)) if not isinstance(x, float) else '')\n",
    "ribozyme_rfam_map.rename(columns={0:'Label',1:'Rfam ID'},inplace=True)\n",
    "ribozyme_rfam_map = ribozyme_rfam_map[['Rfam ID', 'Label', 'sequence(s)']]\n",
    "ribozyme_rfam_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "ribozyme_rfam_map.drop_duplicates().to_csv(properties_location + 'ribozyme.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e78f85",
   "metadata": {},
   "source": [
    "***\n",
    "# Biological role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Tumor-Suppressor-Gene', 'Oncogene', 'General']\n",
    "definition = ['A tumor suppressor gene encodes a protein that acts to regulate cell division, keeping it in check. When a tumor suppressor gene is inactivated by a mutation, the protein it encodes is not produced or does not function properly, and as a result, uncontrolled cell division may occur. Such mutations may contribute to the development of a cancer.',\n",
    "              'An oncogene is a mutated gene that has the potential to cause cancer. Before an oncogene becomes mutated, it is called a proto-oncogene, and it plays a role in regulating normal cell division. Cancer can arise when a proto-oncogene is mutated, changing it into an oncogene and causing the cell to divide and multiply uncontrollably. Some oncogenes work like an accelerator pedal in a car, pushing a cell to divide again and again. Others work like a faulty brake in a car parked on a hill, also causing the cell to divide unchecked.',\n",
    "              '']\n",
    "narration = ['Tumor Suppressor Gene. Tumor suppressor genes are present in all cells in our body. When they are switched on, they prevent ourselves from growing and dividing. You can think of them as being like the brakes of a car. However, when a tumor suppressor gene is switched off, either because the cell mistakenly deletes it or mutates it, the brake is released and the cell may start to grow and divide uncontrollably and potentially drive the cell to turn into a cancer cell.',\n",
    "             'Oncogene. The name of oncogene suggests it is a gene that can cause cancer. Initially, oncogenes were identified in viruses, which could cause cancers in animals. Later, it was found that oncogenes can be mutated copies of certain normal cellular genes also called proto-oncogenes. Intact proto-oncogenes play important functions, regulating normal cellular growth, division, and apoptosis, which is the name for programmed or controlled cell death. Oncogenes or mutated copies of the proto-oncogenes may lead to uncontrolled cell growth and the escape from cell death, which may result in cancer development.',\n",
    "             '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = pd.DataFrame({'Name': name, 'Definition': definition, 'Narration': narration})\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd82a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "role.drop_duplicates().to_csv(properties_location + 'biologicalRole.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b75f021",
   "metadata": {},
   "source": [
    "***\n",
    "# piRNA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff5bfa",
   "metadata": {},
   "source": [
    "## piRBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9434f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://bigdata.ibp.ac.cn/piRBase/browse.php --> \"Download\" button\n",
    "piRNA = pd.read_csv(unprocessed_data_location + 'piRBase_hsa.txt', sep='\\t')[['name','aliases','accession','sequence','dataset','pubmed']]\n",
    "piRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "piRNA['aliases'] = piRNA['aliases'].str.replace(',', '|')\n",
    "\n",
    "piRNA.accession = 'https://www.ncbi.nlm.nih.gov/nucleotide/' + piRNA.accession.astype(str)\n",
    "piRNA.accession = piRNA.accession.replace('https://www.ncbi.nlm.nih.gov/nucleotide/nan', np.nan)\n",
    "\n",
    "# Remove number of reads per dataset\n",
    "piRNA.dataset = piRNA.dataset.str.replace(r':\\d+', '', regex=True)\n",
    "piRNA.dataset = 'http://bigdata.ibp.ac.cn/piRBase/browseds2.php?dsid=' + piRNA.dataset.astype(str)\n",
    "piRNA.dataset = piRNA.dataset.str.replace(' ', '|http://bigdata.ibp.ac.cn/piRBase/browseds2.php?dsid=')\n",
    "piRNA.dataset = piRNA.dataset.replace('http://bigdata.ibp.ac.cn/piRBase/browseds2.php?dsid=nan', np.nan)\n",
    "\n",
    "piRNA.pubmed = 'https://pubmed.ncbi.nlm.nih.gov/' + piRNA.pubmed.astype(str)\n",
    "piRNA.pubmed = piRNA.pubmed.str.replace(' ', '|https://pubmed.ncbi.nlm.nih.gov/')\n",
    "piRNA.pubmed = piRNA.pubmed.replace('https://pubmed.ncbi.nlm.nih.gov/nan', np.nan)\n",
    "\n",
    "piRNA = piRNA.rename(columns={'name':'Name','aliases':'Synonym(s)','accession':'Accession','sequence':'Sequence','dataset':'Dataset','pubmed':'References (PMID)'})\n",
    "piRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00240acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "piRNAfix = list(range(8438265, 8592950))\n",
    "piRNAfix = ['piR-hsa-' + str(num) for num in range(8438265, 8592950)]\n",
    "piRNAfix = pd.DataFrame({'Name': piRNAfix})\n",
    "piRNAfix[\"Synonym(s)\"] = np.nan\n",
    "piRNAfix[\"Accession\"] = np.nan\n",
    "piRNAfix[\"Sequence\"] = np.nan\n",
    "piRNAfix[\"Dataset\"] = np.nan\n",
    "piRNAfix[\"References (PMID)\"] = np.nan\n",
    "piRNAfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "piRNA = pd.concat([piRNA, piRNAfix])\n",
    "piRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44742c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "piRNA.drop_duplicates().to_csv(properties_location + 'piRNA.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b751f2",
   "metadata": {},
   "source": [
    "***\n",
    "# RNA drugs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645ddd2",
   "metadata": {},
   "source": [
    "https://go.drugbank.com/releases/latest#open-data --> DrugBank Vocabulary --> Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DrugBank = pd.read_csv(unprocessed_data_location + 'drugbank vocabulary.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e5c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASOdnonO_data = pd.concat([pd.read_csv('../resources/edge_data/ASOd-mRNA2430.txt',sep='\\t')['DrugBank ID'],\n",
    "    pd.read_csv('../resources/edge_data/ASOd-disease2606.txt',sep='\\t')['DB ID'],\n",
    "    pd.read_csv('../resources/edge_data/ASOd-protein11007.txt',sep='\\t')['DrugBank ID'],\n",
    "    pd.read_csv('../resources/edge_data/ASOd-protein10002.txt',sep='\\t')['DrugBank ID']])\n",
    "\n",
    "aptamerdnonO_data = pd.concat([pd.read_csv('../resources/edge_data/aptamerd-protein2436.txt',sep='\\t')['DrugBank ID'],\n",
    "    pd.read_csv('../resources/edge_data/aptamerd-disease2606.txt',sep='\\t')['DrugBank ID']])\n",
    "\n",
    "siRNAdnonO_data = pd.concat([pd.read_csv('../resources/edge_data/siRNAd-mRNA2430.txt',sep='\\t')['DrugBank ID'],\n",
    "    pd.read_csv('../resources/edge_data/siRNAd-disease2606.txt',sep='\\t')['DrugBank ID']])\n",
    "\n",
    "mRNAvnonO_data = pd.read_csv('../resources/edge_data/mRNAv-disease2606.txt',sep='\\t')['DrugBank ID']\n",
    "\n",
    "RNAdrugs = pd.concat([ASOdnonO_data, aptamerdnonO_data, siRNAdnonO_data, mRNAvnonO_data]).drop_duplicates().reset_index(drop=True)\n",
    "RNAdrugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27210c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNAdrugs = pd.merge(pd.DataFrame(RNAdrugs), DrugBank, left_on=[0], right_on=['DrugBank ID']).drop(columns=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNAdrugs.drop_duplicates().to_csv(properties_location + 'RNAdrugs.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b11fbf",
   "metadata": {},
   "source": [
    "***\n",
    "# Gene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294fbe2e",
   "metadata": {},
   "source": [
    "## PheKnowLator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dfbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_clean = pd.read_csv(processed_data_location + 'Merged_Human_Ensembl_Entrez_HGNC_Uniprot_Identifiers.txt', sep='\\t')\n",
    "merged_data_clean = merged_data_clean[(~merged_data_clean['entrez_id'].isna()) & (merged_data_clean['entrez_id'] != 'None')]\n",
    "\n",
    "def merge_rows(df, column1):\n",
    "    df = df.drop_duplicates()\n",
    "    df_merged = df.groupby([column1]).agg(lambda x: '|'.join(set(str(i) for i in x if i != 'None' and i != 'unknown'))).reset_index()\n",
    "    return df_merged.drop_duplicates()\n",
    "\n",
    "merged_data_clean = merge_rows(merged_data_clean, 'entrez_id')\n",
    "merged_data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_clean.drop_duplicates().to_csv(properties_location + 'gene.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59e7bd",
   "metadata": {},
   "source": [
    "***\n",
    "# Reactome pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_reactome_map = pd.read_csv(unprocessed_data_location + 'kegg_reactome.csv', header=0, delimiter=',')[['Source Name','Source ID']]\n",
    "kegg_reactome_map.columns=[0,1]\n",
    "\n",
    "reactome_pathways = pd.read_csv(unprocessed_data_location + 'ReactomePathways.txt', header=None, delimiter='\\t')\n",
    "# remove all non-human pathways\n",
    "reactome_pathways = reactome_pathways[reactome_pathways[2] == 'Homo sapiens'][[0,1]]\n",
    "reactome_pathways.columns=[1,0]\n",
    "\n",
    "desc_reactome_map = pd.concat([kegg_reactome_map, reactome_pathways]).drop_duplicates()\n",
    "desc_reactome_map[1] =  'https://reactome.org/content/detail/' + desc_reactome_map[1].astype(str)\n",
    "\n",
    "desc_reactome_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_reactome_map.to_csv(properties_location + 'Reactome.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d0e069",
   "metadata": {},
   "source": [
    "***\n",
    "# Wikipathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116008ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_wpw_map = pd.read_csv(unprocessed_data_location + 'wpw_reactome.csv', delimiter='\\t', names=range(587))[[0,1]]\n",
    "desc_wpw_map[0] = desc_wpw_map[0].str.replace(r'%WikiPathways_.*$', '', regex=True)\n",
    "\n",
    "desc_wpw_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e00ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_wpw_map.to_csv(properties_location + 'Wikipathways.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ed33f",
   "metadata": {},
   "source": [
    "***\n",
    "# OBO terms/classes and properties\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc1ef87",
   "metadata": {},
   "source": [
    "***\n",
    "# RO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce48fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_graph = Graph()\n",
    "ro_graph.parse(ontology_data_location + 'ro_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(ro_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb2fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(ro_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(ro_graph)]\n",
    "master_synonyms = [x for x in ro_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in ro_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0]) if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(c) for c in cls_syn]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in ro_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'Description': desc, 'Synonym(s)': synonym\n",
    "    }\n",
    "    \n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'RO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef16dff",
   "metadata": {},
   "source": [
    "***\n",
    "# HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da342095",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_graph = Graph()\n",
    "hpo_graph.parse(ontology_data_location + 'hp_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(hpo_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311136ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "dbxref_uri = URIRef(\"http://www.geneontology.org/formats/oboInOwl#hasDbXref\")\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(hpo_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(hpo_graph)]\n",
    "master_synonyms = [x for x in hpo_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in hpo_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0])  if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(c) for c in cls_syn]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in hpo_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    # DbXref\n",
    "    cls_ed = [x for x in hpo_graph.objects(x, dbxref_uri) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ed = '|'.join([str(c) for c in cls_ed]) if len(cls_ed) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'Description': desc, 'Synonym(s)': synonym, 'DbXref': desc_ed\n",
    "    }\n",
    "\n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'HPO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409365d8",
   "metadata": {},
   "source": [
    "***\n",
    "# GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_graph = Graph()\n",
    "go_graph.parse(ontology_data_location + 'go_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(go_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3c611",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "hasOBONamespace = URIRef(\"http://www.geneontology.org/formats/oboInOwl#hasOBONamespace\")\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(go_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(go_graph)]\n",
    "master_synonyms = [x for x in go_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in go_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0]) if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(cls_syn)]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in go_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    # vocabulary(MF/BP/CC)\n",
    "    cls_ed = [x for x in go_graph.objects(x, hasOBONamespace) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ed = str(cls_ed[0]) if len(cls_ed) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'Description': desc, 'Synonym': synonym, 'Vocabulary(MF/BP/CC)': desc_ed\n",
    "    }\n",
    "\n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50905bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'GO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f449d91",
   "metadata": {},
   "source": [
    "***\n",
    "# Mondo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "mondo_graph = Graph()\n",
    "mondo_graph.parse(ontology_data_location + 'mondo_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(mondo_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "dbxref_uri = URIRef(\"http://www.geneontology.org/formats/oboInOwl#hasDbXref\")\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(mondo_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(mondo_graph)]\n",
    "master_synonyms = [x for x in mondo_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in mondo_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0])  if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(c) for c in cls_syn]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in mondo_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    # DbXref\n",
    "    cls_ed = [x for x in mondo_graph.objects(x, dbxref_uri) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ed = '|'.join([str(c) for c in cls_ed]) if len(cls_ed) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'Description': desc, 'Synonym(s)': synonym, 'DbXref': desc_ed\n",
    "    }\n",
    "\n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b955dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'Mondo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3bb097",
   "metadata": {},
   "source": [
    "***\n",
    "# VO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddceba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vo_graph = Graph()\n",
    "vo_graph.parse(ontology_data_location + 'vo_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(vo_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fec954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(vo_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(vo_graph)]\n",
    "master_synonyms = [x for x in vo_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in vo_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0]) if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(c) for c in cls_syn]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in vo_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    # seeAlso\n",
    "    cls_seeAlso = [x for x in vo_graph.objects(x, RDFS.seeAlso) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    seeAlsos = str(cls_seeAlso[0]) if len(cls_seeAlso) > 0 else 'None'\n",
    "    # editor notes\n",
    "    cls_ed = [x for x in vo_graph.objects(x, obo.IAO_0000116) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ed = '|'.join([str(cls_ed[0])]) if len(cls_ed) > 0 else 'None'\n",
    "    # vaccine proper name\n",
    "    cls_pn = [x for x in vo_graph.objects(x, obo.VO_0003158) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_pn = str(cls_pn[0]) if len(cls_pn) > 0 else 'None'\n",
    "    # definition source\n",
    "    cls_ds = [x for x in vo_graph.objects(x, obo.IAO_0000119) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ds = str(cls_ds[0]) if len(cls_ds) > 0 else 'None'  \n",
    "    # alternative label\n",
    "    cls_al = [x for x in vo_graph.objects(x, obo.IAO_0000118) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_al = str(cls_al[0]) if len(cls_al) > 0 else 'None' \n",
    "    # FDA indications\n",
    "    cls_fi = [x for x in vo_graph.objects(x, obo.VO_0003160) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_fi = str(cls_fi[0]) if len(cls_fi) > 0 else 'None' \n",
    "    # trade name\n",
    "    cls_td = [x for x in vo_graph.objects(x, obo.VO_0003099) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_td = str(cls_td[0]) if len(cls_td) > 0 else 'None'\n",
    "    # example of usage\n",
    "    cls_eu = [x for x in vo_graph.objects(x, obo.IAO_0000112) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_eu = str(cls_eu[0]) if len(cls_eu) > 0 else 'None'\n",
    "    # vaccine STN\n",
    "    cls_stn = [x for x in vo_graph.objects(x, obo.VO_0003162) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_stn = str(cls_stn[0]) if len(cls_stn) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'AlternativeLabel':desc_al, 'seeAlso': seeAlsos, 'TradeName': desc_td,\n",
    "        'Description': desc, 'DefinitionSource': desc_ds, 'Synonym(s)': synonym, 'EditorNotes': desc_ed,\n",
    "        'VaccineProperName': desc_pn, 'FDAindications': desc_fi, 'ExampleOfUsage': desc_eu,\n",
    "        'vaccineSTN': desc_stn\n",
    "    }\n",
    "\n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'VO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7444f",
   "metadata": {},
   "source": [
    "***\n",
    "# ChEBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ec63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chebi_graph = Graph()\n",
    "chebi_graph.parse(ontology_data_location + 'chebi_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(chebi_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d042dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "hasOBONamespace = URIRef(\"http://www.geneontology.org/formats/oboInOwl#hasOBONamespace\")\n",
    "dbxref_uri = URIRef(\"http://www.geneontology.org/formats/oboInOwl#hasDbXref\")\n",
    "iupacName = URIRef(\"http://purl.obolibrary.org/obo/chebi#IUPAC_NAME\")\n",
    "charge = URIRef(\"http://purl.obolibrary.org/obo/chebi/charge\")\n",
    "mass = URIRef(\"http://purl.obolibrary.org/obo/chebi/mass\")\n",
    "smiles = URIRef(\"http://purl.obolibrary.org/obo/chebi/smiles\")\n",
    "formula = URIRef(\"http://purl.obolibrary.org/obo/chebi/formula\")\n",
    "monoisotopicmass = URIRef(\"http://purl.obolibrary.org/obo/chebi/monoisotopicmass\")\n",
    "inchi = URIRef(\"http://purl.obolibrary.org/obo/chebi/inchi\")\n",
    "inchikey = URIRef(\"http://purl.obolibrary.org/obo/chebi/inchikey\")\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(chebi_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(chebi_graph)]\n",
    "master_synonyms = [x for x in chebi_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in chebi_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0])  if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(c) for c in cls_syn]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in chebi_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    # DbXref\n",
    "    cls_ed = [x for x in chebi_graph.objects(x, dbxref_uri) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ed = '|'.join([str(c) for c in cls_ed]) if len(cls_ed) > 0 else 'None'\n",
    "    # vocabulary\n",
    "    cls_vo = [x for x in chebi_graph.objects(x, hasOBONamespace) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_vo = str(cls_vo[0]) if len(cls_vo) > 0 else 'None'\n",
    "    # IUPAC name\n",
    "    cls_iupac = [x for x in chebi_graph.objects(x, iupacName) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_iupac = str(cls_iupac[0]) if len(cls_iupac) > 0 else 'None'\n",
    "    # charge\n",
    "    cls_ch = [x for x in chebi_graph.objects(x, charge) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ch = str(cls_ch[0]) if len(cls_ch) > 0 else 'None'\n",
    "    # mass\n",
    "    cls_mass = [x for x in chebi_graph.objects(x, mass) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_mass = str(cls_mass[0]) if len(cls_mass) > 0 else 'None'\n",
    "    # smiles\n",
    "    cls_smiles = [x for x in chebi_graph.objects(x, smiles) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_smiles = str(cls_smiles[0]) if len(cls_smiles) > 0 else 'None'\n",
    "    # formula\n",
    "    cls_form = [x for x in chebi_graph.objects(x, formula) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_form = str(cls_form[0]) if len(cls_form) > 0 else 'None'\n",
    "    # monoisotopicmass\n",
    "    cls_mim = [x for x in chebi_graph.objects(x, monoisotopicmass) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_mim = str(cls_mim[0]) if len(cls_mim) > 0 else 'None'\n",
    "    # inchi\n",
    "    cls_in = [x for x in chebi_graph.objects(x, inchi) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_in = str(cls_in[0]) if len(cls_in) > 0 else 'None'\n",
    "    # inchikey\n",
    "    cls_ink = [x for x in chebi_graph.objects(x, inchikey) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ink = str(cls_ink[0]) if len(cls_ink) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'Description': desc, 'Synonym(s)': synonym, 'DbXref': desc_ed,\n",
    "        'Namespace': desc_vo, 'IUPACname': desc_iupac, 'Charge': desc_ch, 'Mass': desc_mass,\n",
    "        'Smiles': desc_smiles, 'Monoisotopicmass': desc_mim, 'Inchi': desc_in, 'Inchikey': desc_ink\n",
    "    }\n",
    "\n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c9a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'ChEBI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941db69b",
   "metadata": {},
   "source": [
    "***\n",
    "# Uberon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uberon_graph = Graph()\n",
    "uberon_graph.parse(ontology_data_location + 'ext_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(uberon_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "dbxref_uri = URIRef(\"http://www.geneontology.org/formats/oboInOwl#hasDbXref\")\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(uberon_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(uberon_graph)]\n",
    "master_synonyms = [x for x in uberon_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in uberon_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0])  if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(c) for c in cls_syn]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in uberon_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    # DbXref\n",
    "    cls_ed = [x for x in uberon_graph.objects(x, dbxref_uri) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ed = '|'.join([str(c) for c in cls_ed]) if len(cls_ed) > 0 else 'None'\n",
    "    # external definition\n",
    "    cls_extd = [x for x in uberon_graph.objects(x, obo.UBPROP_0000001) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_extd = str(cls_extd[0]) if len(cls_extd) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'Description': desc, 'Synonym(s)': synonym,\n",
    "        'DbXref': desc_ed, 'ExternalDefinition': desc_extd\n",
    "    }\n",
    "\n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'Uberon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49611ff2",
   "metadata": {},
   "source": [
    "***\n",
    "# CLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clo_graph = Graph()\n",
    "clo_graph.parse(ontology_data_location + 'clo_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(clo_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "comment = URIRef(\"http://www.w3.org/2000/01/rdf-schema#comment\")\n",
    "seeAlso = URIRef(\"http://www.w3.org/2000/01/rdf-schema#seeAlso\")\n",
    "depictedBy = URIRef(\"http://xmlns.com/foaf/0.1/depicted_by\")\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(clo_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(clo_graph)]\n",
    "master_synonyms = [x for x in clo_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in clo_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0])  if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(c) for c in cls_syn]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in clo_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    # DbXref\n",
    "    cls_ed = [x for x in clo_graph.objects(x, dbxref_uri) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ed = '|'.join([str(c) for c in cls_ed]) if len(cls_ed) > 0 else 'None'\n",
    "    # comment\n",
    "    cls_com = [x for x in clo_graph.objects(x, comment) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_com = '|'.join([str(c) for c in cls_com]) if len(cls_com) > 0 else 'None'\n",
    "    # seeAlso\n",
    "    cls_sa = [x for x in clo_graph.objects(x, seeAlso) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_sa = '|'.join([str(c) for c in cls_sa]) if len(cls_sa) > 0 else 'None'\n",
    "    # depicted by\n",
    "    cls_db = [x for x in clo_graph.objects(x, depictedBy) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_db = '|'.join([str(c) for c in cls_db]) if len(cls_db) > 0 else 'None'\n",
    "    # example of usage\n",
    "    cls_eou = [x for x in clo_graph.objects(x, obo.IAO_0000112) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_eou = str(cls_eou[0]) if len(cls_eou) > 0 else 'None'\n",
    "    # definition source\n",
    "    cls_ds = [x for x in clo_graph.objects(x, obo.IAO_0000119) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ds = str(cls_ds[0]) if len(cls_ds) > 0 else 'None'\n",
    "    # alternative term\n",
    "    cls_at = [x for x in clo_graph.objects(x, obo.IAO_0000118) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_at = '|'.join([str(c) for c in cls_at]) if len(cls_at) > 0 else 'None'\n",
    "    # IEDB alternative term\n",
    "    cls_iedb = [x for x in clo_graph.objects(x, obo.OBI_9991118) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_iedb = str(cls_iedb[0]) if len(cls_iedb) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'Description': desc, 'Synonym(s)': synonym, 'DbXref': desc_ed,\n",
    "        'Comment': desc_com, 'SeeAlso': desc_sa, 'DepictedBy': desc_db, 'ExampleOfUsage': desc_eou,\n",
    "        'DefinitionSource': desc_ds, 'AlternativeTerm': desc_at, 'IEDBalternativeTerm': desc_iedb\n",
    "    }\n",
    "\n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c97de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'CLO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423788e3",
   "metadata": {},
   "source": [
    "***\n",
    "# PRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_graph = Graph()\n",
    "pro_graph.parse(ontology_data_location + 'pr_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(pro_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ed521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "comment = URIRef(\"http://www.w3.org/2000/01/rdf-schema#comment\")\n",
    "seeAlso = URIRef(\"http://www.w3.org/2000/01/rdf-schema#seeAlso\")\n",
    "depictedBy = URIRef(\"http://xmlns.com/foaf/0.1/depicted_by\")\n",
    "orth = URIRef(\"http://purl.obolibrary.org/obo/pr#PRO-short-label\")\n",
    "syn2 = URIRef(\"http://purl.obolibrary.org/obo/pr#Gene-based\")\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(pro_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(pro_graph)]\n",
    "master_synonyms = [x for x in pro_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in pro_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0])  if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(c) for c in cls_syn]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in pro_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    # DbXref\n",
    "    cls_ed = [x for x in pro_graph.objects(x, dbxref_uri) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ed = '|'.join([str(c) for c in cls_ed]) if len(cls_ed) > 0 else 'None'\n",
    "    # comment\n",
    "    cls_com = [x for x in pro_graph.objects(x, comment) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_com = '|'.join([str(c) for c in cls_com]) if len(cls_com) > 0 else 'None'\n",
    "    # unique short label for PRO terms for display purposes; based on orthology\n",
    "    cls_orth = [x for x in pro_graph.objects(x, orth) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_orth = str(cls_orth[0]) if len(cls_orth) > 0 else 'None'\n",
    "    # synonyms based on current or previous gene name, ORF name, or ordered locus name\n",
    "    cls_syn2 = [x for x in pro_graph.objects(x, syn2) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_syn2 = '|'.join([str(c) for c in cls_syn2]) if len(cls_syn2) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'Description': desc, 'Synonym(s)': synonym, 'DbXref': desc_ed,\n",
    "        'Comment': desc_com, 'UniqueShortLabel(orthology-based)': desc_orth,\n",
    "        'Synonym(s)(unusedName/ORF/locus-based)': desc_syn2,\n",
    "    }\n",
    "\n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e20955",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'PRO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f1cfc",
   "metadata": {},
   "source": [
    "***\n",
    "# SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf343b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "so_graph = Graph()\n",
    "so_graph.parse(ontology_data_location + 'so_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(so_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae111fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(so_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(so_graph)]\n",
    "master_synonyms = [x for x in so_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in so_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0])  if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(c) for c in cls_syn]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in so_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    # DbXref\n",
    "    cls_ed = [x for x in so_graph.objects(x, dbxref_uri) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc_ed = '|'.join([str(c) for c in cls_ed]) if len(cls_ed) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'Description': desc, 'Synonym(s)': synonym, 'DbXref': desc_ed\n",
    "    }\n",
    "\n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200b335",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'SO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70b4a48",
   "metadata": {},
   "source": [
    "***\n",
    "# PW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e50fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_graph = Graph()\n",
    "pw_graph.parse(ontology_data_location + 'pw_with_imports.owl')\n",
    "\n",
    "print('There are {} edges in the ontology.'.format(len(pw_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "relation_metadata_dict, obo = {}, Namespace('http://purl.obolibrary.org/obo/')\n",
    "\n",
    "# get ontology information\n",
    "cls = [x for x in gets_ontology_classes(pw_graph)] #+\\\n",
    "      #[x for x in gets_object_properties(pw_graph)]\n",
    "master_synonyms = [x for x in pw_graph if 'synonym' in str(x[1]).lower() and isinstance(x[0], URIRef)]\n",
    "\n",
    "for x in tqdm(cls):\n",
    "    # labels\n",
    "    cls_label = [x for x in pw_graph.objects(x, RDFS.label) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    labels = str(cls_label[0]) if len(cls_label) > 0 else 'None'\n",
    "    # synonyms\n",
    "    cls_syn = [str(i[2]) for i in master_synonyms if x == i[0]]\n",
    "    synonym = '|'.join([str(c) for c in cls_syn]) if len(cls_syn) > 0 else 'None'\n",
    "    # description\n",
    "    cls_desc = [x for x in pw_graph.objects(x, obo.IAO_0000115) if '@' not in n3(x) or '@en' in n3(x)]\n",
    "    desc = str(cls_desc[0]) if len(cls_desc) > 0 else 'None'\n",
    "    \n",
    "    relation_metadata_dict[str(x)] = {\n",
    "        'Label': labels, 'Description': desc, 'Synonym(s)': synonym\n",
    "    } \n",
    "\n",
    "pd.DataFrame(relation_metadata_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relation_metadata_dict).T.drop_duplicates().to_csv(properties_location + 'PW.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
