{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "path = config['working_dir']\n",
    "\n",
    "output_dir = os.path.join(path,'output_bert_no_dim_new_new3') \n",
    "print('output_dir: ',output_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)  \n",
    "\n",
    "logging.basicConfig(filename=os.path.join(output_dir, 'txt_embedding_generation.log'), \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = config['nodes_file_path']  \n",
    "print('nodes_file_path:',file_path)\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", usecols=[\"name\", \"type\", \"Description\", \"Sequence\"])\n",
    "\n",
    "biobert_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\", trust_remote_code=True)\n",
    "biobert_model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\", trust_remote_code=True)\n",
    "\n",
    "df[\"embedding\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_text_embedding(text):\n",
    "    if pd.isna(text):  \n",
    "        return None\n",
    "    try:\n",
    "        inputs = biobert_tokenizer(text, return_tensors='pt')['input_ids']\n",
    "        hidden_states = biobert_model(inputs)[0]  # [1, sequence_length, 768]\n",
    "\n",
    "        embedding_mean = torch.mean(hidden_states[0], dim=0)  # Mean pooling\n",
    "\n",
    "        return embedding_mean.detach().cpu().numpy().tolist() \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: len {len(text)}  {text}. \\nErrore: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_batch(df, file_path):\n",
    "    if not os.path.exists(os.path.dirname(file_path)):\n",
    "        os.makedirs(os.path.dirname(file_path))\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        existing_df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "        df = pd.concat([existing_df, df], ignore_index=True)\n",
    "    \n",
    "    df[[\"name\", 'type', \"embedding\"]].to_csv(file_path, sep=\"\\t\", index=False)\n",
    "    os.sync()  \n",
    "\n",
    "def load_processed_indices(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        return set(pd.read_csv(file_path, sep=\"\\t\").index.tolist())\n",
    "    return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_output_path = os.path.join(output_dir, \"text_embeddings.tsv\")\n",
    "text_output_filled_path = os.path.join(output_dir, \"text_embeddings_filled.tsv\")\n",
    "processed_indices_path = os.path.join(output_dir, \"processed_text_indices.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df[df[\"type\"].isin([\"Phenotype\", \"Disease\", \"Genomic feature\"])].copy()\n",
    "df_text\n",
    "\n",
    "processed_indices = load_processed_indices(processed_indices_path)\n",
    "\n",
    "if os.path.exists(text_output_path):\n",
    "    existing_df = pd.read_csv(text_output_path, sep=\"\\t\")\n",
    "    if len(existing_df) == len(df_text):  \n",
    "        df_text = existing_df\n",
    "    else:\n",
    "        for i, row in df_text.iterrows():\n",
    "            if i in processed_indices:  \n",
    "                continue\n",
    "            print(row[\"Description\"])\n",
    "            embedding = get_text_embedding(row[\"Description\"])\n",
    "            df_text.at[i, \"embedding\"] = embedding  \n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                save_batch(df_text.iloc[i-9:i+1], text_output_path)\n",
    "                with open(processed_indices_path, \"a\") as f:\n",
    "                    f.write(\"\\n\".join(map(str, range(i-9, i+1))) + \"\\n\")\n",
    "\n",
    "        remaining_indices = range(len(df_text) - (len(df_text) % 10), len(df_text))\n",
    "        if len(remaining_indices) > 0:\n",
    "            save_batch(df_text.iloc[remaining_indices], text_output_path)\n",
    "            with open(processed_indices_path, \"a\") as f:\n",
    "                f.write(\"\\n\".join(map(str, remaining_indices)) + \"\\n\")\n",
    "else:\n",
    "    for i, row in df_text.iterrows():\n",
    "        embedding = get_text_embedding(row[\"Description\"])\n",
    "        df_text.at[i, \"embedding\"] = embedding  \n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            save_batch(df_text.iloc[i-9:i+1], text_output_path)\n",
    "            with open(processed_indices_path, \"a\") as f:\n",
    "                f.write(\"\\n\".join(map(str, range(i-9, i+1))) + \"\\n\")\n",
    "\n",
    "    remaining_indices = range(len(df_text) - (len(df_text) % 10), len(df_text))\n",
    "    if len(remaining_indices) > 0:\n",
    "        save_batch(df_text.iloc[remaining_indices], text_output_path)\n",
    "        with open(processed_indices_path, \"a\") as f:\n",
    "            f.write(\"\\n\".join(map(str, remaining_indices)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_null_embeddings_with_type_mean(df):\n",
    "\n",
    "    if isinstance(df['embedding'].iloc[0], str):\n",
    "        df['embedding'] = df['embedding'].apply(lambda x: eval(x) if pd.notna(x) else np.nan)\n",
    "    \n",
    "    df['embedding'] = df['embedding'].apply(lambda x: np.array(x) if isinstance(x, list) else x)\n",
    "    \n",
    "    non_null_mask = df['embedding'].apply(lambda x: x is not np.nan if isinstance(x, np.ndarray) else pd.notna(x))\n",
    "    non_null_embeddings = df[non_null_mask]\n",
    "    \n",
    "    type_mean_embeddings = non_null_embeddings.groupby('type')['embedding'].apply(\n",
    "        lambda x: np.mean(np.stack(x.values), axis=0)\n",
    "    ).to_dict()\n",
    "    \n",
    "    def fill_na_embedding(row):\n",
    "        if isinstance(row['embedding'], np.ndarray):\n",
    "            return row['embedding']\n",
    "        elif pd.isna(row['embedding']):\n",
    "            return type_mean_embeddings.get(row['type'], np.nan)\n",
    "        return row['embedding']\n",
    "    \n",
    "    df['embedding'] = df.apply(fill_na_embedding, axis=1)\n",
    "\n",
    "    def to_list(embedding):\n",
    "        if isinstance(embedding, str):\n",
    "            embedding = np.array(eval(embedding))\n",
    "        return embedding.tolist()\n",
    "    \n",
    "    df['embedding'] = df['embedding'].apply(to_list)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_text = pd.read_csv(text_output_path, sep=\"\\t\")\n",
    "\n",
    "df_text_filled = replace_null_embeddings_with_type_mean(df_text)\n",
    "print(df_text_filled[df_text_filled['embedding'].isna()]) \n",
    "\n",
    "if os.path.exists(text_output_filled_path):\n",
    "    pass \n",
    "else:\n",
    "    try:\n",
    "        save_batch(df_text_filled, text_output_filled_path)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
