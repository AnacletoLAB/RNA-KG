{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "path = config['working_dir']\n",
    "\n",
    "input_dir = os.path.join(path,'output_embedding')\n",
    "print('input_dir:',input_dir)\n",
    "output_dir = os.path.join(path,'output_embedding/results')\n",
    "print('output_dir:',output_dir)\n",
    "\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(filename=os.path.join(output_dir,'output_prediction.log'), \n",
    "                    level=logging.DEBUG, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape import Graph\n",
    "import pandas as pd\n",
    "\n",
    "nodes_df_path = config['nodes_file_path']\n",
    "print('nodes_df_path:',nodes_df_path)\n",
    "edges_df_path = config['edges_file_path']\n",
    "print('edges_df_path:',edges_df_path)\n",
    "\n",
    "nodes_df = pd.read_csv(nodes_df_path, sep=\"\\t\")\n",
    "edges_df = pd.read_csv(edges_df_path, sep=\"\\t\")\n",
    "\n",
    "view_directed = Graph.from_pd(\n",
    "    edges_df=edges_df,\n",
    "    nodes_df=nodes_df,\n",
    "    node_name_column=\"name\",\n",
    "    node_type_column=\"type\",\n",
    "    edge_src_column=\"subject\",\n",
    "    edge_dst_column=\"object\",\n",
    "    edge_type_column=\"predicate\",\n",
    "    directed=True,\n",
    "    name=\"RNA-KG VIEW_properties\",\n",
    ")\n",
    "view_undirected = Graph.from_pd(\n",
    "    edges_df=edges_df,\n",
    "    nodes_df=nodes_df,\n",
    "    node_name_column=\"name\",\n",
    "    node_type_column=\"type\",\n",
    "    edge_src_column=\"subject\",\n",
    "    edge_dst_column=\"object\",\n",
    "    edge_type_column=\"predicate\",\n",
    "    directed=False,\n",
    "    name=\"RNA-KG VIEW_properties\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions using SciKit-Learn to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to use the models directly from sci-kit learn instead of grape\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import grape\n",
    "\n",
    "\n",
    "def get_edge_type_ids_list(graph):\n",
    "    edge_types = []\n",
    "    for edge_id in range(graph.get_number_of_directed_edges()):\n",
    "        predicate = graph.get_edge_type_name_from_edge_id(edge_id)\n",
    "        predicate_id = graph.get_edge_type_id_from_edge_type_name(predicate)\n",
    "        edge_types.append(predicate_id)\n",
    "    return edge_types\n",
    "\n",
    "\n",
    "def extract_embeddings_for_graph(grape_embedding, grape_graph):\n",
    "    before = time.time()\n",
    "    node_embedding = grape_embedding.get_all_node_embedding()\n",
    "    try:\n",
    "        edge_type_embedding = grape_embedding.get_all_edge_type_embeddings()\n",
    "    except ValueError as e:\n",
    "        logging.warning(\n",
    "            f\"Error while extracting edge type embeddings: {e}, using empty list instead\"\n",
    "        )\n",
    "        edge_type_embedding = []\n",
    "    number_of_edges = grape_graph.get_number_of_directed_edges()\n",
    "    edge_node_names = grape_graph.get_edge_node_names(directed=True)\n",
    "    embeddings = []\n",
    "    for edge_id in range(number_of_edges):\n",
    "        subject = edge_node_names[edge_id][0]\n",
    "        object = edge_node_names[edge_id][1]\n",
    "        predicate = grape_graph.get_edge_type_name_from_edge_id(edge_id)\n",
    "        subject_embedding = node_embedding[0].loc[subject].values\n",
    "        predicate_embedding = (\n",
    "            edge_type_embedding[0].loc[predicate].values\n",
    "            if len(edge_type_embedding) > 0\n",
    "            else np.empty(0)\n",
    "        )\n",
    "        object_embedding = node_embedding[0].loc[object].values\n",
    "        edge_embedding = np.concatenate(\n",
    "            [subject_embedding, predicate_embedding, object_embedding]\n",
    "        )\n",
    "        embeddings.append(edge_embedding)\n",
    "    logging.info(f\"Embedding extraction time:{time.time()-before}\")\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def edge_pred_pairs_sklearn(\n",
    "    graph,\n",
    "    embedder,\n",
    "    edge_pred_model,\n",
    "    pairs_to_predict,\n",
    "    name_for_df=None,\n",
    "    clear_output=False,\n",
    "    train_size=0.7,\n",
    "    number_of_holdouts=5,\n",
    "    seed=42,\n",
    "    use_scale_free_distribution=True,\n",
    "    train_on_filtered=True,\n",
    "    training_unbalance_rate=1.0,\n",
    "    verbose=False,\n",
    "    binary=True,\n",
    "):\n",
    "    df_results = pd.DataFrame()\n",
    "    columns = [\n",
    "        \"Graph\",\n",
    "        \"Embedder\",\n",
    "        \"Model\",\n",
    "        \"Source Type\",\n",
    "        \"Destination Type\",\n",
    "        \"Train on filtered\",\n",
    "        \"Training set size\",\n",
    "        \"Testing set size\",\n",
    "        \"Training balanced accuracy\",\n",
    "        \"Positive balanced accuracy\",\n",
    "        \"Negative balanced accuracy\",\n",
    "        \"Mean balanced accuracy\",  # ,'AUC'\n",
    "    ]\n",
    "\n",
    "    for i, pair_to_predict in enumerate(pairs_to_predict):\n",
    "        print(f\"Predicting pair: {pair_to_predict} ({i+1}/{len(pairs_to_predict)})\")\n",
    "\n",
    "        # change how the training behaves\n",
    "        # update_fit(edge_pred_model, pair_to_predict if train_on_filtered else None, graph) # Not needed anymore with the sklearn models\n",
    "        # negative graph extracted from the full graph to avoid false negatives\n",
    "        # model will only be trained on data of the relevant type pair to predict\n",
    "        results_custom_filtered_train = edge_prediction_pipeline_sklearn(\n",
    "            graph,\n",
    "            edge_pred_model,\n",
    "            embedder,\n",
    "            pair_to_predict,\n",
    "            train_on_filtered=train_on_filtered,\n",
    "            train_size=train_size,\n",
    "            number_of_holdouts=number_of_holdouts,\n",
    "            seed=seed,\n",
    "            verbose=verbose,\n",
    "            clear_output_holdout=clear_output,\n",
    "            use_scale_free_distribution=use_scale_free_distribution,\n",
    "            training_unbalance_rate=training_unbalance_rate,\n",
    "            binary=binary,\n",
    "        )\n",
    "        df_results_custom_filtered_train = pd.DataFrame(results_custom_filtered_train)\n",
    "        df_results = pd.concat([df_results, df_results_custom_filtered_train])\n",
    "\n",
    "    df_results.columns = columns\n",
    "    edge_pred_model_name = (\n",
    "        edge_pred_model.__class__.__module__ + \".\" + edge_pred_model.__class__.__name__\n",
    "    )\n",
    "    df_results[\"edge_pred_model\"] = edge_pred_model_name\n",
    "    df_results[\"embedding_model\"] = \"\"#embedder.model_name()\n",
    "    df_results[\"name\"] = (\n",
    "        f\"-{edge_pred_model_name}\"#{embedder.model_name()}\n",
    "        if name_for_df is None\n",
    "        else name_for_df\n",
    "    )\n",
    "    # results[f'{embedder.model_name()}-{model.model_name()}'] = df_results\n",
    "    return df_results\n",
    "\n",
    "\n",
    "def edge_prediction_pipeline_sklearn(\n",
    "    graph,\n",
    "    model,\n",
    "    embedder,\n",
    "    pair_to_predict,\n",
    "    train_on_filtered=True,\n",
    "    train_size=0.7,\n",
    "    number_of_holdouts=5,\n",
    "    seed=42,\n",
    "    verbose=False,\n",
    "    clear_output_holdout=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    training_unbalance_rate=1.0,\n",
    "    binary=True,\n",
    "):\n",
    "    random.seed(seed)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(number_of_holdouts):\n",
    "        # clean the cell output at each iteration to avoid huge cell outputs\n",
    "        if clear_output_holdout:\n",
    "            clear_output(wait=True)\n",
    "        # use connected monte carlo to obtain a training set that has the same connectivity guarantees as full graph\n",
    "        logging.info(f\"Generating holdout {i+1}/{number_of_holdouts}\")\n",
    "        random_state = random.randrange(0, 100000)\n",
    "        train_graph, positive_test_graph = graph.connected_holdout(\n",
    "            train_size=train_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "        # check if number of connected components is the same in the training set and full graph\n",
    "        logging.debug(train_graph.get_number_of_connected_components())\n",
    "        assert (\n",
    "            train_graph.get_number_of_connected_components()\n",
    "            == graph.get_number_of_connected_components()\n",
    "        )\n",
    "\n",
    "        logging.info(\"Filtering train and test graph by source/destination node type\")\n",
    "        # keep only the edges (source-destination node type) we are interested in\n",
    "        train_graph_filtered = train_graph.filter_from_names(\n",
    "            source_node_type_name_to_keep=[pair_to_predict[0]],\n",
    "            destination_node_type_name_to_keep=[pair_to_predict[1]],\n",
    "        )\n",
    "        test_graph_filtered = positive_test_graph.filter_from_names(\n",
    "            source_node_type_name_to_keep=[pair_to_predict[0]],\n",
    "            destination_node_type_name_to_keep=[pair_to_predict[1]],\n",
    "        )\n",
    "\n",
    "        # check if embedder is of class grape.EmbeddingResult\n",
    "        if not isinstance(embedder, grape.EmbeddingResult):\n",
    "            # calculate the embedding on the not filtered train graph\n",
    "            logging.info(\"Training embedding on unfiltered train graph\")\n",
    "            before = time.time()\n",
    "\n",
    "            train_embedding = embedder.fit_transform(train_graph)\n",
    "\n",
    "            logging.info(f\"Embedding time:{time.time()-before}\")\n",
    "        else:\n",
    "            logging.info(\"Using precalculated embeddings\")\n",
    "            train_embedding = embedder\n",
    "\n",
    "        logging.info(\"Training model using the filtered train graph\")\n",
    "\n",
    "        logging.info(\"Generating negative training graph\")\n",
    "        before = time.time()\n",
    "        number_of_negative_samples = (\n",
    "            int(\n",
    "                math.ceil(\n",
    "                    train_graph_filtered.get_number_of_directed_edges()\n",
    "                    * training_unbalance_rate\n",
    "                )\n",
    "            )\n",
    "            if train_on_filtered\n",
    "            else int(\n",
    "                math.ceil(\n",
    "                    train_graph.get_number_of_directed_edges() * training_unbalance_rate\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Number of negative samples: {number_of_negative_samples}\")\n",
    "        train_negative_graph = graph.sample_negative_graph(  # using the full graph to generate the negative edges to avoid false negatives\n",
    "            number_of_negative_samples=number_of_negative_samples,\n",
    "            # only_from_same_component=True,\n",
    "            random_state=random_state,\n",
    "            use_scale_free_distribution=use_scale_free_distribution,\n",
    "            # sample_edge_types=False, # TODO: check if this is correct and test what happens if it is True\n",
    "            source_node_types_names=[pair_to_predict[0]] if pair_to_predict else None,\n",
    "            destination_node_types_names=(\n",
    "                [pair_to_predict[1]] if pair_to_predict else None\n",
    "            ),\n",
    "        )\n",
    "        logging.info(train_negative_graph.get_unique_edge_type_ids())\n",
    "        logging.info(\n",
    "            f\"Number of edge types in negative training graph: {len(train_negative_graph.get_unique_edge_type_ids())}\"\n",
    "        )\n",
    "        logging.info(f\"Negative training graph generation time:{time.time()-before}\")\n",
    "        logging.info(\"Extracting embeddings for the negative training graph\")\n",
    "        before = time.time()\n",
    "        train_negative_graph_embeddings = extract_embeddings_for_graph(\n",
    "            train_embedding, train_negative_graph\n",
    "        )\n",
    "        logging.info(\n",
    "            f\"Negative training graph embedding extraction time:{time.time()-before}\"\n",
    "        )\n",
    "\n",
    "        if train_on_filtered:\n",
    "            logging.info(train_graph_filtered.get_unique_edge_type_ids())\n",
    "            logging.info(\n",
    "                f\"Number of edge types in positive training graph: {len(train_graph_filtered.get_unique_edge_type_ids())}\"\n",
    "            )\n",
    "            # generate the list of embeddings for the train_graph_filtered\n",
    "            logging.info(\"Extracting embeddings for the positive training graph\")\n",
    "            train_positive_graph_filtered_embeddings = extract_embeddings_for_graph(\n",
    "                train_embedding, train_graph_filtered\n",
    "            )\n",
    "            # combine the positive and negative embeddings\n",
    "            train_graph_embeddings = np.concatenate(\n",
    "                [\n",
    "                    train_positive_graph_filtered_embeddings,\n",
    "                    train_negative_graph_embeddings,\n",
    "                ]\n",
    "            )\n",
    "            # generate the list of labels for the train_graph_filtered\n",
    "            if binary:\n",
    "                train_graph_filtered_labels = [\n",
    "                    1 for _ in range(len(train_positive_graph_filtered_embeddings))\n",
    "                ] + [0 for _ in range(len(train_negative_graph_embeddings))]\n",
    "            else:\n",
    "                positive_train_edge_types = get_edge_type_ids_list(train_graph_filtered)\n",
    "                negative_train_edge_types = [\n",
    "                    -1 for _ in range(len(train_negative_graph_embeddings))\n",
    "                ]  # get_edge_type_ids_list(train_negative_graph)\n",
    "                train_graph_filtered_labels = (\n",
    "                    positive_train_edge_types + negative_train_edge_types\n",
    "                )\n",
    "\n",
    "            # train the model\n",
    "            logging.info(\"Training model on the filtered training graph\")\n",
    "            model = model.fit(train_graph_embeddings, train_graph_filtered_labels)\n",
    "        else:\n",
    "            logging.info(train_graph.get_unique_edge_type_ids())\n",
    "            logging.info(\n",
    "                f\"Number of edge types in positive training graph: {len(train_graph.get_unique_edge_type_ids())}\"\n",
    "            )\n",
    "            # generate the list of embeddings for the train_graph\n",
    "            logging.info(\"Extracting embeddings for the positive training graph\")\n",
    "            train_positive_graph_embeddings = extract_embeddings_for_graph(\n",
    "                train_embedding, train_graph\n",
    "            )\n",
    "            # combine the positive and negative embeddings\n",
    "            train_graph_embeddings = np.concatenate(\n",
    "                [train_positive_graph_embeddings, train_negative_graph_embeddings]\n",
    "            )\n",
    "            # generate the list of labels for the train_graph\n",
    "            if binary:\n",
    "                train_graph_labels = [\n",
    "                    1 for _ in range(len(train_positive_graph_embeddings))\n",
    "                ] + [0 for _ in range(len(train_negative_graph_embeddings))]\n",
    "            else:\n",
    "                positive_train_edge_types = get_edge_type_ids_list(train_graph)\n",
    "                negative_train_edge_types = [\n",
    "                    -1 for _ in range(len(train_negative_graph_embeddings))\n",
    "                ]  # get_edge_type_ids_list(train_negative_graph)\n",
    "                train_graph_labels = (\n",
    "                    positive_train_edge_types + negative_train_edge_types\n",
    "                )\n",
    "            # train the model\n",
    "            logging.info(\"Training model on the training graph\")\n",
    "            model = model.fit(train_graph_embeddings, train_graph_labels)\n",
    "\n",
    "        logging.info(\"Evaluating model on train set\")\n",
    "        train_pred = model.predict(train_graph_embeddings)\n",
    "        if train_on_filtered:\n",
    "            logging.info(\"Evaluating model on filtered positive train set\")\n",
    "            pos_train_pred = model.predict(train_positive_graph_filtered_embeddings)\n",
    "        else:\n",
    "            logging.info(\"Evaluating model on positive train set\")\n",
    "            pos_train_pred = model.predict(train_positive_graph_embeddings)\n",
    "        logging.info(\"Evaluating model on negative train set\")\n",
    "        neg_train_pred = model.predict(train_negative_graph_embeddings)\n",
    "\n",
    "        training_set_size = len(train_pred)\n",
    "\n",
    "        if binary:\n",
    "            train_score = (\n",
    "                balanced_accuracy_score(train_graph_filtered_labels, train_pred)\n",
    "                if train_on_filtered\n",
    "                else balanced_accuracy_score(train_graph_labels, train_pred)\n",
    "            )\n",
    "            pos_train_score = balanced_accuracy_score(\n",
    "                [1 for _ in range(len(pos_train_pred))], pos_train_pred\n",
    "            )\n",
    "            neg_train_score = balanced_accuracy_score(\n",
    "                [0 for _ in range(len(neg_train_pred))], neg_train_pred\n",
    "            )\n",
    "        else:\n",
    "            train_score = (\n",
    "                balanced_accuracy_score(train_graph_filtered_labels, train_pred)\n",
    "                if train_on_filtered\n",
    "                else balanced_accuracy_score(train_graph_labels, train_pred)\n",
    "            )\n",
    "            pos_train_score = balanced_accuracy_score(\n",
    "                positive_train_edge_types, pos_train_pred\n",
    "            )\n",
    "            neg_train_score = balanced_accuracy_score(\n",
    "                negative_train_edge_types, neg_train_pred\n",
    "            )\n",
    "\n",
    "        if verbose:\n",
    "            # pred_train_edge_presence = train_pred.apply(lambda row:check_if_in_graph(graph,row['sources'],row['destinations'],pair_to_predict),axis=1)\n",
    "            # train_score = balanced_accuracy_score(pred_train_edge_presence, train_pred['prediction'].apply(lambda x:x>0.5))\n",
    "            logging.info(f\"Balanced accuracy score TRAINING: {train_score}\")\n",
    "            logging.info(\n",
    "                f\"Balanced accuracy positive score TRAINING: {pos_train_score}\"\n",
    "            )\n",
    "            logging.info(\n",
    "                f\"Balanced accuracy negative score TRAINING: {neg_train_score}\"\n",
    "            )\n",
    "\n",
    "        logging.info(\"Creating a graph with the negative edges for testing\")\n",
    "        # create graph with negative edges for testing\n",
    "        negative_test_graph = graph.sample_negative_graph(\n",
    "            # number_of_negative_samples=test_graph_filtered.get_number_of_edges(), # this option creates only half the edges\n",
    "            number_of_negative_samples=test_graph_filtered.get_number_of_directed_edges(),\n",
    "            # only_from_same_component=True,\n",
    "            source_node_types_names=[pair_to_predict[0]],\n",
    "            destination_node_types_names=[pair_to_predict[1]],\n",
    "            random_state=random_state\n",
    "            + 1,  # to avoid the same random state as the negative training graph\n",
    "            use_scale_free_distribution=use_scale_free_distribution,\n",
    "        )\n",
    "        logging.info(negative_test_graph.get_unique_edge_type_ids())\n",
    "        logging.info(\n",
    "            f\"Number of edge types in negative test graph: {len(negative_test_graph.get_unique_edge_type_ids())}\"\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            logging.info(\n",
    "                f\"#edges in positive test graph: {test_graph_filtered.get_number_of_directed_edges()}\"\n",
    "            )\n",
    "            logging.info(\n",
    "                f\"#edges in negative test graph: {negative_test_graph.get_number_of_directed_edges()}\"\n",
    "            )\n",
    "\n",
    "        # use model to predict on the positive edges\n",
    "        logging.info(\"Using the model to predict the existence of positive edges\")\n",
    "        # pos_pred = model.predict_proba(\n",
    "        #   graph=test_graph_filtered,\n",
    "        #   edge_features=transe_edge_features,\n",
    "        #   return_predictions_dataframe=True,\n",
    "        #   support=train_graph\n",
    "        # )\n",
    "        pos_pred = model.predict(\n",
    "            extract_embeddings_for_graph(train_embedding, test_graph_filtered)\n",
    "        )\n",
    "\n",
    "        # if verbose:\n",
    "        #     # check if all edges of positive test set are in the original graph\n",
    "        #     pos_pred_edge_presence = pos_pred.apply(lambda row:check_if_in_graph(graph,row['sources'],row['destinations'],pair_to_predict),axis=1)\n",
    "        #     logging.info(f'Are all positive edges present in the positive test set also in the original graph? {pos_pred_edge_presence.all()}')\n",
    "        #     logging.info(pos_pred_edge_presence.value_counts())\n",
    "\n",
    "        # use model to predict on the negative edges\n",
    "        logging.info(\"Using the model to predict the non-existence of negative edges\")\n",
    "        # neg_pred = model.predict_proba(\n",
    "        #   graph=negative_test_graph,\n",
    "        #   edge_features=transe_edge_features,\n",
    "        #   return_predictions_dataframe=True,\n",
    "        #   support=train_graph\n",
    "        # )\n",
    "        neg_pred = model.predict(\n",
    "            extract_embeddings_for_graph(train_embedding, negative_test_graph)\n",
    "        )\n",
    "\n",
    "        testing_set_size = len(pos_pred) + len(neg_pred)\n",
    "\n",
    "        # if verbose:\n",
    "        #     # check if all edges of negative test set are not in the original graph\n",
    "        #     neg_pred_edge_presence = neg_pred.apply(lambda row:check_if_in_graph(graph,row['sources'],row['destinations'],pair_to_predict),axis=1)\n",
    "        #     logging.info(f'Are all negative edges present in the negative test set NOT in the original graph? {~neg_pred_edge_presence.all()}')\n",
    "        #     logging.info(neg_pred_edge_presence.value_counts())\n",
    "\n",
    "        # calculate balanced accuracy score for positive and negative predictions\n",
    "        if binary:\n",
    "            pos_score = balanced_accuracy_score(\n",
    "                [1 for _ in range(len(pos_pred))], pos_pred\n",
    "            )\n",
    "            neg_score = balanced_accuracy_score(\n",
    "                [0 for _ in range(len(neg_pred))], neg_pred\n",
    "            )\n",
    "        else:\n",
    "            positive_test_edge_types = get_edge_type_ids_list(test_graph_filtered)\n",
    "            negative_test_edge_types = [\n",
    "                -1 for _ in range(len(neg_pred))\n",
    "            ]  # get_edge_type_ids_list(negative_test_graph)\n",
    "            pos_score = balanced_accuracy_score(positive_test_edge_types, pos_pred)\n",
    "            neg_score = balanced_accuracy_score(negative_test_edge_types, neg_pred)\n",
    "            overall_score = balanced_accuracy_score(\n",
    "                positive_test_edge_types + negative_test_edge_types,\n",
    "                np.concatenate([pos_pred, neg_pred]),\n",
    "            )\n",
    "            logging.info(f\"Overall balanced accuracy score: {overall_score}\")\n",
    "        # pos_score = balanced_accuracy_score([True for _ in range(len(pos_pred))], pos_pred)\n",
    "        # neg_score = balanced_accuracy_score([False for _ in range(len(neg_pred))], neg_pred)\n",
    "        logging.info(f\"Balanced accuracy positive score: {pos_score}\")\n",
    "        logging.info(f\"Balanced accuracy negative score: {neg_score}\")\n",
    "        avg_score = (pos_score + neg_score) / 2\n",
    "        logging.info(f\"Balanced accuracy mean score: {avg_score}\")\n",
    "\n",
    "        # if binary:\n",
    "        #     auc_score = roc_auc_score(\n",
    "        #         [True for _ in range(len(pos_pred))] + [False for _ in range(len(neg_pred))],\n",
    "        #         np.concatenate([pos_pred, neg_pred])\n",
    "        #     )\n",
    "        # else:\n",
    "        #     auc_score = roc_auc_score(\n",
    "        #         positive_test_edge_types + negative_test_edge_types,\n",
    "        #         np.concatenate([pos_pred, neg_pred])\n",
    "        #     )\n",
    "        # logging.info(f\"AUC score: {auc_score}\")\n",
    "\n",
    "        if hasattr(model, \"get_depth\"):\n",
    "            logging.info(f\"Tree depth: {model.get_depth()}\")\n",
    "\n",
    "        model_name = model.__class__.__module__ + \".\" + model.__class__.__name__\n",
    "\n",
    "        results.append(\n",
    "            (\n",
    "                graph.get_name(),\n",
    "                \"\",#embedder.model_name(),\n",
    "                model_name,\n",
    "                pair_to_predict[0],\n",
    "                pair_to_predict[1],\n",
    "                train_on_filtered,\n",
    "                training_set_size,\n",
    "                testing_set_size,\n",
    "                train_score,\n",
    "                pos_score,\n",
    "                neg_score,\n",
    "                avg_score,\n",
    "            )  # ,auc_score\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Edge Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load naïve embedders (and store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naïve embedders\n",
    "\n",
    "# embedder_transE = TransEEnsmallen(random_state=seed) #default embedding_size=100\n",
    "# embedder_line = FirstOrderLINEEnsmallen(\n",
    "#     random_state=seed, enable_cache=False, embedding_size=100, verbose=False\n",
    "# )\n",
    "# embedder_node2vec = Node2VecSkipGramEnsmallen(random_state=seed, embedding_size=100)\n",
    "\n",
    "# graph_embedding_transe = embedder_transE.fit_transform(view_directed) # NB. directed graph \n",
    "# graph_embedding_line = embedder_line.fit_transform(view_undirected) # NB. undirected graph\n",
    "# graph_embedding_node2vec = embedder_node2vec.fit_transform(view_undirected) # NB. undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store naïve embeddings\n",
    "import numpy as np\n",
    "\n",
    "def store_embedding(embedding, folder, filename):\n",
    "  for i in range(embedding.number_of_embeddings()):\n",
    "    emb_i = embedding.get_node_embedding_from_index(i)\n",
    "    emb_i.loc[:, 'embedding'] = emb_i.iloc[:, 0:].apply(lambda row: row.to_list(), axis=1)\n",
    "    emb_i.index.name = 'name'\n",
    "    emb_i[['embedding']].to_csv(folder + f'{filename}_{i}.tsv', sep='\\t')\n",
    "\n",
    "store_embedding(graph_embedding_transe, 'store_embeddings/', 'transe_dim100')\n",
    "# store_embedding(graph_embedding_line, 'store_embeddings/', 'line_dim100')\n",
    "# store_embedding(graph_embedding_node2vec, 'store_embeddings/', 'node2vec_dim100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding via BioBERT / DNABERT\n",
    "\n",
    "def process_embeddings(input_text, input_seq, model_name):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    print(model_name)\n",
    "    \n",
    "    # df_t = pd.read_csv(input_seq, sep=\"\\t\", usecols=['name', 'embedding'])\n",
    "    # df_t.set_index('name', inplace=True)\n",
    "    # df_d = pd.read_csv(input_text, sep=\"\\t\", usecols=['name', 'embedding'])\n",
    "    # df_d.set_index('name', inplace=True)\n",
    "    \n",
    "    # df_b = pd.concat([df_t, df_d], axis=0)\n",
    "    df_b = pd.read_csv(input_seq, sep=\"\\t\", usecols=['name', 'embedding'])\n",
    "    df_b.set_index('name', inplace=True)\n",
    "    print(len(df_b['embedding'].apply(ast.literal_eval).iloc[0]))\n",
    "\n",
    "    df_fo = pd.read_csv(os.path.join(path, f\"prediction_output/{model_name}_dim100_0.tsv\"), sep=\"\\t\",usecols=['name', 'embedding'])\n",
    "    df_fo.set_index('name', inplace=True)\n",
    "    print(len(df_fo['embedding'].apply(ast.literal_eval).iloc[0]))\n",
    "\n",
    "    df = pd.merge(df_b, df_fo, left_index=True, right_index=True, suffixes=('_l', '_r'))  # default inner join\n",
    "\n",
    "    df['embedding'] = df.apply(lambda row: ast.literal_eval(row['embedding_l']) + ast.literal_eval(row['embedding_r']), axis=1)\n",
    "    df.drop(columns=['embedding_l', 'embedding_r'], inplace=True)\n",
    "\n",
    "    emb_length = len(df['embedding'].iloc[0])\n",
    "    print(emb_length)\n",
    "\n",
    "    exploded_df = pd.DataFrame(df['embedding'].tolist(), index=df.index)\n",
    "\n",
    "    df_final = pd.concat([df, exploded_df], axis=1)\n",
    "\n",
    "    df_final = df_final.drop(columns=['embedding'])\n",
    "    df_final.to_csv(os.path.join(output_dir, f'{prefix}_{model_name}100_0.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = os.path.join(output_dir, \"embedded_text_nan_filled.tsv\")\n",
    "input_seq = os.path.join(output_dir, \"BERT_embeddings.tsv\")\n",
    "\n",
    "process_embeddings(input_text,input_seq,'line')\n",
    "process_embeddings(input_text,input_seq,'node2vec')\n",
    "process_embeddings(input_text,input_seq,'transe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load external embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the external embeddings\n",
    "import pandas as pd\n",
    "import grape\n",
    "\n",
    "# Feel free to update this function to match the format of your embeddings\n",
    "# If the IDs are strings, \n",
    "def load_node_embedding(folder, filename):\n",
    "    i = 0\n",
    "    embeddings = []\n",
    "    while True:\n",
    "        try:\n",
    "            df_embedding_i = pd.read_csv(os.path.join(folder, f'{filename}_{i}.csv'), index_col=0)\n",
    "            # print(df_embedding_i.head())\n",
    "            embeddings.append(df_embedding_i)\n",
    "            i += 1\n",
    "        except FileNotFoundError:\n",
    "            logging.warning('load_node_embedding: file not found'+os.path.join(folder, f'{filename}_{i}.csv'))\n",
    "            break\n",
    "    embedding = grape.EmbeddingResult(embedding_method_name=filename, node_embeddings=embeddings)\n",
    "    return embedding\n",
    "\n",
    "# TODO: Change the folder and filename to match the location of your embeddings\n",
    "# node_embedding = load_node_embedding(folder='store_embeddings/', filename='emb_concat_transe_100_llm') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.embedders import TransEEnsmallen, FirstOrderLINEEnsmallen, Node2VecSkipGramEnsmallen\n",
    "\n",
    "# from grape.edge_prediction import DecisionTreeEdgePrediction, RandomForestEdgePrediction\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "seed = 42\n",
    "\n",
    "model_tree = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "pairs_to_predict = [\n",
    "    (\"miRNA\", \"Gene\"),\n",
    "    (\"miRNA\", \"Disease\"),\n",
    "    (\"miRNA\", \"Phenotype\"),\n",
    "    (\"Gene\", \"Disease\"),\n",
    "    (\"Gene\", \"Phenotype\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINE\n",
    "node_embedding = load_node_embedding(folder=input_dir, filename='openai_line100') # è necessario che il nome del file abbia suffisso _0 ma non va inserito in questo parametro\n",
    "\n",
    "# binary\n",
    "results_fun_line_tree_b = edge_pred_pairs_sklearn(\n",
    "    view_undirected,\n",
    "    node_embedding, #embedder_line,\n",
    "    model_tree,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=5,\n",
    "    binary=True\n",
    ")\n",
    "results_fun_line_tree_b.to_csv( os.path.join(output_dir, 'openai_line_100_tree_binary_undirected.csv')) \n",
    "\n",
    "# multiclass\n",
    "results_fun_line_tree_m = edge_pred_pairs_sklearn(\n",
    "    view_undirected,\n",
    "    node_embedding,\n",
    "    model_tree,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=1,\n",
    "    binary=False,\n",
    ")\n",
    "results_fun_line_tree_m.to_csv( os.path.join(output_dir, 'openai_line_100_tree_multiclass_undirected.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec\n",
    "node_embedding = load_node_embedding(folder=input_dir, filename='openai_node2vec100') # è necessario che il nome del file abbia suffisso _0 ma non va inserito in questo parametro\n",
    "\n",
    "# binary\n",
    "results_fun_node2vec_tree_b = edge_pred_pairs_sklearn(\n",
    "    view_undirected,\n",
    "    node_embedding, #embedder_line,\n",
    "    model_tree,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=5,\n",
    "    binary=True\n",
    ")\n",
    "results_fun_node2vec_tree_b.to_csv( os.path.join(output_dir, 'openai_node2vec_100_tree_binary_undirected.csv')) \n",
    "\n",
    "# multiclass\n",
    "results_fun_node2vec_tree_m = edge_pred_pairs_sklearn(\n",
    "    view_undirected,\n",
    "    node_embedding,\n",
    "    model_tree,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=1,\n",
    "    binary=False,\n",
    ")\n",
    "results_fun_node2vec_tree_m.to_csv( os.path.join(output_dir, 'openai_node2vec_100_tree_multiclass_undirected.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransE\n",
    "node_embedding = load_node_embedding(folder=input_dir, filename='openai_transe100') # è necessario che il nome del file abbia suffisso _0 ma non va inserito in questo parametro\n",
    "\n",
    "# binary\n",
    "results_fun_transE_tree_b = edge_pred_pairs_sklearn(\n",
    "    view_directed,  # change this to view_undirected to use the undirected graph\n",
    "    node_embedding,# change this to the embedder that you want to use or the precalculated embeddings loaded with load_node_embedding function\n",
    "    model_tree,  # change this to the model that you want to use usually DecisionTreeClassifier or RandomForestClassifier\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=5,\n",
    "    binary=True,  # change this to False if you want to predict the edge types instead of a binary classification\n",
    ")\n",
    "results_fun_transE_tree_b.to_csv(os.path.join(output_dir, 'openai_transe_100_tree_binary_directed.csv'))\n",
    "\n",
    "# multiclass\n",
    "results_fun_transE_tree_m = edge_pred_pairs_sklearn(\n",
    "    view_directed,  # change this to view_undirected to use the undirected graph\n",
    "    node_embedding,# change this to the embedder that you want to use or the precalculated embeddings loaded with load_node_embedding function\n",
    "    model_tree,  # change this to the model that you want to use usually DecisionTreeClassifier or RandomForestClassifier\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=5,\n",
    "    binary=False,  # change this to False if you want to predict the edge types instead of a binary classification\n",
    ")\n",
    "results_fun_transE_tree_m.to_csv(os.path.join(output_dir, 'openai_transe_100_tree_multiclass_directed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group results by source_type and destination_type, calculate mean and std for each group\n",
    "# results_fun_transE_tree.groupby([\"Source Type\", \"Destination Type\"])[\n",
    "#     [\n",
    "#         \"Positive balanced accuracy\",\n",
    "#         \"Negative balanced accuracy\",\n",
    "#         \"Mean balanced accuracy\",\n",
    "#     ]\n",
    "# ].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.embedders import TransEEnsmallen, FirstOrderLINEEnsmallen, Node2VecSkipGramEnsmallen\n",
    "\n",
    "# from grape.edge_prediction import DecisionTreeEdgePrediction, RandomForestEdgePrediction\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed = 42\n",
    "\n",
    "model_forest = RandomForestClassifier(random_state=seed, n_jobs=6)\n",
    "\n",
    "pairs_to_predict = [\n",
    "    (\"miRNA\", \"Gene\"),\n",
    "    (\"miRNA\", \"Disease\"),\n",
    "    (\"miRNA\", \"Phenotype\"),\n",
    "    (\"Gene\", \"Disease\"),\n",
    "    (\"Gene\", \"Phenotype\"),\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINE\n",
    "node_embedding = load_node_embedding(folder=input_dir, filename='openai_line100') \n",
    "\n",
    "# binary\n",
    "results_fun_line_forest_b = edge_pred_pairs_sklearn(\n",
    "    view_undirected,\n",
    "    node_embedding, #embedder_line,\n",
    "    model_forest,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=5,\n",
    "    binary=True\n",
    ")\n",
    "results_fun_line_forest_b.to_csv( os.path.join(output_dir, 'openai_line_100_forest_binary_undirected.csv')) \n",
    "\n",
    "# multiclass\n",
    "results_fun_line_forest_m = edge_pred_pairs_sklearn(\n",
    "    view_undirected,\n",
    "    node_embedding,\n",
    "    model_forest,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=1,\n",
    "    binary=False,\n",
    ")\n",
    "results_fun_line_forest_m.to_csv( os.path.join(output_dir, 'openai_line_100_forest_multiclass_undirected.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec\n",
    "node_embedding = load_node_embedding(folder=input_dir, filename='openai_node2vec100') # è necessario che il nome del file abbia suffisso _0 ma non va inserito in questo parametro\n",
    "\n",
    "# binary\n",
    "results_fun_node2vec_forest_b = edge_pred_pairs_sklearn(\n",
    "    view_undirected,\n",
    "    node_embedding, #embedder_line,\n",
    "    model_forest,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=5,\n",
    "    binary=True\n",
    ")\n",
    "results_fun_node2vec_forest_b.to_csv( os.path.join(output_dir, 'openai_node2vec_100_forest_binary_undirected.csv')) \n",
    "\n",
    "# multiclass\n",
    "results_fun_node2vec_forest_m = edge_pred_pairs_sklearn(\n",
    "    view_undirected,\n",
    "    node_embedding,\n",
    "    model_forest,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=1,\n",
    "    binary=False,\n",
    ")\n",
    "results_fun_node2vec_forest_m.to_csv( os.path.join(output_dir, 'openai_node2vec_100_forest_multiclass_undirected.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransE\n",
    "node_embedding = load_node_embedding(folder=input_dir, filename='openai_transe100')\n",
    "\n",
    "# binary\n",
    "results_fun_transE_forest_b = edge_pred_pairs_sklearn(\n",
    "    view_directed,  # change this to view_undirected to use the undirected graph\n",
    "    node_embedding,# change this to the embedder that you want to use or the precalculated embeddings loaded with load_node_embedding function\n",
    "    model_forest,  # change this to the model that you want to use usually DecisionTreeClassifier or RandomForestClassifier\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=5,\n",
    "    binary=True,  # change this to False if you want to predict the edge types instead of a binary classification\n",
    ")\n",
    "results_fun_transE_forest_b.to_csv(os.path.join(output_dir, 'openai_transe_100_forest_binary_directed.csv'))\n",
    "\n",
    "# multiclass\n",
    "results_fun_transE_forest_m = edge_pred_pairs_sklearn(\n",
    "    view_directed,  # change this to view_undirected to use the undirected graph\n",
    "    node_embedding,# change this to the embedder that you want to use or the precalculated embeddings loaded with load_node_embedding function\n",
    "    model_forest,  # change this to the model that you want to use usually DecisionTreeClassifier or RandomForestClassifier\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=5,\n",
    "    binary=False,  # change this to False if you want to predict the edge types instead of a binary classification\n",
    ")\n",
    "results_fun_transE_forest_m.to_csv(os.path.join(output_dir, 'openai_transe_100_forest_multiclass_directed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_fun_transE_forest.groupby([\"Source Type\", \"Destination Type\"])[\n",
    "#     [\n",
    "#         \"Positive balanced accuracy\",\n",
    "#         \"Negative balanced accuracy\",\n",
    "#         \"Mean balanced accuracy\",\n",
    "#     ]\n",
    "# ].agg([\"mean\", \"std\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
