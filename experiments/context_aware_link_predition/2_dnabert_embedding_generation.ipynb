{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertConfig, AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "path = config['working_dir']\n",
    "\n",
    "output_dir = os.path.join(path,'output_bert_no_dim_new_new2') \n",
    "print('output_dir:',output_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)  \n",
    "\n",
    "output_file_name = \"dna_embeddings\"\n",
    "print('output_file_name:',output_file_name)\n",
    "\n",
    "logging.basicConfig(filename=os.path.join(output_dir, 'dna_embedding_generation.log'), \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "nodes_file_path = config['nodes_file_path']  \n",
    "print('nodes_file_path:',nodes_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DNABERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\")\n",
    "dnabert_model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True, config=config)\n",
    "dnabert_tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding(seq):\n",
    "    if pd.isna(seq): \n",
    "        return None\n",
    "    try:\n",
    "        inputs = dnabert_tokenizer(seq, return_tensors='pt')[\"input_ids\"]\n",
    "        hidden_states = dnabert_model(inputs)[0]  # [1, sequence_length, 768]\n",
    "\n",
    "        # embedding with mean pooling\n",
    "        embedding_mean = torch.mean(hidden_states[0], dim=0)\n",
    "        \n",
    "        return embedding_mean.detach().cpu().numpy().tolist()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_final_embedding(sequences):\n",
    "    embeddings_list = []\n",
    "\n",
    "    for seq in sequences:\n",
    "        if not seq: \n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            embedding = calculate_embedding(seq)\n",
    "            if embedding is not None:\n",
    "                embeddings_list.append(embedding) \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error: {seq}: {e}\")\n",
    "\n",
    "    if not embeddings_list: \n",
    "        return None\n",
    "\n",
    "    final_embedding = np.mean(embeddings_list, axis=0).tolist()  \n",
    "    return final_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(nodes_file_path, sep='\\t')\n",
    "len0 = df.groupby('type')['name'].nunique()\n",
    "print(\"\\nCount of names by type :\",len0)\n",
    "\n",
    "df_dna = df[df[\"type\"].isin([\"Gene\", \"miRNA\"])]\n",
    "\n",
    "df_dna.loc[:, 'Sequence'] = df_dna['Sequence'].str.replace('U', 'T')\n",
    "\n",
    "df_dna.loc[:, 'len_seq'] = df_dna['Sequence'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "chunk_size = 512  \n",
    "df_dna.loc[:, 'seq_list'] = df_dna['Sequence'].apply(lambda seq: [seq[i:i + chunk_size] for i in range(0, len(seq), chunk_size)] if isinstance(seq, str) else [])\n",
    "df_dna.loc[:, 'seq_list_len'] = df_dna['seq_list'].apply(len)\n",
    "\n",
    "print(df_dna.shape)\n",
    "df_dna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len0 = df_dna[df_dna['len_seq']==0].groupby('type')['name'].nunique()\n",
    "print(\"\\nCount of names with seq_len=0 by type :\",len0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = os.path.join(output_dir, f'{output_file_name}.tsv')\n",
    "output_file_path_discarded = os.path.join(output_dir, f\"{output_file_name}_discarded.tsv\")\n",
    "\n",
    "if os.path.exists(output_file_path):\n",
    "    df_existing = pd.read_csv(output_file_path, sep='\\t')\n",
    "    processed_count = df_existing.shape[0]\n",
    "else:\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        f.write(\"name\\ttype\\tlen_seq\\tembedding\\n\")\n",
    "    processed_count = 0\n",
    "\n",
    "    \n",
    "batch_size = 5  \n",
    "embeddings_batch = []\n",
    "\n",
    "for index, row in df_dna.iloc[processed_count:].iterrows():\n",
    "    sequence_name = row['name']\n",
    "    sequence_type = row['type']\n",
    "    sequence_list = row['seq_list']\n",
    "    sequence_len = row['len_seq']\n",
    "        \n",
    "    embedding = calculate_final_embedding(sequence_list)\n",
    "\n",
    "    if embedding is None:\n",
    "        if not os.path.exists(output_file_path_discarded):\n",
    "            with open(output_file_path_discarded, 'w') as f:\n",
    "                f.write(\"name\\ttype\\tlen_seq\\tembedding\\n\")\n",
    "        \n",
    "        with open(output_file_path_discarded, 'a') as f:\n",
    "            f.write(f\"{sequence_name}\\t{sequence_type}\\t{sequence_len}\\n\")\n",
    "            \n",
    "    \n",
    "    embeddings_batch.append((sequence_name, sequence_type, sequence_len, embedding))\n",
    "    processed_count += 1\n",
    "\n",
    "    print(str(processed_count)+\"/\"+str(df_dna.shape[0])+\" name=\"+sequence_name)\n",
    "    logger.info(str(processed_count)+\"/\"+str(df_dna.shape[0])+\" name=\"+sequence_name)\n",
    "\n",
    "    if len(embeddings_batch) >= batch_size:\n",
    "        with open(output_file_path, 'a') as f:\n",
    "            for sequence_name, sequence_type, sequence_len, embedding in embeddings_batch:\n",
    "                f.write(f\"{sequence_name}\\t{sequence_type}\\t{sequence_len}\\t{embedding}\\n\")\n",
    "        embeddings_batch = []\n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "if embeddings_batch:\n",
    "    with open(output_file_path, 'a') as f:\n",
    "        for sequence_name, sequence_type, sequence_len, embedding in embeddings_batch:\n",
    "            f.write(f\"{sequence_name}\\t{sequence_type}\\t{sequence_len}\\t{embedding}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def replace_null_embeddings_with_type_mean(df):\n",
    "    if isinstance(df['embedding'].iloc[0], str):\n",
    "        df['embedding'] = df['embedding'].apply(lambda x: eval(x) if pd.notna(x) else np.nan)\n",
    "    \n",
    "    df['embedding'] = df['embedding'].apply(lambda x: np.array(x) if isinstance(x, list) else x)\n",
    "    \n",
    "    non_null_mask = df['embedding'].apply(lambda x: x is not np.nan if isinstance(x, np.ndarray) else pd.notna(x))\n",
    "    non_null_embeddings = df[non_null_mask]\n",
    "    \n",
    "    type_mean_embeddings = non_null_embeddings.groupby('type')['embedding'].apply(\n",
    "        lambda x: np.mean(np.stack(x.values), axis=0)\n",
    "    ).to_dict()\n",
    "    \n",
    "    def fill_na_embedding(row):\n",
    "        if isinstance(row['embedding'], np.ndarray):\n",
    "            return row['embedding']\n",
    "        elif pd.isna(row['embedding']):\n",
    "            return type_mean_embeddings.get(row['type'], np.nan)\n",
    "        return row['embedding']\n",
    "    \n",
    "    df['embedding'] = df.apply(fill_na_embedding, axis=1)\n",
    "\n",
    "    def to_list(embedding):\n",
    "        if isinstance(embedding, str):\n",
    "            embedding = np.array(eval(embedding))\n",
    "        return embedding.tolist()\n",
    "    \n",
    "    df['embedding'] = df['embedding'].apply(to_list)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.read_csv(os.path.join(output_dir, f\"{output_file_name}.tsv\"), sep='\\t')\n",
    "df_output = replace_null_embeddings_with_type_mean(df_output)\n",
    "print(df_output[df_output['embedding'].isna()])  \n",
    "\n",
    "df_output.to_csv(os.path.join(output_dir, f\"{output_file_name}_filled.tsv\"), sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
