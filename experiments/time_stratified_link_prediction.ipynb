{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logging.getLogger().setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "edges_complete = pd.read_csv(\"complete_edges.csv\", usecols=[':START_ID', ':TYPE', ':END_ID', 'PubMedID:string[]'])# entire edges file\n",
    "edges_complete = edges_complete.rename(\n",
    "    columns={':START_ID': 'subject', ':END_ID': 'object', ':TYPE': 'predicate', 'PubMedID:string[]': 'PubMedID'})\n",
    "edges_complete = edges_complete[edges_complete['PubMedID'].notna()]\n",
    "len(edges_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pmids(pmid_cell):\n",
    "    if pd.isna(pmid_cell):\n",
    "        return 0\n",
    "    return len(str(pmid_cell).split(\";\"))\n",
    "\n",
    "total_pmids = edges_complete[\"PubMedID\"].apply(count_pmids).sum()\n",
    "total_pmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pmids(pmid_cell):\n",
    "    if pd.isna(pmid_cell):\n",
    "        return []\n",
    "    return [pmid.strip() for pmid in str(pmid_cell).split(\";\") if pmid.strip()]\n",
    "\n",
    "all_pmids = edges_complete[\"PubMedID\"].apply(extract_pmids)\n",
    "unique_pmids = set(pmid for sublist in all_pmids for pmid in sublist)\n",
    "len(unique_pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape import Graph\n",
    "import pandas as pd\n",
    "\n",
    "path_to_folder_with_graph_files = \"./data/\"\n",
    "\n",
    "nodes_df_path = path_to_folder_with_graph_files + \"nodes.tsv\"\n",
    "edges_df_path = path_to_folder_with_graph_files + \"edges.tsv\"\n",
    "nodes_df = pd.read_csv(nodes_df_path, sep=\"\\t\")\n",
    "edges_df = pd.read_csv(edges_df_path, sep=\"\\t\")\n",
    "\n",
    "edges_df = edges_df.merge(edges_complete, how='left', on=['subject', 'predicate', 'object'])\n",
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edges_df[edges_df['PubMedID'].notna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pmids = edges_df[\"PubMedID\"].apply(count_pmids).sum()\n",
    "total_pmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pmids = edges_df[\"PubMedID\"].apply(extract_pmids)\n",
    "unique_pmids = set(pmid for sublist in all_pmids for pmid in sublist)\n",
    "len(unique_pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "Entrez.email = \"emanuele.cavalleri@unimi.it\"\n",
    "Entrez.api_key = \"8d88dc3d63cd73854f0034baa217b05a9808\"\n",
    "\n",
    "pmid_cache_path = \"pmid_to_year.json\"\n",
    "\n",
    "if os.path.exists(pmid_cache_path):\n",
    "    with open(pmid_cache_path, \"r\") as f:\n",
    "        pmid_to_year = json.load(f)\n",
    "else:\n",
    "    pmid_to_year = {}\n",
    "\n",
    "to_process = [pmid for pmid in unique_pmids if pmid not in pmid_to_year]\n",
    "\n",
    "for pmid in tqdm(to_process, desc=\"Fetching publication years\"):\n",
    "    try:\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=pmid)\n",
    "        record = Entrez.read(handle)\n",
    "        pmid_to_year[pmid] = record['PubmedArticle'][0]['MedlineCitation'].get(\"DateRevised\", [])['Year']\n",
    "    except Exception as e:\n",
    "        pmid_to_year[pmid] = \"NA\"\n",
    "    finally:\n",
    "        sleep(0.15)\n",
    "        if len(pmid_to_year) % 100 == 0 or pmid == to_process[-1]:\n",
    "            with open(pmid_cache_path, \"w\") as f:\n",
    "                json.dump(pmid_to_year, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "with open(\"pmid_to_year.json\", \"r\") as f:\n",
    "    pmid_to_year = json.load(f)\n",
    "\n",
    "processed_years = []\n",
    "for year in pmid_to_year.values():\n",
    "    if year == \"NA\":\n",
    "        continue\n",
    "    try:\n",
    "        y = int(year)\n",
    "        if y <= 2012:\n",
    "            processed_years.append(\"2002–2012\")\n",
    "        elif 2013 <= y <= 2017:\n",
    "            processed_years.append(\"2013–2017\")\n",
    "        else:\n",
    "            processed_years.append(str(y))\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "year_counts = Counter(processed_years)\n",
    "\n",
    "df = pd.DataFrame(year_counts.items(), columns=[\"year\", \"count\"])\n",
    "df = df.sort_values(\n",
    "    by=\"year\",\n",
    "    key=lambda col: col.map(\n",
    "        lambda x: 2010 if x == \"2002–2012\" else (2011 if x == \"2013–2017\" else int(x))\n",
    "    )\n",
    ")\n",
    "\n",
    "df[\"color\"] = df[\"year\"].apply(lambda x: [176/255, 205/255, 241/255])\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(4.5, 3.5))\n",
    "bars = ax.bar(df[\"year\"], df[\"count\"], color=df[\"color\"].tolist(), width=0.8)\n",
    "\n",
    "def format_large_number(value):\n",
    "    if value >= 1_000_000:\n",
    "        return f\"{value / 1_000_000:.0f}M\"\n",
    "    elif value >= 1_000:\n",
    "        return f\"{value / 1_000:.0f}k\"\n",
    "    return str(value)\n",
    "\n",
    "for bar, value in zip(bars, df[\"count\"]):\n",
    "    y_pos = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, y_pos * 1.02, format_large_number(value),\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylim(1e3, 10 ** 4.3)\n",
    "ax.tick_params(axis='x', labelrotation=45, labelsize=9)\n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.tick_params(axis='y', which='both', labelleft=False)\n",
    "ax.grid(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "ax.tick_params(axis='y', which='both', length=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pubmed_years.png', dpi=400, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df_ = edges_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pmid_to_year.json\", \"r\") as f:\n",
    "    pmid_to_year = json.load(f)\n",
    "\n",
    "edges_df['PubMedID_list'] = edges_df['PubMedID'].str.split(';')\n",
    "edges_df = edges_df.drop(columns=['PubMedID'])\n",
    "edges_df = edges_df.explode('PubMedID_list').rename(columns={'PubMedID_list': 'PubMedID'})\n",
    "\n",
    "def extract_year(pmid_string):\n",
    "    if pd.isna(pmid_string) or not isinstance(pmid_string, str):\n",
    "        return None\n",
    "    pmids = pmid_string.split(\";\")\n",
    "    years = []\n",
    "    for pmid in pmids:\n",
    "        pmid = pmid.strip()\n",
    "        year = pmid_to_year.get(pmid)\n",
    "        if year and year != \"NA\":\n",
    "            try:\n",
    "                years.append(int(year))\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return years[0] if years else None\n",
    "\n",
    "edges_df[\"year\"] = edges_df[\"PubMedID\"].apply(extract_year)\n",
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "df = edges_df.merge(nodes_df[['name','type']], left_on='subject', right_on='name').drop(columns=['name']).merge(\n",
    "    nodes_df[['name','type']], left_on='object', right_on='name').drop(columns=['name'])\n",
    "\n",
    "def mirna_relation_type(row):\n",
    "    t1 = row['type_x'].lower()\n",
    "    t2 = row['type_y'].lower()\n",
    "    if 'mirna' in (t1, t2):\n",
    "        if 'gene' in (t1, t2):\n",
    "            return 'miRNA-Gene'\n",
    "        elif 'disease' in (t1, t2):\n",
    "            return 'miRNA-Disease'\n",
    "        elif 'phenotype' in (t1, t2):\n",
    "            return 'miRNA-Phenotype'\n",
    "    if 'gene' in (t1, t2):\n",
    "        if 'disease' in (t1, t2):\n",
    "            return 'Gene-Disease'\n",
    "        elif 'phenotype' in (t1, t2):\n",
    "            return 'Gene-Phenotype'\n",
    "    return 'Other'\n",
    "\n",
    "df['mirna_relation_type'] = df.apply(mirna_relation_type, axis=1)\n",
    "\n",
    "df = df[df['year'].notna()]\n",
    "\n",
    "def simplify_year(y):\n",
    "    try:\n",
    "        y = int(float(y))\n",
    "        if y <= 2012:\n",
    "            return \"2002–2012\"\n",
    "        elif 2013 <= y <= 2017:\n",
    "            return \"2013–2017\"\n",
    "        else:\n",
    "            return str(y)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['year_group'] = df['year'].apply(simplify_year)\n",
    "df = df[df['year_group'].notna()]\n",
    "\n",
    "counts_all = Counter(df['year_group'])\n",
    "\n",
    "counts_mirna_gene = Counter(df[df['mirna_relation_type'] == 'miRNA-Gene']['year_group'])\n",
    "counts_mirna_disease = Counter(df[df['mirna_relation_type'] == 'miRNA-Disease']['year_group'])\n",
    "counts_mirna_phenotype = Counter(df[df['mirna_relation_type'] == 'miRNA-Phenotype']['year_group'])\n",
    "counts_gene_disease = Counter(df[df['mirna_relation_type'] == 'Gene-Disease']['year_group'])\n",
    "counts_gene_phenotype = Counter(df[df['mirna_relation_type'] == 'Gene-Phenotype']['year_group'])\n",
    "\n",
    "years_sorted = sorted(set(counts_all.keys()), key=lambda x: 2010 if x == \"2002–2012\" else (2015 if x == \"2013–2017\" else int(x)))\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'year': years_sorted,\n",
    "    'all_relations': [counts_all[y] for y in years_sorted],\n",
    "    'miRNA-Gene': [counts_mirna_gene.get(y, 0) for y in years_sorted],\n",
    "    'miRNA-Disease': [counts_mirna_disease.get(y, 0) for y in years_sorted],\n",
    "    'miRNA-Phenotype': [counts_mirna_phenotype.get(y, 0) for y in years_sorted],\n",
    "    'Gene-Disease': [counts_gene_disease.get(y, 0) for y in years_sorted],\n",
    "    'Gene-Phenotype': [counts_gene_phenotype.get(y, 0) for y in years_sorted],\n",
    "})\n",
    "\n",
    "colors = {\n",
    "    'all_relations': [176/255, 205/255, 241/255],\n",
    "    'miRNA-Gene': [255/255, 127/255, 80/255],      # Coral\n",
    "    'miRNA-Disease': [100/255, 149/255, 237/255],  # CornflowerBlue\n",
    "    'miRNA-Phenotype': [60/255, 179/255, 113/255], # MediumSeaGreen\n",
    "    'Gene-Disease': [100/255, 149/255, 237/255],  # CornflowerBlue\n",
    "    'Gene-Phenotype': [60/255, 179/255, 113/255], # MediumSeaGreen\n",
    "}\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(7, 4.5))\n",
    "bar_width = 0.18\n",
    "x = range(len(plot_df))\n",
    "\n",
    "positions_all = [i - 1.5*bar_width for i in x]\n",
    "positions_gene = [i - 0.5*bar_width for i in x]\n",
    "positions_disease = [i + 0.5*bar_width for i in x]\n",
    "positions_phenotype = [i + 1.5*bar_width for i in x]\n",
    "positions_disease2 = [i + 2*bar_width for i in x]\n",
    "positions_phenotype2 = [i + 2.5*bar_width for i in x]\n",
    "\n",
    "ax.bar(positions_all, plot_df['all_relations'], width=bar_width, color=colors['all_relations'], label='Tutte le relazioni')\n",
    "ax.bar(positions_gene, plot_df['miRNA-Gene'], width=bar_width, color=colors['miRNA-Gene'], label='miRNA-Gene')\n",
    "ax.bar(positions_disease, plot_df['miRNA-Disease'], width=bar_width, color=colors['miRNA-Disease'], label='miRNA-Disease')\n",
    "ax.bar(positions_phenotype, plot_df['miRNA-Phenotype'], width=bar_width, color=colors['miRNA-Phenotype'], label='miRNA-Phenotype')\n",
    "ax.bar(positions_disease2, plot_df['Gene-Disease'], width=bar_width, color=colors['Gene-Disease'], label='Gene-Disease')\n",
    "ax.bar(positions_phenotype2, plot_df['Gene-Phenotype'], width=bar_width, color=colors['Gene-Phenotype'], label='Gene-Phenotype')\n",
    "\n",
    "def format_large_number(value):\n",
    "    if value >= 1_000_000:\n",
    "        return f\"{value / 1_000_000:.0f}M\"\n",
    "    elif value >= 1_000:\n",
    "        return f\"{value / 1_000:.0f}k\"\n",
    "    return str(value)\n",
    "\n",
    "for i in x:\n",
    "    vals = [plot_df.at[i, 'all_relations'], plot_df.at[i, 'miRNA-Gene'], plot_df.at[i, 'miRNA-Disease'], plot_df.at[i, 'miRNA-Phenotype'], plot_df.at[i, 'Gene-Phenotype'], plot_df.at[i, 'Gene-Disease']]\n",
    "    pos_list = [positions_all[i], positions_gene[i], positions_disease[i], positions_phenotype[i], positions_disease2[i], positions_phenotype2[i]]\n",
    "    for val, pos in zip(vals, pos_list):\n",
    "        if val > 0:\n",
    "            ax.text(pos, val * 1.02, format_large_number(val), ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(plot_df['year'], rotation=45, ha='right', fontsize=9)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim(1e2, 10**4.5)\n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "ax.set_ylabel('Numero di relazioni (log scale)', fontsize=9)\n",
    "ax.grid(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "ax.tick_params(axis='y', which='both', length=0)\n",
    "ax.legend(fontsize=9, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mirna_relation_types.png\", dpi=400, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges_df = edges_df[(edges_df['year']<2025) | (edges_df['year'].isna())]\n",
    "test_edges_df = edges_df[edges_df['year']>=2025]\n",
    "\n",
    "nodes_df = nodes_df[(nodes_df['name'].isin(train_edges_df['subject'])) | (nodes_df['name'].isin(train_edges_df['object']))]\n",
    "\n",
    "test_edges_df = test_edges_df[test_edges_df['subject'].isin(nodes_df['name'])]\n",
    "test_edges_df = test_edges_df[test_edges_df['object'].isin(nodes_df['name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges_df.to_csv(\"test_edges.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_directed = Graph.from_pd(\n",
    "    edges_df=train_edges_df,\n",
    "    nodes_df=nodes_df,\n",
    "    node_name_column=\"name\",\n",
    "    node_type_column=\"type\",\n",
    "    edge_src_column=\"subject\",\n",
    "    edge_dst_column=\"object\",\n",
    "    edge_type_column=\"predicate\",\n",
    "    directed=True,\n",
    "    name=\"RNA-KG VIEW_properties\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions to use GRAPE embeddings via SciKit-Learn to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to use the models directly from sci-kit learn instead of grape\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import grape\n",
    "\n",
    "\n",
    "def get_edge_type_ids_list(graph):\n",
    "    edge_types = []\n",
    "    for edge_id in range(graph.get_number_of_directed_edges()):\n",
    "        predicate = graph.get_edge_type_name_from_edge_id(edge_id)\n",
    "        predicate_id = graph.get_edge_type_id_from_edge_type_name(predicate)\n",
    "        edge_types.append(predicate_id)\n",
    "    return edge_types\n",
    "\n",
    "\n",
    "def extract_embeddings_for_graph(grape_embedding, grape_graph):\n",
    "    before = time.time()\n",
    "    node_embedding = grape_embedding.get_all_node_embedding()\n",
    "    try:\n",
    "        edge_type_embedding = grape_embedding.get_all_edge_type_embeddings()\n",
    "    except ValueError as e:\n",
    "        logging.warning(\n",
    "            f\"Error while extracting edge type embeddings: {e}, using empty list instead\"\n",
    "        )\n",
    "        edge_type_embedding = []\n",
    "    number_of_edges = grape_graph.get_number_of_directed_edges()\n",
    "    edge_node_names = grape_graph.get_edge_node_names(directed=True)\n",
    "    embeddings = []\n",
    "    for edge_id in range(number_of_edges):\n",
    "        subject = edge_node_names[edge_id][0]\n",
    "        object = edge_node_names[edge_id][1]\n",
    "        predicate = grape_graph.get_edge_type_name_from_edge_id(edge_id)\n",
    "        subject_embedding = node_embedding[0].loc[subject].values\n",
    "        predicate_embedding = (\n",
    "            edge_type_embedding[0].loc[predicate].values\n",
    "            if len(edge_type_embedding) > 0\n",
    "            else np.empty(0)\n",
    "        )\n",
    "        object_embedding = node_embedding[0].loc[object].values\n",
    "        edge_embedding = np.concatenate(\n",
    "            [subject_embedding, predicate_embedding, object_embedding]\n",
    "        )\n",
    "        embeddings.append(edge_embedding)\n",
    "    logging.info(f\"Embedding extraction time:{time.time()-before}\")\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def edge_pred_pairs_sklearn(\n",
    "    graph,\n",
    "    embedder,\n",
    "    edge_pred_model,\n",
    "    pairs_to_predict,\n",
    "    name_for_df=None,\n",
    "    clear_output=False,\n",
    "    train_size=0.7,\n",
    "    number_of_holdouts=5,\n",
    "    seed=42,\n",
    "    use_scale_free_distribution=True,\n",
    "    train_on_filtered=True,\n",
    "    training_unbalance_rate=1.0,\n",
    "    verbose=False,\n",
    "    binary=True,\n",
    "):\n",
    "    df_results = pd.DataFrame()\n",
    "    columns = [\n",
    "        \"Graph\",\n",
    "        \"Embedder\",\n",
    "        \"Model\",\n",
    "        \"Source Type\",\n",
    "        \"Destination Type\",\n",
    "        \"Train on filtered\",\n",
    "        \"Training set size\",\n",
    "        \"Testing set size\",\n",
    "        \"Training balanced accuracy\",\n",
    "        \"Positive balanced accuracy\",\n",
    "        \"Negative balanced accuracy\",\n",
    "        \"Mean balanced accuracy\",  # ,'AUC'\n",
    "    ]\n",
    "\n",
    "    for i, pair_to_predict in enumerate(pairs_to_predict):\n",
    "        print(f\"Predicting pair: {pair_to_predict} ({i+1}/{len(pairs_to_predict)})\")\n",
    "\n",
    "        # change how the training behaves\n",
    "        # update_fit(edge_pred_model, pair_to_predict if train_on_filtered else None, graph) # Not needed anymore with the sklearn models\n",
    "        # negative graph extracted from the full graph to avoid false negatives\n",
    "        # model will only be trained on data of the relevant type pair to predict\n",
    "        results_custom_filtered_train = edge_prediction_pipeline_sklearn(\n",
    "            graph,\n",
    "            edge_pred_model,\n",
    "            embedder,\n",
    "            pair_to_predict,\n",
    "            train_on_filtered=train_on_filtered,\n",
    "            train_size=train_size,\n",
    "            number_of_holdouts=number_of_holdouts,\n",
    "            seed=seed,\n",
    "            verbose=verbose,\n",
    "            clear_output_holdout=clear_output,\n",
    "            use_scale_free_distribution=use_scale_free_distribution,\n",
    "            training_unbalance_rate=training_unbalance_rate,\n",
    "            binary=binary,\n",
    "        )\n",
    "        df_results_custom_filtered_train = pd.DataFrame(results_custom_filtered_train)\n",
    "        df_results = pd.concat([df_results, df_results_custom_filtered_train])\n",
    "\n",
    "    df_results.columns = columns\n",
    "    edge_pred_model_name = (\n",
    "        edge_pred_model.__class__.__module__ + \".\" + edge_pred_model.__class__.__name__\n",
    "    )\n",
    "    df_results[\"edge_pred_model\"] = edge_pred_model_name\n",
    "    df_results[\"embedding_model\"] = \"\"#embedder.model_name()\n",
    "    df_results[\"name\"] = (\n",
    "        f\"-{edge_pred_model_name}\"#{embedder.model_name()}\n",
    "        if name_for_df is None\n",
    "        else name_for_df\n",
    "    )\n",
    "    # results[f'{embedder.model_name()}-{model.model_name()}'] = df_results\n",
    "    return df_results\n",
    "\n",
    "\n",
    "def edge_prediction_pipeline_sklearn(\n",
    "    graph,\n",
    "    model,\n",
    "    embedder,\n",
    "    pair_to_predict,\n",
    "    train_on_filtered=True,\n",
    "    train_size=0.7,\n",
    "    number_of_holdouts=5,\n",
    "    seed=42,\n",
    "    verbose=False,\n",
    "    clear_output_holdout=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    training_unbalance_rate=1.0,\n",
    "    binary=True,\n",
    "):\n",
    "    random.seed(seed)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(number_of_holdouts):\n",
    "        # clean the cell output at each iteration to avoid huge cell outputs\n",
    "        if clear_output_holdout:\n",
    "            clear_output(wait=True)\n",
    "        # use connected monte carlo to obtain a training set that has the same connectivity guarantees as full graph\n",
    "        logging.info(f\"Generating holdout {i+1}/{number_of_holdouts}\")\n",
    "        random_state = random.randrange(0, 100000)\n",
    "        train_graph, positive_test_graph = graph.connected_holdout(\n",
    "            train_size=train_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "        # check if number of connected components is the same in the training set and full graph\n",
    "        logging.debug(train_graph.get_number_of_connected_components())\n",
    "        assert (\n",
    "            train_graph.get_number_of_connected_components()\n",
    "            == graph.get_number_of_connected_components()\n",
    "        )\n",
    "\n",
    "        logging.info(\"Filtering train and test graph by source/destination node type\")\n",
    "        # keep only the edges (source-destination node type) we are interested in\n",
    "        train_graph_filtered = train_graph.filter_from_names(\n",
    "            source_node_type_name_to_keep=[pair_to_predict[0]],\n",
    "            destination_node_type_name_to_keep=[pair_to_predict[1]],\n",
    "        )\n",
    "        test_graph_filtered = positive_test_graph.filter_from_names(\n",
    "            source_node_type_name_to_keep=[pair_to_predict[0]],\n",
    "            destination_node_type_name_to_keep=[pair_to_predict[1]],\n",
    "        )\n",
    "\n",
    "        # check if embedder is of class grape.EmbeddingResult\n",
    "        if not isinstance(embedder, grape.EmbeddingResult):\n",
    "            # calculate the embedding on the not filtered train graph\n",
    "            logging.info(\"Training embedding on unfiltered train graph\")\n",
    "            before = time.time()\n",
    "\n",
    "            train_embedding = embedder.fit_transform(train_graph)\n",
    "\n",
    "            logging.info(f\"Embedding time:{time.time()-before}\")\n",
    "        else:\n",
    "            logging.info(\"Using precalculated embeddings\")\n",
    "            train_embedding = embedder\n",
    "\n",
    "        logging.info(\"Training model using the filtered train graph\")\n",
    "\n",
    "        logging.info(\"Generating negative training graph\")\n",
    "        before = time.time()\n",
    "        number_of_negative_samples = (\n",
    "            int(\n",
    "                math.ceil(\n",
    "                    train_graph_filtered.get_number_of_directed_edges()\n",
    "                    * training_unbalance_rate\n",
    "                )\n",
    "            )\n",
    "            if train_on_filtered\n",
    "            else int(\n",
    "                math.ceil(\n",
    "                    train_graph.get_number_of_directed_edges() * training_unbalance_rate\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Number of negative samples: {number_of_negative_samples}\")\n",
    "        train_negative_graph = graph.sample_negative_graph(  # using the full graph to generate the negative edges to avoid false negatives\n",
    "            number_of_negative_samples=number_of_negative_samples,\n",
    "            # only_from_same_component=True,\n",
    "            random_state=random_state,\n",
    "            use_scale_free_distribution=use_scale_free_distribution,\n",
    "            # sample_edge_types=False, # TODO: check if this is correct and test what happens if it is True\n",
    "            source_node_types_names=[pair_to_predict[0]] if pair_to_predict else None,\n",
    "            destination_node_types_names=(\n",
    "                [pair_to_predict[1]] if pair_to_predict else None\n",
    "            ),\n",
    "        )\n",
    "        logging.info(train_negative_graph.get_unique_edge_type_ids())\n",
    "        logging.info(\n",
    "            f\"Number of edge types in negative training graph: {len(train_negative_graph.get_unique_edge_type_ids())}\"\n",
    "        )\n",
    "        logging.info(f\"Negative training graph generation time:{time.time()-before}\")\n",
    "        logging.info(\"Extracting embeddings for the negative training graph\")\n",
    "        before = time.time()\n",
    "        train_negative_graph_embeddings = extract_embeddings_for_graph(\n",
    "            train_embedding, train_negative_graph\n",
    "        )\n",
    "        logging.info(\n",
    "            f\"Negative training graph embedding extraction time:{time.time()-before}\"\n",
    "        )\n",
    "\n",
    "        if train_on_filtered:\n",
    "            logging.info(train_graph_filtered.get_unique_edge_type_ids())\n",
    "            logging.info(\n",
    "                f\"Number of edge types in positive training graph: {len(train_graph_filtered.get_unique_edge_type_ids())}\"\n",
    "            )\n",
    "            # generate the list of embeddings for the train_graph_filtered\n",
    "            logging.info(\"Extracting embeddings for the positive training graph\")\n",
    "            train_positive_graph_filtered_embeddings = extract_embeddings_for_graph(\n",
    "                train_embedding, train_graph_filtered\n",
    "            )\n",
    "            # combine the positive and negative embeddings\n",
    "            train_graph_embeddings = np.concatenate(\n",
    "                [\n",
    "                    train_positive_graph_filtered_embeddings,\n",
    "                    train_negative_graph_embeddings,\n",
    "                ]\n",
    "            )\n",
    "            # generate the list of labels for the train_graph_filtered\n",
    "            if binary:\n",
    "                train_graph_filtered_labels = [\n",
    "                    1 for _ in range(len(train_positive_graph_filtered_embeddings))\n",
    "                ] + [0 for _ in range(len(train_negative_graph_embeddings))]\n",
    "            else:\n",
    "                positive_train_edge_types = get_edge_type_ids_list(train_graph_filtered)\n",
    "                negative_train_edge_types = [\n",
    "                    -1 for _ in range(len(train_negative_graph_embeddings))\n",
    "                ]  # get_edge_type_ids_list(train_negative_graph)\n",
    "                train_graph_filtered_labels = (\n",
    "                    positive_train_edge_types + negative_train_edge_types\n",
    "                )\n",
    "\n",
    "            # train the model\n",
    "            logging.info(\"Training model on the filtered training graph\")\n",
    "            model = model.fit(train_graph_embeddings, train_graph_filtered_labels)\n",
    "        else:\n",
    "            logging.info(train_graph.get_unique_edge_type_ids())\n",
    "            logging.info(\n",
    "                f\"Number of edge types in positive training graph: {len(train_graph.get_unique_edge_type_ids())}\"\n",
    "            )\n",
    "            # generate the list of embeddings for the train_graph\n",
    "            logging.info(\"Extracting embeddings for the positive training graph\")\n",
    "            train_positive_graph_embeddings = extract_embeddings_for_graph(\n",
    "                train_embedding, train_graph\n",
    "            )\n",
    "            # combine the positive and negative embeddings\n",
    "            train_graph_embeddings = np.concatenate(\n",
    "                [train_positive_graph_embeddings, train_negative_graph_embeddings]\n",
    "            )\n",
    "            # generate the list of labels for the train_graph\n",
    "            if binary:\n",
    "                train_graph_labels = [\n",
    "                    1 for _ in range(len(train_positive_graph_embeddings))\n",
    "                ] + [0 for _ in range(len(train_negative_graph_embeddings))]\n",
    "            else:\n",
    "                positive_train_edge_types = get_edge_type_ids_list(train_graph)\n",
    "                negative_train_edge_types = [\n",
    "                    -1 for _ in range(len(train_negative_graph_embeddings))\n",
    "                ]  # get_edge_type_ids_list(train_negative_graph)\n",
    "                train_graph_labels = (\n",
    "                    positive_train_edge_types + negative_train_edge_types\n",
    "                )\n",
    "            # train the model\n",
    "            logging.info(\"Training model on the training graph\")\n",
    "            model = model.fit(train_graph_embeddings, train_graph_labels)\n",
    "\n",
    "        logging.info(\"Evaluating model on train set\")\n",
    "        train_pred = model.predict(train_graph_embeddings)\n",
    "        if train_on_filtered:\n",
    "            logging.info(\"Evaluating model on filtered positive train set\")\n",
    "            pos_train_pred = model.predict(train_positive_graph_filtered_embeddings)\n",
    "        else:\n",
    "            logging.info(\"Evaluating model on positive train set\")\n",
    "            pos_train_pred = model.predict(train_positive_graph_embeddings)\n",
    "        logging.info(\"Evaluating model on negative train set\")\n",
    "        neg_train_pred = model.predict(train_negative_graph_embeddings)\n",
    "\n",
    "        training_set_size = len(train_pred)\n",
    "\n",
    "        if binary:\n",
    "            train_score = (\n",
    "                balanced_accuracy_score(train_graph_filtered_labels, train_pred)\n",
    "                if train_on_filtered\n",
    "                else balanced_accuracy_score(train_graph_labels, train_pred)\n",
    "            )\n",
    "            pos_train_score = balanced_accuracy_score(\n",
    "                [1 for _ in range(len(pos_train_pred))], pos_train_pred\n",
    "            )\n",
    "            neg_train_score = balanced_accuracy_score(\n",
    "                [0 for _ in range(len(neg_train_pred))], neg_train_pred\n",
    "            )\n",
    "        else:\n",
    "            train_score = (\n",
    "                balanced_accuracy_score(train_graph_filtered_labels, train_pred)\n",
    "                if train_on_filtered\n",
    "                else balanced_accuracy_score(train_graph_labels, train_pred)\n",
    "            )\n",
    "            pos_train_score = balanced_accuracy_score(\n",
    "                positive_train_edge_types, pos_train_pred\n",
    "            )\n",
    "            neg_train_score = balanced_accuracy_score(\n",
    "                negative_train_edge_types, neg_train_pred\n",
    "            )\n",
    "\n",
    "        if verbose:\n",
    "            # pred_train_edge_presence = train_pred.apply(lambda row:check_if_in_graph(graph,row['sources'],row['destinations'],pair_to_predict),axis=1)\n",
    "            # train_score = balanced_accuracy_score(pred_train_edge_presence, train_pred['prediction'].apply(lambda x:x>0.5))\n",
    "            logging.info(f\"Balanced accuracy score TRAINING: {train_score}\")\n",
    "            logging.info(\n",
    "                f\"Balanced accuracy positive score TRAINING: {pos_train_score}\"\n",
    "            )\n",
    "            logging.info(\n",
    "                f\"Balanced accuracy negative score TRAINING: {neg_train_score}\"\n",
    "            )\n",
    "\n",
    "        logging.info(\"Creating a graph with the negative edges for testing\")\n",
    "        # create graph with negative edges for testing\n",
    "        negative_test_graph = graph.sample_negative_graph(\n",
    "            # number_of_negative_samples=test_graph_filtered.get_number_of_edges(), # this option creates only half the edges\n",
    "            number_of_negative_samples=test_graph_filtered.get_number_of_directed_edges(),\n",
    "            # only_from_same_component=True,\n",
    "            source_node_types_names=[pair_to_predict[0]],\n",
    "            destination_node_types_names=[pair_to_predict[1]],\n",
    "            random_state=random_state\n",
    "            + 1,  # to avoid the same random state as the negative training graph\n",
    "            use_scale_free_distribution=use_scale_free_distribution,\n",
    "        )\n",
    "        logging.info(negative_test_graph.get_unique_edge_type_ids())\n",
    "        logging.info(\n",
    "            f\"Number of edge types in negative test graph: {len(negative_test_graph.get_unique_edge_type_ids())}\"\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            logging.info(\n",
    "                f\"#edges in positive test graph: {test_graph_filtered.get_number_of_directed_edges()}\"\n",
    "            )\n",
    "            logging.info(\n",
    "                f\"#edges in negative test graph: {negative_test_graph.get_number_of_directed_edges()}\"\n",
    "            )\n",
    "\n",
    "        # use model to predict on the positive edges\n",
    "        logging.info(\"Using the model to predict the existence of positive edges\")\n",
    "        # pos_pred = model.predict_proba(\n",
    "        #   graph=test_graph_filtered,\n",
    "        #   edge_features=transe_edge_features,\n",
    "        #   return_predictions_dataframe=True,\n",
    "        #   support=train_graph\n",
    "        # )\n",
    "        pos_pred = model.predict(\n",
    "            extract_embeddings_for_graph(train_embedding, test_graph_filtered)\n",
    "        )\n",
    "\n",
    "        # if verbose:\n",
    "        #     # check if all edges of positive test set are in the original graph\n",
    "        #     pos_pred_edge_presence = pos_pred.apply(lambda row:check_if_in_graph(graph,row['sources'],row['destinations'],pair_to_predict),axis=1)\n",
    "        #     logging.info(f'Are all positive edges present in the positive test set also in the original graph? {pos_pred_edge_presence.all()}')\n",
    "        #     logging.info(pos_pred_edge_presence.value_counts())\n",
    "\n",
    "        # use model to predict on the negative edges\n",
    "        logging.info(\"Using the model to predict the non-existence of negative edges\")\n",
    "        # neg_pred = model.predict_proba(\n",
    "        #   graph=negative_test_graph,\n",
    "        #   edge_features=transe_edge_features,\n",
    "        #   return_predictions_dataframe=True,\n",
    "        #   support=train_graph\n",
    "        # )\n",
    "        neg_pred = model.predict(\n",
    "            extract_embeddings_for_graph(train_embedding, negative_test_graph)\n",
    "        )\n",
    "\n",
    "        testing_set_size = len(pos_pred) + len(neg_pred)\n",
    "\n",
    "        # if verbose:\n",
    "        #     # check if all edges of negative test set are not in the original graph\n",
    "        #     neg_pred_edge_presence = neg_pred.apply(lambda row:check_if_in_graph(graph,row['sources'],row['destinations'],pair_to_predict),axis=1)\n",
    "        #     logging.info(f'Are all negative edges present in the negative test set NOT in the original graph? {~neg_pred_edge_presence.all()}')\n",
    "        #     logging.info(neg_pred_edge_presence.value_counts())\n",
    "\n",
    "        # calculate balanced accuracy score for positive and negative predictions\n",
    "        if binary:\n",
    "            pos_score = balanced_accuracy_score(\n",
    "                [1 for _ in range(len(pos_pred))], pos_pred\n",
    "            )\n",
    "            neg_score = balanced_accuracy_score(\n",
    "                [0 for _ in range(len(neg_pred))], neg_pred\n",
    "            )\n",
    "        else:\n",
    "            positive_test_edge_types = get_edge_type_ids_list(test_graph_filtered)\n",
    "            negative_test_edge_types = [\n",
    "                -1 for _ in range(len(neg_pred))\n",
    "            ]  # get_edge_type_ids_list(negative_test_graph)\n",
    "            pos_score = balanced_accuracy_score(positive_test_edge_types, pos_pred)\n",
    "            neg_score = balanced_accuracy_score(negative_test_edge_types, neg_pred)\n",
    "            overall_score = balanced_accuracy_score(\n",
    "                positive_test_edge_types + negative_test_edge_types,\n",
    "                np.concatenate([pos_pred, neg_pred]),\n",
    "            )\n",
    "            logging.info(f\"Overall balanced accuracy score: {overall_score}\")\n",
    "        # pos_score = balanced_accuracy_score([True for _ in range(len(pos_pred))], pos_pred)\n",
    "        # neg_score = balanced_accuracy_score([False for _ in range(len(neg_pred))], neg_pred)\n",
    "        logging.info(f\"Balanced accuracy positive score: {pos_score}\")\n",
    "        logging.info(f\"Balanced accuracy negative score: {neg_score}\")\n",
    "        avg_score = (pos_score + neg_score) / 2\n",
    "        logging.info(f\"Balanced accuracy mean score: {avg_score}\")\n",
    "\n",
    "        # if binary:\n",
    "        #     auc_score = roc_auc_score(\n",
    "        #         [True for _ in range(len(pos_pred))] + [False for _ in range(len(neg_pred))],\n",
    "        #         np.concatenate([pos_pred, neg_pred])\n",
    "        #     )\n",
    "        # else:\n",
    "        #     auc_score = roc_auc_score(\n",
    "        #         positive_test_edge_types + negative_test_edge_types,\n",
    "        #         np.concatenate([pos_pred, neg_pred])\n",
    "        #     )\n",
    "        # logging.info(f\"AUC score: {auc_score}\")\n",
    "\n",
    "        if hasattr(model, \"get_depth\"):\n",
    "            logging.info(f\"Tree depth: {model.get_depth()}\")\n",
    "\n",
    "        model_name = model.__class__.__module__ + \".\" + model.__class__.__name__\n",
    "\n",
    "        results.append(\n",
    "            (\n",
    "                graph.get_name(),\n",
    "                \"\",#embedder.model_name(),\n",
    "                model_name,\n",
    "                pair_to_predict[0],\n",
    "                pair_to_predict[1],\n",
    "                train_on_filtered,\n",
    "                training_set_size,\n",
    "                testing_set_size,\n",
    "                train_score,\n",
    "                pos_score,\n",
    "                neg_score,\n",
    "                avg_score,\n",
    "            )  # ,auc_score\n",
    "        )\n",
    "\n",
    "    import joblib\n",
    "    model_path = f\"{graph.get_name()}_{model_name}.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    logging.info(f\"{graph.get_name()}_{model_name}.pkl saved\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Edge Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.embedders import TransEEnsmallen\n",
    "\n",
    "embedder_transE = TransEEnsmallen(random_state=42)\n",
    "graph_embedding_transe = embedder_transE.fit_transform(view_directed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ora_corrente = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"La data e l'ora correnti sono:\", data_ora_corrente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges_df = pd.read_csv(\"test_edges.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# miRNA-Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed = 42\n",
    "\n",
    "model_forest = RandomForestClassifier(random_state=seed, n_jobs=6)\n",
    "pairs_to_predict = [\n",
    "    (\"miRNA\", \"Gene\"),\n",
    "    #(\"miRNA\", \"Disease\"),\n",
    "    #(\"miRNA\", \"Phenotype\"),\n",
    "    #(\"Gene\", \"Disease\"),\n",
    "    #(\"Gene\", \"Phenotype\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG) \n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "results_fun_transE_forest = edge_pred_pairs_sklearn(\n",
    "    view_directed,\n",
    "    graph_embedding_transe,\n",
    "    model_forest,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=1,\n",
    "    binary=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fun_transE_forest.groupby([\"Source Type\", \"Destination Type\"])[\n",
    "    [\n",
    "        \"Positive balanced accuracy\",\n",
    "        \"Negative balanced accuracy\",\n",
    "        \"Mean balanced accuracy\",\n",
    "    ]\n",
    "].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_on_graph(graph, embedder, model_path, include_edge_types=True):\n",
    "    \"\"\"\n",
    "    Predicts link scores for all edges in the provided graph using the given embedder and a trained sklearn model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : grape.Graph\n",
    "        The graph to use for extracting edges and embeddings.\n",
    "    embedder : grape.EmbeddingResult or compatible embedder\n",
    "        The node and optionally edge embedder used for embedding nodes and edges.\n",
    "    model_path : str\n",
    "        Path to the pre-trained sklearn model.\n",
    "    include_edge_types : bool, optional\n",
    "        Whether to include edge type embeddings in the concatenated input, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions : np.ndarray\n",
    "        An array of predicted scores (e.g., probabilities or binary labels depending on model).\n",
    "    edge_ids : list\n",
    "        List of edge (subject, predicate, object) identifiers corresponding to each prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # Estrarre embeddings\n",
    "    node_embeddings = embedder.get_all_node_embedding()[0]\n",
    "    try:\n",
    "        edge_type_embeddings = embedder.get_all_edge_type_embeddings()[0] if include_edge_types else {}\n",
    "    except:\n",
    "        edge_type_embeddings = {}\n",
    "\n",
    "    edge_node_names = graph.get_edge_node_names(directed=True)\n",
    "    predictions = []\n",
    "    edge_ids = []\n",
    "\n",
    "    for edge_id in tqdm(range(graph.get_number_of_directed_edges()), desc=\"Predicting edges\"):\n",
    "        subj, obj = edge_node_names[edge_id]\n",
    "        predicate = graph.get_edge_type_name_from_edge_id(edge_id)\n",
    "\n",
    "        subj_emb = node_embeddings.loc[subj].values\n",
    "        obj_emb = node_embeddings.loc[obj].values\n",
    "\n",
    "        if include_edge_types and predicate in edge_type_embeddings.index:\n",
    "            pred_emb = edge_type_embeddings.loc[predicate].values\n",
    "            edge_input = np.concatenate([subj_emb, pred_emb, obj_emb])\n",
    "        else:\n",
    "            edge_input = np.concatenate([subj_emb, obj_emb])\n",
    "\n",
    "        score = model.predict_proba([edge_input])[0][1] if hasattr(model, \"predict_proba\") else model.predict([edge_input])[0]\n",
    "        predictions.append(score)\n",
    "        edge_ids.append((subj, predicate, obj))\n",
    "\n",
    "    return np.array(predictions), edge_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges_df_ = test_edges_df.merge(\n",
    "    nodes_df[['name', 'type']], left_on='subject', right_on='name'\n",
    ").drop(columns=['name']).merge(\n",
    "    nodes_df[['name', 'type']], left_on='object', right_on='name'\n",
    ").drop(columns=['name'])\n",
    "\n",
    "mask = False\n",
    "for type1, type2 in pairs_to_predict:\n",
    "    mask |= ((test_edges_df_['type_x'] == type1) & (test_edges_df_['type_y'] == type2)) | \\\n",
    "            ((test_edges_df_['type_x'] == type2) & (test_edges_df_['type_y'] == type1))\n",
    "\n",
    "test_edges_df_filtered = test_edges_df_[mask][['subject', 'predicate', 'object']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_view = Graph.from_pd(\n",
    "    edges_df=test_edges_df_filtered,\n",
    "    nodes_df=nodes_df,\n",
    "    node_name_column=\"name\",\n",
    "    node_type_column=\"type\",\n",
    "    edge_src_column=\"subject\",\n",
    "    edge_dst_column=\"object\",\n",
    "    edge_type_column=\"predicate\",\n",
    "    directed=True,\n",
    "    name=\"RNA-KG VIEW_properties test set\",\n",
    ")\n",
    "\n",
    "predictions, edge_triples = predict_on_graph(\n",
    "    graph=test_view,\n",
    "    embedder=graph_embedding_transe,\n",
    "    model_path=\"RNA-KG VIEW_properties_sklearn.ensemble._forest.RandomForestClassifier.pkl\",\n",
    "    include_edge_types=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(edge_triples, columns=[\"subject\", \"predicate\", \"object\"])\n",
    "df[\"prediction\"] = predictions\n",
    "df.to_csv(\"predictions_mirnagene.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mirnagene = pd.read_csv(\"predictions_mirnagene.csv\")\n",
    "mirnagene = mirnagene.merge(test_edges_df, on=['subject', 'predicate', 'object'], how='left')\n",
    "mirnagene.to_csv(\"predictions_mirnagene.csv\", index=False)\n",
    "mirnagene "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mirnagene['prediction'].to_numpy()\n",
    "threshold = 0.5\n",
    "(predictions>=threshold).sum(), len(predictions), \\\n",
    "len(predictions[predictions>=threshold])/len(predictions), len(predictions[predictions<threshold])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=mirnagene, x='year', y='prediction')\n",
    "plt.title('Distribuzione delle Predizioni per Anno')\n",
    "plt.xlabel('Anno')\n",
    "plt.ylabel('Valori Predetti')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirnagene = mirnagene[mirnagene['prediction'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mirnagene['prediction'].to_numpy()\n",
    "threshold = 0.5\n",
    "(predictions>=threshold).sum(), len(predictions), \\\n",
    "len(predictions[predictions>=threshold])/len(predictions), len(predictions[predictions<threshold])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=mirnagene, x='year', y='prediction')\n",
    "plt.title('Distribuzione delle Predizioni per Anno')\n",
    "plt.xlabel('Anno')\n",
    "plt.ylabel('Valori Predetti')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# miRNA-Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed = 42\n",
    "\n",
    "model_forest = RandomForestClassifier(random_state=seed, n_jobs=6)\n",
    "pairs_to_predict = [\n",
    "    #(\"miRNA\", \"Gene\"),\n",
    "    (\"miRNA\", \"Disease\"),\n",
    "    #(\"miRNA\", \"Phenotype\"),\n",
    "    #(\"Gene\", \"Disease\"),\n",
    "    #(\"Gene\", \"Phenotype\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG) \n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "results_fun_transE_forest = edge_pred_pairs_sklearn(\n",
    "    view_directed,\n",
    "    graph_embedding_transe,\n",
    "    model_forest,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=1,\n",
    "    binary=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fun_transE_forest.groupby([\"Source Type\", \"Destination Type\"])[\n",
    "    [\n",
    "        \"Positive balanced accuracy\",\n",
    "        \"Negative balanced accuracy\",\n",
    "        \"Mean balanced accuracy\",\n",
    "    ]\n",
    "].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_on_graph(graph, embedder, model_path, include_edge_types=True):\n",
    "    \"\"\"\n",
    "    Predicts link scores for all edges in the provided graph using the given embedder and a trained sklearn model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : grape.Graph\n",
    "        The graph to use for extracting edges and embeddings.\n",
    "    embedder : grape.EmbeddingResult or compatible embedder\n",
    "        The node and optionally edge embedder used for embedding nodes and edges.\n",
    "    model_path : str\n",
    "        Path to the pre-trained sklearn model.\n",
    "    include_edge_types : bool, optional\n",
    "        Whether to include edge type embeddings in the concatenated input, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions : np.ndarray\n",
    "        An array of predicted scores (e.g., probabilities or binary labels depending on model).\n",
    "    edge_ids : list\n",
    "        List of edge (subject, predicate, object) identifiers corresponding to each prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # Estrarre embeddings\n",
    "    node_embeddings = embedder.get_all_node_embedding()[0]\n",
    "    try:\n",
    "        edge_type_embeddings = embedder.get_all_edge_type_embeddings()[0] if include_edge_types else {}\n",
    "    except:\n",
    "        edge_type_embeddings = {}\n",
    "\n",
    "    edge_node_names = graph.get_edge_node_names(directed=True)\n",
    "    predictions = []\n",
    "    edge_ids = []\n",
    "\n",
    "    for edge_id in tqdm(range(graph.get_number_of_directed_edges()), desc=\"Predicting edges\"):\n",
    "        subj, obj = edge_node_names[edge_id]\n",
    "        predicate = graph.get_edge_type_name_from_edge_id(edge_id)\n",
    "\n",
    "        subj_emb = node_embeddings.loc[subj].values\n",
    "        obj_emb = node_embeddings.loc[obj].values\n",
    "\n",
    "        if include_edge_types and predicate in edge_type_embeddings.index:\n",
    "            pred_emb = edge_type_embeddings.loc[predicate].values\n",
    "            edge_input = np.concatenate([subj_emb, pred_emb, obj_emb])\n",
    "        else:\n",
    "            edge_input = np.concatenate([subj_emb, obj_emb])\n",
    "\n",
    "        score = model.predict_proba([edge_input])[0][1] if hasattr(model, \"predict_proba\") else model.predict([edge_input])[0]\n",
    "        predictions.append(score)\n",
    "        edge_ids.append((subj, predicate, obj))\n",
    "\n",
    "    return np.array(predictions), edge_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges_df_ = test_edges_df.merge(\n",
    "    nodes_df[['name', 'type']], left_on='subject', right_on='name'\n",
    ").drop(columns=['name']).merge(\n",
    "    nodes_df[['name', 'type']], left_on='object', right_on='name'\n",
    ").drop(columns=['name'])\n",
    "\n",
    "mask = False\n",
    "for type1, type2 in pairs_to_predict:\n",
    "    mask |= ((test_edges_df_['type_x'] == type1) & (test_edges_df_['type_y'] == type2)) | \\\n",
    "            ((test_edges_df_['type_x'] == type2) & (test_edges_df_['type_y'] == type1))\n",
    "\n",
    "test_edges_df_filtered = test_edges_df_[mask][['subject', 'predicate', 'object']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_view = Graph.from_pd(\n",
    "    edges_df=test_edges_df_filtered,\n",
    "    nodes_df=nodes_df,\n",
    "    node_name_column=\"name\",\n",
    "    node_type_column=\"type\",\n",
    "    edge_src_column=\"subject\",\n",
    "    edge_dst_column=\"object\",\n",
    "    edge_type_column=\"predicate\",\n",
    "    directed=True,\n",
    "    name=\"RNA-KG VIEW_properties test set\",\n",
    ")\n",
    "\n",
    "predictions, edge_triples = predict_on_graph(\n",
    "    graph=test_view,\n",
    "    embedder=graph_embedding_transe,\n",
    "    model_path=\"RNA-KG VIEW_properties_sklearn.ensemble._forest.RandomForestClassifier.pkl\",\n",
    "    include_edge_types=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(edge_triples, columns=[\"subject\", \"predicate\", \"object\"])\n",
    "df[\"prediction\"] = predictions\n",
    "df.to_csv(\"predictions_mirnadisease.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mirnadisease = pd.read_csv(\"predictions_mirnadisease.csv\")\n",
    "mirnadisease = mirnadisease.merge(test_edges_df, on=['subject', 'predicate', 'object'], how='left')\n",
    "mirnadisease.to_csv(\"predictions_mirnadisease.csv\", index=False)\n",
    "mirnadisease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mirnadisease['prediction'].to_numpy()\n",
    "threshold = 0.5\n",
    "(predictions>=threshold).sum(), len(predictions), \\\n",
    "len(predictions[predictions>=threshold])/len(predictions), len(predictions[predictions<threshold])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=mirnadisease, x='year', y='prediction')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirnadisease = mirnadisease[mirnadisease['prediction'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mirnadisease['prediction'].to_numpy()\n",
    "threshold = 0.5\n",
    "(predictions>=threshold).sum(), len(predictions), \\\n",
    "len(predictions[predictions>=threshold])/len(predictions), len(predictions[predictions<threshold])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=mirnadisease, x='year', y='prediction')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# miRNA-Phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed = 42\n",
    "\n",
    "model_forest = RandomForestClassifier(random_state=seed, n_jobs=6)\n",
    "pairs_to_predict = [\n",
    "    #(\"miRNA\", \"Gene\"),\n",
    "    #(\"miRNA\", \"Disease\"),\n",
    "    (\"miRNA\", \"Phenotype\"),\n",
    "    #(\"Gene\", \"Disease\"),\n",
    "    #(\"Gene\", \"Phenotype\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG) \n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "results_fun_transE_forest = edge_pred_pairs_sklearn(\n",
    "    view_directed,\n",
    "    graph_embedding_transe,\n",
    "    model_forest,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=1,\n",
    "    binary=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fun_transE_forest.groupby([\"Source Type\", \"Destination Type\"])[\n",
    "    [\n",
    "        \"Positive balanced accuracy\",\n",
    "        \"Negative balanced accuracy\",\n",
    "        \"Mean balanced accuracy\",\n",
    "    ]\n",
    "].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_on_graph(graph, embedder, model_path, include_edge_types=True):\n",
    "    \"\"\"\n",
    "    Predicts link scores for all edges in the provided graph using the given embedder and a trained sklearn model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : grape.Graph\n",
    "        The graph to use for extracting edges and embeddings.\n",
    "    embedder : grape.EmbeddingResult or compatible embedder\n",
    "        The node and optionally edge embedder used for embedding nodes and edges.\n",
    "    model_path : str\n",
    "        Path to the pre-trained sklearn model.\n",
    "    include_edge_types : bool, optional\n",
    "        Whether to include edge type embeddings in the concatenated input, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions : np.ndarray\n",
    "        An array of predicted scores (e.g., probabilities or binary labels depending on model).\n",
    "    edge_ids : list\n",
    "        List of edge (subject, predicate, object) identifiers corresponding to each prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    node_embeddings = embedder.get_all_node_embedding()[0]\n",
    "    try:\n",
    "        edge_type_embeddings = embedder.get_all_edge_type_embeddings()[0] if include_edge_types else {}\n",
    "    except:\n",
    "        edge_type_embeddings = {}\n",
    "\n",
    "    edge_node_names = graph.get_edge_node_names(directed=True)\n",
    "    predictions = []\n",
    "    edge_ids = []\n",
    "\n",
    "    for edge_id in tqdm(range(graph.get_number_of_directed_edges()), desc=\"Predicting edges\"):\n",
    "        subj, obj = edge_node_names[edge_id]\n",
    "        predicate = graph.get_edge_type_name_from_edge_id(edge_id)\n",
    "\n",
    "        subj_emb = node_embeddings.loc[subj].values\n",
    "        obj_emb = node_embeddings.loc[obj].values\n",
    "\n",
    "        if include_edge_types and predicate in edge_type_embeddings.index:\n",
    "            pred_emb = edge_type_embeddings.loc[predicate].values\n",
    "            edge_input = np.concatenate([subj_emb, pred_emb, obj_emb])\n",
    "        else:\n",
    "            edge_input = np.concatenate([subj_emb, obj_emb])\n",
    "\n",
    "        score = model.predict_proba([edge_input])[0][1] if hasattr(model, \"predict_proba\") else model.predict([edge_input])[0]\n",
    "        predictions.append(score)\n",
    "        edge_ids.append((subj, predicate, obj))\n",
    "\n",
    "    return np.array(predictions), edge_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges_df_ = test_edges_df.merge(\n",
    "    nodes_df[['name', 'type']], left_on='subject', right_on='name'\n",
    ").drop(columns=['name']).merge(\n",
    "    nodes_df[['name', 'type']], left_on='object', right_on='name'\n",
    ").drop(columns=['name'])\n",
    "\n",
    "mask = False\n",
    "for type1, type2 in pairs_to_predict:\n",
    "    mask |= ((test_edges_df_['type_x'] == type1) & (test_edges_df_['type_y'] == type2)) | \\\n",
    "            ((test_edges_df_['type_x'] == type2) & (test_edges_df_['type_y'] == type1))\n",
    "\n",
    "test_edges_df_filtered = test_edges_df_[mask][['subject', 'predicate', 'object']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_view = Graph.from_pd(\n",
    "    edges_df=test_edges_df_filtered,\n",
    "    nodes_df=nodes_df,\n",
    "    node_name_column=\"name\",\n",
    "    node_type_column=\"type\",\n",
    "    edge_src_column=\"subject\",\n",
    "    edge_dst_column=\"object\",\n",
    "    edge_type_column=\"predicate\",\n",
    "    directed=True,\n",
    "    name=\"RNA-KG VIEW_properties test set\",\n",
    ")\n",
    "\n",
    "predictions, edge_triples = predict_on_graph(\n",
    "    graph=test_view,\n",
    "    embedder=graph_embedding_transe,\n",
    "    model_path=\"RNA-KG VIEW_properties_sklearn.ensemble._forest.RandomForestClassifier.pkl\",\n",
    "    include_edge_types=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(edge_triples, columns=[\"subject\", \"predicate\", \"object\"])\n",
    "df[\"prediction\"] = predictions\n",
    "df.to_csv(\"predictions_mirnaphenotype.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mirnaphenotype = pd.read_csv(\"predictions_mirnaphenotype.csv\")\n",
    "mirnaphenotype = mirnaphenotype.merge(test_edges_df, on=['subject', 'predicate', 'object'], how='left')\n",
    "mirnaphenotype.to_csv(\"predictions_mirnaphenotype.csv\", index=False)\n",
    "mirnaphenotype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mirnaphenotype['prediction'].to_numpy()\n",
    "threshold = 0.5\n",
    "(predictions>=threshold).sum(), len(predictions), \\\n",
    "len(predictions[predictions>=threshold])/len(predictions), len(predictions[predictions<threshold])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=mirnaphenotype, x='year', y='prediction')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirnaphenotype = mirnaphenotype[mirnaphenotype['prediction'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mirnaphenotype['prediction'].to_numpy()\n",
    "threshold = 0.5\n",
    "(predictions>=threshold).sum(), len(predictions), \\\n",
    "len(predictions[predictions>=threshold])/len(predictions), len(predictions[predictions<threshold])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=mirnaphenotype, x='year', y='prediction')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene-Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed = 42\n",
    "\n",
    "model_forest = RandomForestClassifier(random_state=seed, n_jobs=6)\n",
    "pairs_to_predict = [\n",
    "    #(\"miRNA\", \"Gene\"),\n",
    "    #(\"miRNA\", \"Disease\"),\n",
    "    #(\"miRNA\", \"Phenotype\"),\n",
    "    (\"Gene\", \"Disease\"),\n",
    "    #(\"Gene\", \"Phenotype\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG) \n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "results_fun_transE_forest = edge_pred_pairs_sklearn(\n",
    "    view_directed,\n",
    "    graph_embedding_transe,\n",
    "    model_forest,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=1,\n",
    "    binary=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fun_transE_forest.groupby([\"Source Type\", \"Destination Type\"])[\n",
    "    [\n",
    "        \"Positive balanced accuracy\",\n",
    "        \"Negative balanced accuracy\",\n",
    "        \"Mean balanced accuracy\",\n",
    "    ]\n",
    "].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_on_graph(graph, embedder, model_path, include_edge_types=True):\n",
    "    \"\"\"\n",
    "    Predicts link scores for all edges in the provided graph using the given embedder and a trained sklearn model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : grape.Graph\n",
    "        The graph to use for extracting edges and embeddings.\n",
    "    embedder : grape.EmbeddingResult or compatible embedder\n",
    "        The node and optionally edge embedder used for embedding nodes and edges.\n",
    "    model_path : str\n",
    "        Path to the pre-trained sklearn model.\n",
    "    include_edge_types : bool, optional\n",
    "        Whether to include edge type embeddings in the concatenated input, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions : np.ndarray\n",
    "        An array of predicted scores (e.g., probabilities or binary labels depending on model).\n",
    "    edge_ids : list\n",
    "        List of edge (subject, predicate, object) identifiers corresponding to each prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    node_embeddings = embedder.get_all_node_embedding()[0]\n",
    "    try:\n",
    "        edge_type_embeddings = embedder.get_all_edge_type_embeddings()[0] if include_edge_types else {}\n",
    "    except:\n",
    "        edge_type_embeddings = {}\n",
    "\n",
    "    edge_node_names = graph.get_edge_node_names(directed=True)\n",
    "    predictions = []\n",
    "    edge_ids = []\n",
    "\n",
    "    for edge_id in tqdm(range(graph.get_number_of_directed_edges()), desc=\"Predicting edges\"):\n",
    "        subj, obj = edge_node_names[edge_id]\n",
    "        predicate = graph.get_edge_type_name_from_edge_id(edge_id)\n",
    "\n",
    "        subj_emb = node_embeddings.loc[subj].values\n",
    "        obj_emb = node_embeddings.loc[obj].values\n",
    "\n",
    "        if include_edge_types and predicate in edge_type_embeddings.index:\n",
    "            pred_emb = edge_type_embeddings.loc[predicate].values\n",
    "            edge_input = np.concatenate([subj_emb, pred_emb, obj_emb])\n",
    "        else:\n",
    "            edge_input = np.concatenate([subj_emb, obj_emb])\n",
    "\n",
    "        score = model.predict_proba([edge_input])[0][1] if hasattr(model, \"predict_proba\") else model.predict([edge_input])[0]\n",
    "        predictions.append(score)\n",
    "        edge_ids.append((subj, predicate, obj))\n",
    "\n",
    "    return np.array(predictions), edge_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges_df_ = test_edges_df.merge(\n",
    "    nodes_df[['name', 'type']], left_on='subject', right_on='name'\n",
    ").drop(columns=['name']).merge(\n",
    "    nodes_df[['name', 'type']], left_on='object', right_on='name'\n",
    ").drop(columns=['name'])\n",
    "\n",
    "mask = False\n",
    "for type1, type2 in pairs_to_predict:\n",
    "    mask |= ((test_edges_df_['type_x'] == type1) & (test_edges_df_['type_y'] == type2)) | \\\n",
    "            ((test_edges_df_['type_x'] == type2) & (test_edges_df_['type_y'] == type1))\n",
    "\n",
    "test_edges_df_filtered = test_edges_df_[mask][['subject', 'predicate', 'object']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_view = Graph.from_pd(\n",
    "    edges_df=test_edges_df_filtered,\n",
    "    nodes_df=nodes_df,\n",
    "    node_name_column=\"name\",\n",
    "    node_type_column=\"type\",\n",
    "    edge_src_column=\"subject\",\n",
    "    edge_dst_column=\"object\",\n",
    "    edge_type_column=\"predicate\",\n",
    "    directed=True,\n",
    "    name=\"RNA-KG VIEW_properties test set\",\n",
    ")\n",
    "\n",
    "predictions, edge_triples = predict_on_graph(\n",
    "    graph=test_view,\n",
    "    embedder=graph_embedding_transe,\n",
    "    model_path=\"RNA-KG VIEW_properties_sklearn.ensemble._forest.RandomForestClassifier.pkl\",\n",
    "    include_edge_types=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(edge_triples, columns=[\"subject\", \"predicate\", \"object\"])\n",
    "df[\"prediction\"] = predictions\n",
    "df.to_csv(\"predictions_genedisease.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "genedisease = pd.read_csv(\"predictions_genedisease.csv\")\n",
    "genedisease = genedisease.merge(test_edges_df, on=['subject', 'predicate', 'object'], how='left')\n",
    "genedisease.to_csv(\"predictions_genedisease.csv\", index=False)\n",
    "genedisease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = genedisease['prediction'].to_numpy()\n",
    "threshold = 0.5\n",
    "(predictions>=threshold).sum(), len(predictions), \\\n",
    "len(predictions[predictions>=threshold])/len(predictions), len(predictions[predictions<threshold])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=genedisease, x='year', y='prediction')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genedisease = genedisease[genedisease['prediction'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = genedisease['prediction'].to_numpy()\n",
    "threshold = 0.5\n",
    "(predictions>=threshold).sum(), len(predictions), \\\n",
    "len(predictions[predictions>=threshold])/len(predictions), len(predictions[predictions<threshold])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=genedisease, x='year', y='prediction')\n",
    "plt.title('Distribuzione delle Predizioni per Anno')\n",
    "plt.xlabel('Anno')\n",
    "plt.ylabel('Valori Predetti')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene-Phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed = 42\n",
    "\n",
    "model_forest = RandomForestClassifier(random_state=seed, n_jobs=6)\n",
    "pairs_to_predict = [\n",
    "    #(\"miRNA\", \"Gene\"),\n",
    "    #(\"miRNA\", \"Disease\"),\n",
    "    #(\"miRNA\", \"Phenotype\"),\n",
    "    #(\"Gene\", \"Disease\"),\n",
    "    (\"Gene\", \"Phenotype\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG) \n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "results_fun_transE_forest = edge_pred_pairs_sklearn(\n",
    "    view_directed,\n",
    "    graph_embedding_transe,\n",
    "    model_forest,\n",
    "    pairs_to_predict,\n",
    "    seed=seed,\n",
    "    clear_output=True,\n",
    "    use_scale_free_distribution=True,\n",
    "    verbose=True,\n",
    "    number_of_holdouts=1,\n",
    "    binary=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fun_transE_forest.groupby([\"Source Type\", \"Destination Type\"])[\n",
    "    [\n",
    "        \"Positive balanced accuracy\",\n",
    "        \"Negative balanced accuracy\",\n",
    "        \"Mean balanced accuracy\",\n",
    "    ]\n",
    "].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_on_graph(graph, embedder, model_path, include_edge_types=True):\n",
    "    \"\"\"\n",
    "    Predicts link scores for all edges in the provided graph using the given embedder and a trained sklearn model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : grape.Graph\n",
    "        The graph to use for extracting edges and embeddings.\n",
    "    embedder : grape.EmbeddingResult or compatible embedder\n",
    "        The node and optionally edge embedder used for embedding nodes and edges.\n",
    "    model_path : str\n",
    "        Path to the pre-trained sklearn model.\n",
    "    include_edge_types : bool, optional\n",
    "        Whether to include edge type embeddings in the concatenated input, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions : np.ndarray\n",
    "        An array of predicted scores (e.g., probabilities or binary labels depending on model).\n",
    "    edge_ids : list\n",
    "        List of edge (subject, predicate, object) identifiers corresponding to each prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # Estrarre embeddings\n",
    "    node_embeddings = embedder.get_all_node_embedding()[0]\n",
    "    try:\n",
    "        edge_type_embeddings = embedder.get_all_edge_type_embeddings()[0] if include_edge_types else {}\n",
    "    except:\n",
    "        edge_type_embeddings = {}\n",
    "\n",
    "    edge_node_names = graph.get_edge_node_names(directed=True)\n",
    "    predictions = []\n",
    "    edge_ids = []\n",
    "\n",
    "    for edge_id in tqdm(range(graph.get_number_of_directed_edges()), desc=\"Predicting edges\"):\n",
    "        subj, obj = edge_node_names[edge_id]\n",
    "        predicate = graph.get_edge_type_name_from_edge_id(edge_id)\n",
    "\n",
    "        subj_emb = node_embeddings.loc[subj].values\n",
    "        obj_emb = node_embeddings.loc[obj].values\n",
    "\n",
    "        if include_edge_types and predicate in edge_type_embeddings.index:\n",
    "            pred_emb = edge_type_embeddings.loc[predicate].values\n",
    "            edge_input = np.concatenate([subj_emb, pred_emb, obj_emb])\n",
    "        else:\n",
    "            edge_input = np.concatenate([subj_emb, obj_emb])\n",
    "\n",
    "        score = model.predict_proba([edge_input])[0][1] if hasattr(model, \"predict_proba\") else model.predict([edge_input])[0]\n",
    "        predictions.append(score)\n",
    "        edge_ids.append((subj, predicate, obj))\n",
    "\n",
    "    return np.array(predictions), edge_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges_df_ = test_edges_df.merge(\n",
    "    nodes_df[['name', 'type']], left_on='subject', right_on='name'\n",
    ").drop(columns=['name']).merge(\n",
    "    nodes_df[['name', 'type']], left_on='object', right_on='name'\n",
    ").drop(columns=['name'])\n",
    "\n",
    "mask = False\n",
    "for type1, type2 in pairs_to_predict:\n",
    "    mask |= ((test_edges_df_['type_x'] == type1) & (test_edges_df_['type_y'] == type2)) | \\\n",
    "            ((test_edges_df_['type_x'] == type2) & (test_edges_df_['type_y'] == type1))\n",
    "\n",
    "test_edges_df_filtered = test_edges_df_[mask][['subject', 'predicate', 'object']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_view = Graph.from_pd(\n",
    "    edges_df=test_edges_df_filtered,\n",
    "    nodes_df=nodes_df,\n",
    "    node_name_column=\"name\",\n",
    "    node_type_column=\"type\",\n",
    "    edge_src_column=\"subject\",\n",
    "    edge_dst_column=\"object\",\n",
    "    edge_type_column=\"predicate\",\n",
    "    directed=True,\n",
    "    name=\"RNA-KG VIEW_properties test set\",\n",
    ")\n",
    "\n",
    "predictions, edge_triples = predict_on_graph(\n",
    "    graph=test_view,\n",
    "    embedder=graph_embedding_transe,\n",
    "    model_path=\"RNA-KG VIEW_properties_sklearn.ensemble._forest.RandomForestClassifier.pkl\",\n",
    "    include_edge_types=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(edge_triples, columns=[\"subject\", \"predicate\", \"object\"])\n",
    "df[\"prediction\"] = predictions\n",
    "df.to_csv(\"predictions_genephenotype.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "genephenotype = pd.read_csv(\"predictions_genephenotype.csv\")\n",
    "genephenotype = genephenotype.merge(test_edges_df, on=['subject', 'predicate', 'object'], how='left')\n",
    "genephenotype.to_csv(\"predictions_genephenotype.csv\", index=False)\n",
    "genephenotype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = genephenotype['prediction'].to_numpy()\n",
    "threshold = 0.5\n",
    "(predictions>=threshold).sum(), len(predictions), \\\n",
    "len(predictions[predictions>=threshold])/len(predictions), len(predictions[predictions<threshold])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=genephenotype, x='year', y='prediction')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genephenotype = genephenotype[genephenotype['prediction'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = genephenotype['prediction'].to_numpy()\n",
    "threshold = 0.5\n",
    "(predictions>=threshold).sum(), len(predictions), \\\n",
    "len(predictions[predictions>=threshold])/len(predictions), len(predictions[predictions<threshold])/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=genephenotype, x='year', y='prediction')\n",
    "plt.title('Distribuzione delle Predizioni per Anno')\n",
    "plt.xlabel('Anno')\n",
    "plt.ylabel('Valori Predetti')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = {\n",
    "    \"miRNA–Gene\": \"TransE_test>=2022/predictions_mirnagene.csv\",\n",
    "    \"miRNA–Disease\": \"TransE_test>=2022/predictions_mirnadisease.csv\",\n",
    "    \"miRNA–Phenotype\": \"TransE_test>=2022/predictions_mirnaphenotype.csv\",\n",
    "    \"Gene–Disease\": \"TransE_test>=2022/predictions_genedisease.csv\",\n",
    "    \"Gene–Phenotype\": \"TransE_test>=2022/predictions_genephenotype.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'year_x': 'year', 'prediction_x': 'prediction'})\n",
    "    df[\"relation_type\"] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "with_zeros = all_data.copy()\n",
    "without_zeros = all_data[all_data[\"prediction\"] != 0].copy()\n",
    "\n",
    "def plot_box(data, title, filename):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=data, x=\"relation_type\", y=\"prediction\", hue=\"year\",\n",
    "                palette=\"Set2\", showfliers=False)\n",
    "    plt.axhline(0.5, color=\"darkred\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Prediction Score\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Year\", loc='upper right', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_box(with_zeros, \"predictions_with_zeros\", \"predictions_with_zeros.png\")\n",
    "plot_box(without_zeros, \"predictions_without_zeros\", \"predictions_without_zeros.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = {\n",
    "    \"miRNA–Gene\": \"TransE_test>=2023/predictions_mirnagene.csv\",\n",
    "    \"miRNA–Disease\": \"TransE_test>=2023/predictions_mirnadisease.csv\",\n",
    "    \"miRNA–Phenotype\": \"TransE_test>=2023/predictions_mirnaphenotype.csv\",\n",
    "    \"Gene–Disease\": \"TransE_test>=2023/predictions_genedisease.csv\",\n",
    "    \"Gene–Phenotype\": \"TransE_test>=2023/predictions_genephenotype.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'year_x': 'year', 'prediction_x': 'prediction'})\n",
    "    df[\"relation_type\"] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "with_zeros = all_data.copy()\n",
    "without_zeros = all_data[all_data[\"prediction\"] != 0].copy()\n",
    "\n",
    "def plot_box(data, title, filename):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=data, x=\"relation_type\", y=\"prediction\", hue=\"year\",\n",
    "                palette=\"Set2\", showfliers=False)\n",
    "    plt.axhline(0.5, color=\"darkred\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Prediction Score\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Year\", loc='upper right', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_box(with_zeros, \"predictions_with_zeros\", \"predictions_with_zeros.png\")\n",
    "plot_box(without_zeros, \"predictions_without_zeros\", \"predictions_without_zeros.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = {\n",
    "    \"miRNA–Gene\": \"TransE_test>=2024/predictions_mirnagene.csv\",\n",
    "    \"miRNA–Disease\": \"TransE_test>=2024/predictions_mirnadisease.csv\",\n",
    "    \"miRNA–Phenotype\": \"TransE_test>=2024/predictions_mirnaphenotype.csv\",\n",
    "    \"Gene–Disease\": \"TransE_test>=2024/predictions_genedisease.csv\",\n",
    "    \"Gene–Phenotype\": \"TransE_test>=2024/predictions_genephenotype.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'year_x': 'year', 'prediction_x': 'prediction'})\n",
    "    df[\"relation_type\"] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "with_zeros = all_data.copy()\n",
    "without_zeros = all_data[all_data[\"prediction\"] != 0].copy()\n",
    "\n",
    "def plot_box(data, title, filename):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=data, x=\"relation_type\", y=\"prediction\", hue=\"year\",\n",
    "                palette=\"Set2\", showfliers=False)\n",
    "    plt.axhline(0.5, color=\"darkred\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Prediction Score\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Year\", loc='upper right', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_box(with_zeros, \"predictions_with_zeros\", \"predictions_with_zeros.png\")\n",
    "plot_box(without_zeros, \"predictions_without_zeros\", \"predictions_without_zeros.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = {\n",
    "    \"miRNA–Gene\": \"TransE_test>=2025/predictions_mirnagene.csv\",\n",
    "    \"miRNA–Disease\": \"TransE_test>=2025/predictions_mirnadisease.csv\",\n",
    "    \"miRNA–Phenotype\": \"TransE_test>=2025/predictions_mirnaphenotype.csv\",\n",
    "    \"Gene–Disease\": \"TransE_test>=2025/predictions_genedisease.csv\",\n",
    "    \"Gene–Phenotype\": \"TransE_test>=2025/predictions_genephenotype.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'year_x': 'year', 'prediction_x': 'prediction'})\n",
    "    df[\"relation_type\"] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "with_zeros = all_data.copy()\n",
    "without_zeros = all_data[all_data[\"prediction\"] != 0].copy()\n",
    "\n",
    "def plot_box(data, title, filename):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=data, x=\"relation_type\", y=\"prediction\", hue=\"year\",\n",
    "                palette=\"Set2\", showfliers=False)\n",
    "    plt.axhline(0.5, color=\"darkred\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Prediction Score\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Year\", loc='upper right', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_box(with_zeros, \"predictions_with_zeros\", \"predictions_with_zeros.png\")\n",
    "plot_box(without_zeros, \"predictions_without_zeros\", \"predictions_without_zeros.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = {\n",
    "    \"miRNA–Gene\": \"Node2Vec_test>=2022/predictions_mirnagene.csv\",\n",
    "    \"miRNA–Disease\": \"Node2Vec_test>=2022/predictions_mirnadisease.csv\",\n",
    "    \"miRNA–Phenotype\": \"Node2Vec_test>=2022/predictions_mirnaphenotype.csv\",\n",
    "    \"Gene–Disease\": \"Node2Vec_test>=2022/predictions_genedisease.csv\",\n",
    "    \"Gene–Phenotype\": \"Node2Vec_test>=2022/predictions_genephenotype.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'year_x': 'year', 'prediction_x': 'prediction'})\n",
    "    df[\"relation_type\"] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "with_zeros = all_data.copy()\n",
    "without_zeros = all_data[all_data[\"prediction\"] != 0].copy()\n",
    "\n",
    "def plot_box(data, title, filename):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=data, x=\"relation_type\", y=\"prediction\", hue=\"year\",\n",
    "                palette=\"Set2\", showfliers=False)\n",
    "    plt.axhline(0.5, color=\"darkred\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Prediction Score\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Year\", loc='upper right', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_box(with_zeros, \"predictions_with_zeros\", \"predictions_with_zeros.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = {\n",
    "    \"miRNA–Gene\": \"Node2Vec_test>=2023/predictions_mirnagene.csv\",\n",
    "    \"miRNA–Disease\": \"Node2Vec_test>=2023/predictions_mirnadisease.csv\",\n",
    "    \"miRNA–Phenotype\": \"Node2Vec_test>=2023/predictions_mirnaphenotype.csv\",\n",
    "    \"Gene–Disease\": \"Node2Vec_test>=2023/predictions_genedisease.csv\",\n",
    "    \"Gene–Phenotype\": \"Node2Vec_test>=2023/predictions_genephenotype.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'year_x': 'year', 'prediction_x': 'prediction'})\n",
    "    df[\"relation_type\"] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "with_zeros = all_data.copy()\n",
    "without_zeros = all_data[all_data[\"prediction\"] != 0].copy()\n",
    "\n",
    "def plot_box(data, title, filename):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=data, x=\"relation_type\", y=\"prediction\", hue=\"year\",\n",
    "                palette=\"Set2\", showfliers=False)\n",
    "    plt.axhline(0.5, color=\"darkred\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Prediction Score\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Year\", loc='upper right', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_box(with_zeros, \"predictions_with_zeros\", \"predictions_with_zeros.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = {\n",
    "    \"miRNA–Gene\": \"Node2Vec_test>=2024/predictions_mirnagene.csv\",\n",
    "    \"miRNA–Disease\": \"Node2Vec_test>=2024/predictions_mirnadisease.csv\",\n",
    "    \"miRNA–Phenotype\": \"Node2Vec_test>=2024/predictions_mirnaphenotype.csv\",\n",
    "    \"Gene–Disease\": \"Node2Vec_test>=2024/predictions_genedisease.csv\",\n",
    "    \"Gene–Phenotype\": \"Node2Vec_test>=2024/predictions_genephenotype.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'year_x': 'year', 'prediction_x': 'prediction'})\n",
    "    df[\"relation_type\"] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "with_zeros = all_data.copy()\n",
    "without_zeros = all_data[all_data[\"prediction\"] != 0].copy()\n",
    "\n",
    "def plot_box(data, title, filename):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=data, x=\"relation_type\", y=\"prediction\", hue=\"year\",\n",
    "                palette=\"Set2\", showfliers=False)\n",
    "    plt.axhline(0.5, color=\"darkred\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Prediction Score\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Year\", loc='upper right', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_box(with_zeros, \"predictions_with_zeros\", \"predictions_with_zeros.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = {\n",
    "    \"miRNA–Gene\": \"Node2Vec_test>=2025/predictions_mirnagene.csv\",\n",
    "    \"miRNA–Disease\": \"Node2Vec_test>=2025/predictions_mirnadisease.csv\",\n",
    "    \"miRNA–Phenotype\": \"Node2Vec_test>=2025/predictions_mirnaphenotype.csv\",\n",
    "    \"Gene–Disease\": \"Node2Vec_test>=2025/predictions_genedisease.csv\",\n",
    "    \"Gene–Phenotype\": \"Node2Vec_test>=2025/predictions_genephenotype.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'year_x': 'year', 'prediction_x': 'prediction'})\n",
    "    df[\"relation_type\"] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "with_zeros = all_data.copy()\n",
    "without_zeros = all_data[all_data[\"prediction\"] != 0].copy()\n",
    "\n",
    "def plot_box(data, title, filename):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=data, x=\"relation_type\", y=\"prediction\", hue=\"year\",\n",
    "                palette=\"Set2\", showfliers=False)\n",
    "    plt.axhline(0.5, color=\"darkred\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Prediction Score\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Year\", loc='upper right', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_box(with_zeros, \"predictions_with_zeros\", \"predictions_with_zeros.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = {\n",
    "    \"miRNA–Gene\": \"Node2Vec_test>=2023/predictions_mirnagene.csv\",\n",
    "    \"miRNA–Disease\": \"Node2Vec_test>=2023/predictions_mirnadisease.csv\",\n",
    "    \"miRNA–Phenotype\": \"Node2Vec_test>=2023/predictions_mirnaphenotype.csv\"#,\n",
    "    #\"Gene–Disease\": \"Node2Vec_test>=2023/predictions_genedisease.csv\",\n",
    "    #\"Gene–Phenotype\": \"Node2Vec_test>=2023/predictions_genephenotype.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'year_x': 'year', 'prediction_x': 'prediction'})\n",
    "    df['year'] = df['year'].astype(str).str.replace('.0', '')\n",
    "    df = df[df['year'].str.isnumeric()]  # Filtra solo gli anni numerici\n",
    "    df = df.sort_values(by='year')\n",
    "    df[\"relation_type\"] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "with_zeros = all_data.copy()\n",
    "without_zeros = all_data[all_data[\"prediction\"] != 0].copy()\n",
    "\n",
    "def plot_box(data, title, filename):\n",
    "    plt.figure(figsize=(4, 2.5))\n",
    "    sns.boxplot(data=data, x=\"relation_type\", y=\"prediction\", hue=\"year\",\n",
    "                palette=\"Set2\", showfliers=False)\n",
    "    plt.axhline(0.5, color=\"darkred\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    #plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Year\", loc='lower right', fontsize=6, title_fontsize=7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "plot_box(with_zeros, \"\", \"timestratified_predictions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data[all_data['prediction'] > 0.5]),\\\n",
    "len(all_data),\\\n",
    "len(all_data[all_data['prediction'] > 0.5]) / len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[all_data['prediction'] > 0.5].groupby('year').size().sort_index(),\\\n",
    "all_data.groupby('year').size().sort_index(),\\\n",
    "all_data[all_data['prediction'] > 0.5].groupby('year').size().sort_index() / all_data.groupby('year').size().sort_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
